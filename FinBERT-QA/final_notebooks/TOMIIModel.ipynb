{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8zaT9bvO5Et_"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pNTTSWVAHWNn",
        "outputId": "d64e34fc-2a12-47ba-e586-12a66f8b565f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /gdrive; to attempt to forcibly remount, call drive.mount(\"/gdrive\", force_remount=True).\n",
            "/gdrive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/gdrive')\n",
        "%cd /gdrive"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Install packages"
      ],
      "metadata": {
        "id": "ZFwnnm2MatNQ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ocYykoNkdZxO"
      },
      "outputs": [],
      "source": [
        "pip install -q -U tensorflow-hub tensorflow-text tensorflow-addons"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sXOmUa18eBqp"
      },
      "outputs": [],
      "source": [
        "!pip install pydot --quiet\n",
        "!pip install gensim==3.8.3 --quiet\n",
        "!pip install tensorflow-datasets --quiet\n",
        "!pip install -U tensorflow-text --quiet\n",
        "!pip install transformers --quiet\n",
        "!pip install pydot --quiet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MhkYBjWuewpq"
      },
      "outputs": [],
      "source": [
        "!pip install -q tensorflow-recommenders\n",
        "!pip install -q scann"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FXgRe8OKeiU7"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import regex as re\n",
        "import csv\n",
        "from itertools import islice\n",
        "import pickle\n",
        "import numpy as np\n",
        "import json\n",
        "import os\n",
        "import sys\n",
        "import argparse\n",
        "from pathlib import Path\n",
        "import pprint\n",
        "import tempfile\n",
        "import re\n",
        "from typing import Dict, Text\n",
        "\n",
        "import sklearn as sk\n",
        "from sklearn.model_selection import train_test_split\n",
        "import nltk\n",
        "from nltk.corpus import reuters\n",
        "from nltk.data import find\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from sklearn.metrics import ndcg_score\n",
        "from sklearn.metrics import average_precision_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zK3EVAowIFU3"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import collections\n",
        "import json\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "import tensorflow_hub as hub\n",
        "import tensorflow_text as text\n",
        "import tensorflow_addons as tfa\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Suppressing tf.hub warnings\n",
        "tf.get_logger().setLevel(\"ERROR\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-LfeLx-MeJhs"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.layers import Embedding, Input, Dense, Lambda\n",
        "from tensorflow.keras.models import Model\n",
        "import tensorflow.keras.backend as K\n",
        "import tensorflow_datasets as tfds\n",
        "import tensorflow_text as tf_text\n",
        "import tensorflow_recommenders as tfrs\n",
        "\n",
        "from transformers import BertTokenizer, TFBertModel"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hs3iqiPlqWcd",
        "outputId": "2063587a-f30a-4c34-a20b-a7c14c715e9a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/gdrive/MyDrive/nlp-yuan_code/FinBERT-QA\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "%cd /gdrive/MyDrive/nlp-yuan_code/FinBERT-QA\n",
        "from src.process_data import *"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Setting up the path"
      ],
      "metadata": {
        "id": "30U9KTR1azWE"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fNrd11D6pa1N"
      },
      "outputs": [],
      "source": [
        "RO_FiQA_DATA_PATH = '/gdrive/MyDrive/nlp-data/nlp-qa-datasets/FiQA/FiQA_train_task2/'\n",
        "RO_FIQA_INDEX = \"/gdrive/MyDrive/nlp-yuan_code/FinBERT-QA/retriever/lucene-index-fiqa/\"\n",
        "WR_PICKLE_DATA = '/gdrive/MyDrive/nlp-yuan_code/FinBERT-QA/data/data_pickle/'\n",
        "WR_PICKLE_TRANSIENT_DATA = '/gdrive/MyDrive/nlp-yuan_code/FinBERT-QA/data/data_pickle/transient/'\n",
        "WR_INTERIM_DATA = '/gdrive/MyDrive/nlp-yuan_code/FinBERT-QA/data/interim/'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tuN3e-2XphOe"
      },
      "outputs": [],
      "source": [
        "train_set = load_pickle(WR_INTERIM_DATA + \"train_set.pickle\")\n",
        "test_set = load_pickle(WR_INTERIM_DATA + \"test_set.pickle\")\n",
        "qid_to_text = load_pickle(WR_INTERIM_DATA + \"qid_to_text.pickle\")\n",
        "docid_to_text = load_pickle(WR_INTERIM_DATA + \"docid_to_text.pickle\")\n",
        "text_to_docid = load_pickle(WR_INTERIM_DATA + \"text_to_docid.pickle\")\n",
        "qa_pairs = load_pickle(WR_INTERIM_DATA + \"qa_pairs.pickle\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Generate Train and Test dataset"
      ],
      "metadata": {
        "id": "2eqYvE_JuNDp"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vgjc-kuarWP7"
      },
      "outputs": [],
      "source": [
        "unique_qids = []\n",
        "unique_aids = []\n",
        "for qid, aid in qa_pairs:\n",
        "  unique_qids.append(qid)\n",
        "  unique_aids.append(aid)\n",
        "unique_qids = np.unique(unique_qids)\n",
        "unique_aids = np.unique(unique_aids)\n",
        "\n",
        "questions = tf.data.Dataset.from_tensor_slices([qid_to_text[qid] if isinstance(qid_to_text.get(qid),str) else '' for qid, aid in qa_pairs])\n",
        "answers = tf.data.Dataset.from_tensor_slices([docid_to_text[aid] if isinstance(docid_to_text.get(aid),str) else '' for qid, aid in qa_pairs])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4z4NowRXqxND",
        "outputId": "11194298-2c54-4bb1-ba5a-acc3f3e9cac8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "6648 17110 17110\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "(17110, 17110)"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "print(len(unique_qids), len(unique_aids), len(qa_pairs))\n",
        "len(answers), len(questions)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N-XNpFWDshld"
      },
      "outputs": [],
      "source": [
        "ds = tf.data.Dataset.zip((questions, answers))\n",
        "ds = ds.map(lambda x, y : {\"question\": x, \"answer\": y})\n",
        "\n",
        "tf.random.set_seed(42)\n",
        "shuffled = ds.shuffle(17_110, seed=42, reshuffle_each_iteration=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cPUS5_k4smab"
      },
      "outputs": [],
      "source": [
        "cached_train = shuffled.shuffle(17_110).batch(1300)\n",
        "cached_test =  shuffled.take(856).batch(150)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s4_VUx1YIJiU"
      },
      "outputs": [],
      "source": [
        "def project_embeddings(\n",
        "    embeddings, num_projection_layers, projection_dims, dropout_rate\n",
        "):\n",
        "    projected_embeddings = layers.Dense(units=projection_dims)(embeddings)\n",
        "    for _ in range(num_projection_layers):\n",
        "        x = tf.nn.gelu(projected_embeddings)\n",
        "        x = layers.Dense(projection_dims)(x)\n",
        "        x = layers.Dropout(dropout_rate)(x)\n",
        "        x = layers.Add()([projected_embeddings, x])\n",
        "        projected_embeddings = layers.LayerNormalization()(x)\n",
        "    return projected_embeddings\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Using BERT to generate embeddings"
      ],
      "metadata": {
        "id": "IYfP9bbnxnsv"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c-BXzP8rIUfJ"
      },
      "outputs": [],
      "source": [
        "def create_text_encoder(num_projection_layers, projection_dims, dropout_rate, trainable=False):\n",
        "  \n",
        "    # Load the BERT preprocessing module.\n",
        "    preprocess = hub.KerasLayer(\n",
        "        \"https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/2\",\n",
        "        name=\"text_preprocessing\",\n",
        "    )\n",
        "    # Load the pre-trained BERT model to be used as the base encoder.\n",
        "    bert = hub.KerasLayer(\n",
        "        \"https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-4_H-512_A-8/1\",\n",
        "        name = \"bert\",\n",
        "    )\n",
        "    # Set the trainability of the base encoder.\n",
        "    bert.trainable = trainable\n",
        "    # Receive the text as inputs.\n",
        "    inputs = layers.Input(shape=(), dtype=tf.string, name=\"text_input\")\n",
        "    # Preprocess the text.\n",
        "    bert_inputs = preprocess(inputs)\n",
        "    # Generate embeddings for the preprocessed text using the BERT model.\n",
        "    embeddings = bert(bert_inputs)[\"pooled_output\"]\n",
        "    # Project the embeddings produced by the model.\n",
        "    outputs = project_embeddings(\n",
        "        embeddings, num_projection_layers, projection_dims, dropout_rate\n",
        "    )\n",
        "    # Create the text encoder model.\n",
        "    return keras.Model(inputs, outputs, name=\"text_encoder\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Generating the Two Tower Model"
      ],
      "metadata": {
        "id": "OpB3Nd2myHWw"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yioR2MYtJqnt"
      },
      "outputs": [],
      "source": [
        "class DualEncoder(keras.Model):\n",
        "    def __init__(self, question_encoder, answer_encoder, temperature=1.0, **kwargs):\n",
        "        super(DualEncoder, self).__init__(**kwargs)\n",
        "        self.question_encoder = question_encoder\n",
        "        self.answer_encoder = answer_encoder\n",
        "        self.temperature = temperature\n",
        "        self.loss_tracker = keras.metrics.Mean(name=\"loss\")\n",
        "\n",
        "    @property\n",
        "    def metrics(self):\n",
        "        return [self.loss_tracker]\n",
        "\n",
        "    def call(self, features, training=False):\n",
        "        # Place each encoder on a separate GPU (if available).\n",
        "        # TF will fallback on available devices if there are fewer than 2 GPUs.\n",
        "        with tf.device(\"/gpu:0\"):\n",
        "            # Get the embeddings for the captions.\n",
        "            question_embeddings = question_encoder(features[\"question\"], training=training)\n",
        "        with tf.device(\"/gpu:1\"):\n",
        "            # Get the embeddings for the images.\n",
        "            answer_embeddings = answer_encoder(features[\"answer\"], training=training)\n",
        "        return question_embeddings, answer_embeddings\n",
        "\n",
        "    def compute_loss(self, question_embeddings, answer_embeddings):\n",
        "        # logits[i][j] is the dot_similarity(caption_i, image_j).\n",
        "        logits = (\n",
        "            tf.matmul(question_embeddings, answer_embeddings, transpose_b=True)\n",
        "            / self.temperature\n",
        "        )\n",
        "        # images_similarity[i][j] is the dot_similarity(image_i, image_j).\n",
        "        answer_similarity = tf.matmul(\n",
        "            answer_embeddings, answer_embeddings, transpose_b=True\n",
        "        )\n",
        "        # captions_similarity[i][j] is the dot_similarity(caption_i, caption_j).\n",
        "        question_similarity = tf.matmul(\n",
        "            question_embeddings, question_embeddings, transpose_b=True\n",
        "        )\n",
        "        # targets[i][j] = avarage dot_similarity(caption_i, caption_j) and dot_similarity(image_i, image_j).\n",
        "        targets = keras.activations.softmax(\n",
        "            (question_similarity + answer_similarity) / (2 * self.temperature)\n",
        "        )\n",
        "        # Compute the loss for the captions using crossentropy\n",
        "        question_loss = keras.losses.categorical_crossentropy(\n",
        "            y_true=targets, y_pred=logits, from_logits=True\n",
        "        )\n",
        "        # Compute the loss for the images using crossentropy\n",
        "        answer_loss = keras.losses.categorical_crossentropy(\n",
        "            y_true=tf.transpose(targets), y_pred=tf.transpose(logits), from_logits=True\n",
        "        )\n",
        "        # Return the mean of the loss over the batch.\n",
        "        return (question_loss + answer_loss) / 2\n",
        "\n",
        "    def train_step(self, features):\n",
        "        with tf.GradientTape() as tape:\n",
        "            # Forward pass\n",
        "            question_embeddings, answer_embeddings = self(features, training=True)\n",
        "            loss = self.compute_loss(question_embeddings, answer_embeddings)\n",
        "        # Backward pass\n",
        "        gradients = tape.gradient(loss, self.trainable_variables)\n",
        "        self.optimizer.apply_gradients(zip(gradients, self.trainable_variables))\n",
        "        # Monitor loss\n",
        "        self.loss_tracker.update_state(loss)\n",
        "        return {\"loss\": self.loss_tracker.result()}\n",
        "\n",
        "    def test_step(self, features):\n",
        "        question_embeddings, answer_embeddings = self(features, training=False)\n",
        "        loss = self.compute_loss(question_embeddings, answer_embeddings)\n",
        "        self.loss_tracker.update_state(loss)\n",
        "        return {\"loss\": self.loss_tracker.result()}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NTQaszltNtKz"
      },
      "outputs": [],
      "source": [
        "num_epochs = 30  # In practice, train for at least 30 epochs\n",
        "batch_size = 256\n",
        "embedding_size = 128\n",
        "\n",
        "answer_encoder = create_text_encoder(\n",
        "    num_projection_layers=1, projection_dims=embedding_size, dropout_rate=0.1\n",
        ")\n",
        "question_encoder = create_text_encoder(\n",
        "    num_projection_layers=1, projection_dims=embedding_size, dropout_rate=0.1\n",
        ")\n",
        "dual_encoder = DualEncoder(question_encoder, answer_encoder, temperature=0.05)\n",
        "dual_encoder.compile(\n",
        "    optimizer=tfa.optimizers.AdamW(learning_rate=0.001, weight_decay=0.001)\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Executing the models with different embedding size"
      ],
      "metadata": {
        "id": "yYbmQS1Nyl8s"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "ECdUsXkycebQ",
        "outputId": "0b9f6474-8204-4504-d7cd-53ecd90755cf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of GPUs: 1\n",
            "Epoch 1/30\n",
            "14/14 [==============================] - 1196s 84s/step - loss: 198.7014 - val_loss: 57.5832 - lr: 0.0010\n",
            "Epoch 2/30\n",
            "14/14 [==============================] - 1192s 85s/step - loss: 88.0066 - val_loss: 32.7797 - lr: 0.0010\n",
            "Epoch 3/30\n",
            "14/14 [==============================] - 1174s 83s/step - loss: 59.3225 - val_loss: 18.7883 - lr: 0.0010\n",
            "Epoch 4/30\n",
            "14/14 [==============================] - 1269s 91s/step - loss: 41.5485 - val_loss: 15.9832 - lr: 0.0010\n",
            "Epoch 5/30\n",
            "14/14 [==============================] - 1267s 90s/step - loss: 32.4841 - val_loss: 15.7090 - lr: 0.0010\n",
            "Epoch 6/30\n",
            "14/14 [==============================] - 1275s 91s/step - loss: 27.9025 - val_loss: 12.8407 - lr: 0.0010\n",
            "Epoch 7/30\n",
            "14/14 [==============================] - 1271s 90s/step - loss: 22.9424 - val_loss: 9.9996 - lr: 0.0010\n",
            "Epoch 8/30\n",
            "14/14 [==============================] - 1184s 84s/step - loss: 18.7557 - val_loss: 8.8074 - lr: 0.0010\n",
            "Epoch 9/30\n",
            "14/14 [==============================] - 1163s 83s/step - loss: 16.3634 - val_loss: 7.8760 - lr: 0.0010\n",
            "Epoch 10/30\n",
            "14/14 [==============================] - 1175s 84s/step - loss: 14.6501 - val_loss: 7.1769 - lr: 0.0010\n",
            "Epoch 11/30\n",
            "14/14 [==============================] - 1203s 85s/step - loss: 13.2290 - val_loss: 6.6075 - lr: 0.0010\n",
            "Epoch 12/30\n",
            "14/14 [==============================] - 1176s 83s/step - loss: 12.0803 - val_loss: 6.2616 - lr: 0.0010\n",
            "Epoch 13/30\n",
            "14/14 [==============================] - 1129s 80s/step - loss: 11.2270 - val_loss: 5.8691 - lr: 0.0010\n",
            "Epoch 14/30\n",
            "14/14 [==============================] - 1107s 79s/step - loss: 10.5443 - val_loss: 5.7964 - lr: 0.0010\n",
            "Epoch 15/30\n",
            "14/14 [==============================] - 1169s 83s/step - loss: 9.9894 - val_loss: 5.5747 - lr: 0.0010\n",
            "Epoch 16/30\n"
          ]
        }
      ],
      "source": [
        "print(f\"Number of GPUs: {len(tf.config.list_physical_devices('GPU'))}\")\n",
        "# Create a learning rate scheduler callback.\n",
        "reduce_lr = keras.callbacks.ReduceLROnPlateau(\n",
        "    monitor=\"val_loss\", factor=0.2, patience=3\n",
        ")\n",
        "# Create an early stopping callback.\n",
        "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
        "    monitor=\"val_loss\", patience=5, restore_best_weights=True\n",
        ")\n",
        "history = dual_encoder.fit(\n",
        "    cached_train,\n",
        "    epochs=num_epochs,\n",
        "    validation_data=cached_test,\n",
        "    callbacks=[reduce_lr, early_stopping],\n",
        ")\n",
        "print(\"Training completed. Saving vision and text encoders...\")\n",
        "answer_encoder.save(\"answer_encoder_128\")\n",
        "question_encoder.save(\"question_encoder_128\")\n",
        "print(\"Models are saved.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OIUHNrGrpOBk"
      },
      "outputs": [],
      "source": [
        "plt.plot(history.history[\"loss\"])\n",
        "plt.plot(history.history[\"val_loss\"])\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.legend([\"train\", \"valid\"], loc=\"upper right\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zl81CMBD892m"
      },
      "outputs": [],
      "source": [
        "print(\"Loading vision and text encoders...\")\n",
        "answer_encoder = keras.models.load_model(\"answer_encoder_128\")\n",
        "question_encoder = keras.models.load_model(\"question_encoder_128\")\n",
        "print(\"Models are loaded.\")\n",
        "\n",
        "\n",
        "questions_answers = tf.data.Dataset.zip((questions, answers))\n",
        "#answers = questions_answers.map(lambda x, y : {\"text_input\": y})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5xjCndUG9bgw"
      },
      "outputs": [],
      "source": [
        "cached_answers = answers.batch(1300)\n",
        "answer_embeddings = answer_encoder.predict(\n",
        "    cached_answers,\n",
        "    verbose=1,\n",
        ")\n",
        "print(f\"answer embeddings shape: {answer_embeddings.shape}.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Evaluate the scores by calculating the similarity"
      ],
      "metadata": {
        "id": "arikiXZQz2JP"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f3f0VKbx-uvH"
      },
      "outputs": [],
      "source": [
        "def find_matches(answer_embeddings, questions, k=9, normalize=True):\n",
        "    # Get the embedding for the query.\n",
        "    query_embedding = question_encoder(tf.convert_to_tensor(questions))\n",
        "    # Normalize the query and the image embeddings.\n",
        "    if normalize:\n",
        "        image_embeddings = tf.math.l2_normalize(answer_embeddings, axis=1)\n",
        "        query_embedding = tf.math.l2_normalize(query_embedding, axis=1)\n",
        "    # Compute the dot product between the query and the image embeddings.\n",
        "    dot_similarity = tf.matmul(query_embedding, answer_embeddings, transpose_b=True)\n",
        "    # Retrieve top k indices.\n",
        "    results = tf.math.top_k(dot_similarity, k).indices.numpy()\n",
        "    scores = tf.math.top_k(dot_similarity, k).values.numpy()\n",
        "\n",
        "    # Return matching image paths.\n",
        "    return [[value for value in values] for values in scores], [[idx for idx in indices] for indices in results]\n",
        "    #return [[idx for idx in indices] for indices in results]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YU0nto5Y-sOA"
      },
      "outputs": [],
      "source": [
        "query = \"a family standing next to the ocean on a sandy beach with a surf board\"\n",
        "scores, matches = find_matches(answer_embeddings, [qid_to_text[8]], normalize=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y39xCQ6A91px"
      },
      "outputs": [],
      "source": [
        "print([qid_to_text[qid]  for qid, aid in qa_pairs][:1])\n",
        "print([qid for qid, aid in qa_pairs][:2])\n",
        "\n",
        "print([docid_to_text[aid]  for qid, aid in qa_pairs][:1])\n",
        "print([aid for qid, aid in qa_pairs][:1])\n",
        "\n",
        "print(qa_pairs[8])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dNx2j9HuPFDL"
      },
      "outputs": [],
      "source": [
        "[(eid_to_docid[m], m) for m in list(matches[0])]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uIgEWMagO8jx"
      },
      "outputs": [],
      "source": [
        "train_set[8]"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Metrics Evaluation"
      ],
      "metadata": {
        "id": "gdKXUDExwwlZ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ef8JX0V690Jw"
      },
      "outputs": [],
      "source": [
        "def run_twotower_scores(data):\n",
        "  ap = []\n",
        "  rr = []\n",
        "  cg = []\n",
        "  skipcnt = 0\n",
        "\n",
        "  #for i, seq in enumerate(tqdm(train_set)):\n",
        "  for j, seq in enumerate(data):\n",
        "    qid, ans_labels, _ , _ = seq[0], seq[1], seq[2], seq[3]\n",
        "    score, cand_ans = find_matches(answer_embeddings, [qid_to_text[qid]], normalize=True)\n",
        "    cands = []\n",
        "    cands_score = []\n",
        "    cnt = 0\n",
        "\n",
        "    for cand_anss, cand_score in zip(cand_ans[0], np.ravel(score).tolist()):\n",
        "      print(cand_anss)\n",
        "      cands.append(text_to_docid[cand_anss.decode(\"utf-8\")])\n",
        "      cnt += 1\n",
        "\n",
        "    max_width = -1\n",
        "    rr_ = 0\n",
        "    ap_ = 0.0\n",
        "    precision_ = 0.0\n",
        "    relcnt_ = 0\n",
        "\n",
        "    top_k = 10\n",
        "\n",
        "    # For each answer in the candidates\n",
        "    for i in range(cnt):\n",
        "      docid = cands[i]\n",
        "      #print(docid)\n",
        "      if docid in ans_labels and rr_ == 0:\n",
        "        rr_ = 1/(i+1)\n",
        "    \n",
        "    relscores = [1 if docid in ans_labels else 0 for docid in cands]\n",
        "    pos = [1.0/(i+1) for i in range(cnt)]\n",
        "    ap_ = average_precision_score(relscores,pos) if sum(relscores) != 0 else 0 \n",
        "\n",
        "    m = dict([(ai, 1/(i+1)) for i, ai in enumerate(ans_labels)])\n",
        "    if len(cands) > 0:\n",
        "      if len(ans_labels)==1:\n",
        "        cg_ = 1.0 if cands[0] in ans_labels else 0\n",
        "      else:\n",
        "        relscores = np.asarray([[ m[cands[i]] if m.get(cands[i]) else 0 for i in range(len(ans_labels))]])\n",
        "        pos = np.asarray([[1/(i+1) for i, ai in enumerate(ans_labels)]])\n",
        "        cg_ = ndcg_score(relscores, pos)\n",
        "    else:\n",
        "      cg_ = 0\n",
        "\n",
        "    ap.append(ap_)\n",
        "    rr.append(rr_)\n",
        "    cg.append(cg_)\n",
        "  return rr, ap, cg"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "90GVEXwZN-UQ"
      },
      "outputs": [],
      "source": [
        "mapped_answers = questions_answers.map(lambda x, y : {\"text_input\": y})\n",
        "l = list(mapped_answers)\n",
        "print(l[:3])\n",
        "cnt = 0\n",
        "for a in l:\n",
        "  if a['text_input'].numpy().decode('utf-8') == '':\n",
        "    cnt += 1\n",
        "\n",
        "print(cnt)\n",
        "\n",
        "\n",
        "eid_to_docid = dict([(i, text_to_docid[a['text_input'].numpy().decode('utf-8')])  for i, a in enumerate(l) if a['text_input'].numpy().decode('utf-8') != '' ])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PNlfjWsmOIQt"
      },
      "outputs": [],
      "source": [
        "for k, v in eid_to_docid.items():\n",
        "  if l[k]['text_input'].numpy().decode('utf-8') != docid_to_text[v]:\n",
        "    print(k, v)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Metrics Evaluation:"
      ],
      "metadata": {
        "id": "XCvUaqvJbwto"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l3X_HBfmxWd-"
      },
      "outputs": [],
      "source": [
        "def ABC(data):\n",
        "  ap = []\n",
        "  rr = []\n",
        "  cg = []\n",
        "  skipcnt = 0\n",
        "\n",
        "  for j, seq in enumerate(data):\n",
        "    qid, ans_labels, _ , _ = seq[0], seq[1], seq[2], seq[3]\n",
        "    score, cand_ans = find_matches(answer_embeddings, [qid_to_text[qid]], normalize=True)\n",
        "    cands = []\n",
        "    cands_score = []\n",
        "\n",
        "    for cand_, cand_score in zip(cand_ans[0], np.ravel(score).tolist()):\n",
        "      cands.append(eid_to_docid[cand_])\n",
        "      print('XXXX', docid_to_text[eid_to_docid[cand_]])\n",
        "      print('YYYY', l[cand_])\n",
        "      cands_score.append(cand_score)\n",
        "    print(cands)\n",
        "    print(ans_labels)\n",
        "\n",
        "\n",
        "def run_twotower_scores__(data):\n",
        "  ap = []\n",
        "  rr = []\n",
        "  cg = []\n",
        "  skipcnt = 0\n",
        "\n",
        "  for j, seq in enumerate(data):\n",
        "    qid, ans_labels, _ , _ = seq[0], seq[1], seq[2], seq[3]\n",
        "    score, cand_ans = find_matches(answer_embeddings, [qid_to_text[qid]], normalize=True)\n",
        "    cands = []\n",
        "    cands_score = []\n",
        "\n",
        "    for cand_, cand_score in zip(cand_ans[0], np.ravel(score).tolist()):\n",
        "      cands.append(eid_to_docid[cand_])\n",
        "      cands_score.append(cand_score)\n",
        "\n",
        "\n",
        "    max_width = -1\n",
        "    rr_ = 0\n",
        "    ap_ = 0.0\n",
        "    precision_ = 0.0\n",
        "    relcnt_ = 0\n",
        "\n",
        "    top_k = 10\n",
        "\n",
        "    for i in range(len(cands)):\n",
        "      docid = cands[i]\n",
        "      if docid in ans_labels and rr_ == 0:\n",
        "        rr_ = 100.0/(i+1)\n",
        "    \n",
        "    relscores = [1 if docid in ans_labels else 0 for docid in cands]\n",
        "    pos = [1.0/(i+1) for i in range(len(cands))]\n",
        "    ap_ = average_precision_score(relscores,pos)*100 if sum(relscores) != 0 else 0 \n",
        "\n",
        "    mcnt = max(len(cands), len(ans_labels))\n",
        "    m = dict([(ai, 1.0/(i+1)) for i, ai in enumerate(ans_labels)])\n",
        "\n",
        "    if len(ans_labels)==0 or len(cands)==0:\n",
        "      cg_ = 0.0\n",
        "    elif len(ans_labels)==1:\n",
        "      cg_ = 1.0 if len(cands)>0 and cands[0] in ans_labels else 0\n",
        "    elif len(cands) == 1:\n",
        "      cg_ = 1.0 if len(ans_labels) and cands[0] in ans_labels else 0\n",
        "    else:\n",
        "      relscores = np.asarray([[ m[cands[i]] if i<len(cands) and m.get(cands[i]) else 0 for i in range(mcnt)]])\n",
        "      pos = np.asarray([[1/(i+1) for i in range(mcnt)]])\n",
        "      cg_ = ndcg_score(relscores, pos)*100\n",
        "\n",
        "    ap.append(ap_)\n",
        "    rr.append(rr_)\n",
        "    cg.append(cg_)\n",
        "  return rr, ap, cg"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CkWLc1gJTXow"
      },
      "outputs": [],
      "source": [
        "ABC(train_set[:5])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nsq2xgbo9zLA"
      },
      "outputs": [],
      "source": [
        "rr, ap, cg = run_twotower_scores__(train_set)\n",
        "\n",
        "print('Mean Reciprocal Rank (MRR):', np.mean(rr))\n",
        "print('Mean average Precision (MAP)', np.mean(ap))\n",
        "print('Normalized Discounted Cumulative Gain (NDCG)', np.mean(cg))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3gl_enwX-Yq9"
      },
      "outputs": [],
      "source": [
        "rr[:5]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BL8aJv_49aUA"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "machine_shape": "hm",
      "name": "TOMIIModel.ipynb",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}