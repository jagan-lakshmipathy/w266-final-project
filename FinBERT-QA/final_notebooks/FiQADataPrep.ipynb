{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"FiQADataPrep.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyNC5qyIv2Yk+c6yFzfegUei"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"axRKm1qe0ltf","executionInfo":{"status":"ok","timestamp":1658939728938,"user_tz":240,"elapsed":17508,"user":{"displayName":"jagannathan Lakshmipathy","userId":"05639691877293412421"}},"outputId":"1b1509e7-7dac-438d-b5e7-08c13170852c"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /gdrive\n","/gdrive\n"]}],"source":["from google.colab import drive\n","drive.mount('/gdrive')\n","%cd /gdrive"]},{"cell_type":"code","source":["!pip install pyserini\n","!pip install faiss\n","\n","!apt install libomp-dev\n","!python -m pip install --upgrade faiss faiss-gpu\n","import faiss"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_6Vz5ArP7BzQ","executionInfo":{"status":"ok","timestamp":1658939869850,"user_tz":240,"elapsed":57465,"user":{"displayName":"jagannathan Lakshmipathy","userId":"05639691877293412421"}},"outputId":"3120bf54-a481-4352-9e96-4f1f75f9f671"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting pyserini\n","  Downloading pyserini-0.17.0-py3-none-any.whl (109.5 MB)\n","\u001b[K     |████████████████████████████████| 109.5 MB 26 kB/s \n","\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from pyserini) (4.64.0)\n","Collecting transformers>=4.6.0\n","  Downloading transformers-4.21.0-py3-none-any.whl (4.7 MB)\n","\u001b[K     |████████████████████████████████| 4.7 MB 45.3 MB/s \n","\u001b[?25hCollecting sentencepiece>=0.1.95\n","  Downloading sentencepiece-0.1.96-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n","\u001b[K     |████████████████████████████████| 1.2 MB 56.9 MB/s \n","\u001b[?25hCollecting pyjnius>=1.4.0\n","  Downloading pyjnius-1.4.2-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n","\u001b[K     |████████████████████████████████| 1.3 MB 43.5 MB/s \n","\u001b[?25hRequirement already satisfied: numpy>=1.18.1 in /usr/local/lib/python3.7/dist-packages (from pyserini) (1.21.6)\n","Requirement already satisfied: scikit-learn>=0.22.1 in /usr/local/lib/python3.7/dist-packages (from pyserini) (1.0.2)\n","Collecting onnxruntime>=1.8.1\n","  Downloading onnxruntime-1.12.0-cp37-cp37m-manylinux_2_27_x86_64.whl (4.9 MB)\n","\u001b[K     |████████████████████████████████| 4.9 MB 35.0 MB/s \n","\u001b[?25hRequirement already satisfied: Cython>=0.29.21 in /usr/local/lib/python3.7/dist-packages (from pyserini) (0.29.30)\n","Requirement already satisfied: pandas>=1.1.5 in /usr/local/lib/python3.7/dist-packages (from pyserini) (1.3.5)\n","Collecting lightgbm>=3.3.2\n","  Downloading lightgbm-3.3.2-py3-none-manylinux1_x86_64.whl (2.0 MB)\n","\u001b[K     |████████████████████████████████| 2.0 MB 34.1 MB/s \n","\u001b[?25hRequirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.7/dist-packages (from pyserini) (1.7.3)\n","Collecting nmslib>=2.1.1\n","  Downloading nmslib-2.1.1-cp37-cp37m-manylinux2010_x86_64.whl (13.5 MB)\n","\u001b[K     |████████████████████████████████| 13.5 MB 34.0 MB/s \n","\u001b[?25hRequirement already satisfied: spacy>=3.2.1 in /usr/local/lib/python3.7/dist-packages (from pyserini) (3.4.0)\n","Requirement already satisfied: wheel in /usr/local/lib/python3.7/dist-packages (from lightgbm>=3.3.2->pyserini) (0.37.1)\n","Collecting pybind11<2.6.2\n","  Downloading pybind11-2.6.1-py2.py3-none-any.whl (188 kB)\n","\u001b[K     |████████████████████████████████| 188 kB 36.0 MB/s \n","\u001b[?25hRequirement already satisfied: psutil in /usr/local/lib/python3.7/dist-packages (from nmslib>=2.1.1->pyserini) (5.4.8)\n","Requirement already satisfied: protobuf in /usr/local/lib/python3.7/dist-packages (from onnxruntime>=1.8.1->pyserini) (3.17.3)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from onnxruntime>=1.8.1->pyserini) (21.3)\n","Collecting coloredlogs\n","  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n","\u001b[K     |████████████████████████████████| 46 kB 3.5 MB/s \n","\u001b[?25hRequirement already satisfied: sympy in /usr/local/lib/python3.7/dist-packages (from onnxruntime>=1.8.1->pyserini) (1.7.1)\n","Requirement already satisfied: flatbuffers in /usr/local/lib/python3.7/dist-packages (from onnxruntime>=1.8.1->pyserini) (2.0)\n","Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=1.1.5->pyserini) (2.8.2)\n","Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=1.1.5->pyserini) (2022.1)\n","Requirement already satisfied: six>=1.7.0 in /usr/local/lib/python3.7/dist-packages (from pyjnius>=1.4.0->pyserini) (1.15.0)\n","Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.22.1->pyserini) (1.1.0)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.22.1->pyserini) (3.1.0)\n","Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.9 in /usr/local/lib/python3.7/dist-packages (from spacy>=3.2.1->pyserini) (3.0.9)\n","Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=3.2.1->pyserini) (2.0.6)\n","Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.10.0,>=1.7.4 in /usr/local/lib/python3.7/dist-packages (from spacy>=3.2.1->pyserini) (1.9.1)\n","Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.7/dist-packages (from spacy>=3.2.1->pyserini) (2.0.7)\n","Requirement already satisfied: typing-extensions<4.2.0,>=3.7.4 in /usr/local/lib/python3.7/dist-packages (from spacy>=3.2.1->pyserini) (4.1.1)\n","Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=3.2.1->pyserini) (3.3.0)\n","Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=3.2.1->pyserini) (3.0.6)\n","Requirement already satisfied: thinc<8.2.0,>=8.1.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=3.2.1->pyserini) (8.1.0)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy>=3.2.1->pyserini) (57.4.0)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from spacy>=3.2.1->pyserini) (2.11.3)\n","Requirement already satisfied: typer<0.5.0,>=0.3.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=3.2.1->pyserini) (0.4.2)\n","Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=3.2.1->pyserini) (2.23.0)\n","Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.7/dist-packages (from spacy>=3.2.1->pyserini) (2.4.4)\n","Requirement already satisfied: wasabi<1.1.0,>=0.9.1 in /usr/local/lib/python3.7/dist-packages (from spacy>=3.2.1->pyserini) (0.9.1)\n","Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=3.2.1->pyserini) (1.0.7)\n","Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=3.2.1->pyserini) (1.0.3)\n","Requirement already satisfied: pathy>=0.3.5 in /usr/local/lib/python3.7/dist-packages (from spacy>=3.2.1->pyserini) (0.6.2)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from catalogue<2.1.0,>=2.0.6->spacy>=3.2.1->pyserini) (3.8.1)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->onnxruntime>=1.8.1->pyserini) (3.0.9)\n","Requirement already satisfied: smart-open<6.0.0,>=5.2.1 in /usr/local/lib/python3.7/dist-packages (from pathy>=0.3.5->spacy>=3.2.1->pyserini) (5.2.1)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=3.2.1->pyserini) (2022.6.15)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=3.2.1->pyserini) (3.0.4)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=3.2.1->pyserini) (2.10)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=3.2.1->pyserini) (1.24.3)\n","Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.7/dist-packages (from thinc<8.2.0,>=8.1.0->spacy>=3.2.1->pyserini) (0.7.8)\n","Collecting pyyaml>=5.1\n","  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n","\u001b[K     |████████████████████████████████| 596 kB 53.2 MB/s \n","\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers>=4.6.0->pyserini) (2022.6.2)\n","Collecting huggingface-hub<1.0,>=0.1.0\n","  Downloading huggingface_hub-0.8.1-py3-none-any.whl (101 kB)\n","\u001b[K     |████████████████████████████████| 101 kB 6.2 MB/s \n","\u001b[?25hRequirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers>=4.6.0->pyserini) (4.12.0)\n","Collecting tokenizers!=0.11.3,<0.13,>=0.11.1\n","  Downloading tokenizers-0.12.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.6 MB)\n","\u001b[K     |████████████████████████████████| 6.6 MB 41.3 MB/s \n","\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers>=4.6.0->pyserini) (3.7.1)\n","Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.7/dist-packages (from typer<0.5.0,>=0.3.0->spacy>=3.2.1->pyserini) (7.1.2)\n","Collecting humanfriendly>=9.1\n","  Downloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n","\u001b[K     |████████████████████████████████| 86 kB 5.8 MB/s \n","\u001b[?25hRequirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->spacy>=3.2.1->pyserini) (2.0.1)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.7/dist-packages (from sympy->onnxruntime>=1.8.1->pyserini) (1.2.1)\n","Installing collected packages: pyyaml, humanfriendly, tokenizers, pybind11, huggingface-hub, coloredlogs, transformers, sentencepiece, pyjnius, onnxruntime, nmslib, lightgbm, pyserini\n","  Attempting uninstall: pyyaml\n","    Found existing installation: PyYAML 3.13\n","    Uninstalling PyYAML-3.13:\n","      Successfully uninstalled PyYAML-3.13\n","  Attempting uninstall: lightgbm\n","    Found existing installation: lightgbm 2.2.3\n","    Uninstalling lightgbm-2.2.3:\n","      Successfully uninstalled lightgbm-2.2.3\n","Successfully installed coloredlogs-15.0.1 huggingface-hub-0.8.1 humanfriendly-10.0 lightgbm-3.3.2 nmslib-2.1.1 onnxruntime-1.12.0 pybind11-2.6.1 pyjnius-1.4.2 pyserini-0.17.0 pyyaml-6.0 sentencepiece-0.1.96 tokenizers-0.12.1 transformers-4.21.0\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting faiss\n","  Downloading faiss-1.5.3-cp37-cp37m-manylinux1_x86_64.whl (4.7 MB)\n","\u001b[K     |████████████████████████████████| 4.7 MB 8.8 MB/s \n","\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from faiss) (1.21.6)\n","Installing collected packages: faiss\n","Successfully installed faiss-1.5.3\n","Reading package lists... Done\n","Building dependency tree       \n","Reading state information... Done\n","The following package was automatically installed and is no longer required:\n","  libnvidia-common-460\n","Use 'apt autoremove' to remove it.\n","The following additional packages will be installed:\n","  libomp5\n","Suggested packages:\n","  libomp-doc\n","The following NEW packages will be installed:\n","  libomp-dev libomp5\n","0 upgraded, 2 newly installed, 0 to remove and 49 not upgraded.\n","Need to get 239 kB of archives.\n","After this operation, 804 kB of additional disk space will be used.\n","Get:1 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libomp5 amd64 5.0.1-1 [234 kB]\n","Get:2 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libomp-dev amd64 5.0.1-1 [5,088 B]\n","Fetched 239 kB in 1s (455 kB/s)\n","Selecting previously unselected package libomp5:amd64.\n","(Reading database ... 155653 files and directories currently installed.)\n","Preparing to unpack .../libomp5_5.0.1-1_amd64.deb ...\n","Unpacking libomp5:amd64 (5.0.1-1) ...\n","Selecting previously unselected package libomp-dev.\n","Preparing to unpack .../libomp-dev_5.0.1-1_amd64.deb ...\n","Unpacking libomp-dev (5.0.1-1) ...\n","Setting up libomp5:amd64 (5.0.1-1) ...\n","Setting up libomp-dev (5.0.1-1) ...\n","Processing triggers for libc-bin (2.27-3ubuntu1.3) ...\n","/sbin/ldconfig.real: /usr/local/lib/python3.7/dist-packages/ideep4py/lib/libmkldnn.so.0 is not a symbolic link\n","\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: faiss in /usr/local/lib/python3.7/dist-packages (1.5.3)\n","Collecting faiss-gpu\n","  Downloading faiss_gpu-1.7.2-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (85.5 MB)\n","\u001b[K     |████████████████████████████████| 85.5 MB 115 kB/s \n","\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from faiss) (1.21.6)\n","Installing collected packages: faiss-gpu\n","Successfully installed faiss-gpu-1.7.2\n"]}]},{"cell_type":"code","source":["import pandas as pd\n","import regex as re\n","import csv\n","from itertools import islice\n","import pickle\n","import numpy as np\n","import json\n","import os\n","import sys\n","import argparse\n","from pathlib import Path\n","from sklearn.model_selection import train_test_split\n","from pyserini.search import SimpleSearcher"],"metadata":{"id":"ifSvpkjC6kXG"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["%cd /gdrive/MyDrive/nlp-yuan_code/FinBERT-QA\n","from src.process_data import *"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"V9pkQfTrh82v","executionInfo":{"status":"ok","timestamp":1658940026112,"user_tz":240,"elapsed":3097,"user":{"displayName":"jagannathan Lakshmipathy","userId":"05639691877293412421"}},"outputId":"5eba2034-ed66-4978-87a6-2efb85fd122a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/gdrive/MyDrive/nlp-yuan_code/FinBERT-QA\n"]},{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Unzipping tokenizers/punkt.zip.\n"]}]},{"cell_type":"code","source":["RO_FiQA_DATA_PATH = '/gdrive/MyDrive/nlp-data/nlp-qa-datasets/FiQA/FiQA_train_task2/'\n","RO_FIQA_INDEX = \"/gdrive/MyDrive/nlp-yuan_code/FinBERT-QA/retriever/lucene-index-fiqa/\"\n","WR_PICKLE_DATA = '/gdrive/MyDrive/nlp-yuan_code/FinBERT-QA/data/data_pickle/'\n","WR_PICKLE_TRANSIENT_DATA = '/gdrive/MyDrive/nlp-yuan_code/FinBERT-QA/data/data_pickle/transient/'\n","WR_INTERIM_DATA = '/gdrive/MyDrive/nlp-yuan_code/FinBERT-QA/data/interim/'"],"metadata":{"id":"boJIwot1ebKQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Document id and Answer text\n","collection = load_answers_to_df(RO_FiQA_DATA_PATH+\"FiQA_train_doc_final.tsv\")\n","# Question id and Question text\n","queries = load_questions_to_df(RO_FiQA_DATA_PATH+\"FiQA_train_question_final.tsv\")\n","# Question id and Answer id pair\n","qid_docid = load_qid_docid_to_df(RO_FiQA_DATA_PATH+\"FiQA_train_question_doc_final.tsv\")"],"metadata":{"id":"oRnDxVG9cAek"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def split_label(qid_docid):\n","    \"\"\"\n","    Split question answer pairs into train, test, validation sets.\n","\n","    Returns:\n","        train_label: Dictonary\n","            key - question id\n","            value - list of relevant docids\n","        test_label: Dictonary\n","            key - question id\n","            value - list of relevant docids\n","        valid_label: Dictonary\n","            key - question id\n","            value - list of relevant docids\n","    ----------\n","    Arguments:\n","        qid_docid: Dataframe containing the question id and relevant docids\n","    \"\"\"\n","    # Group the answers for each question into a list\n","    qid_docid = qid_docid.groupby(['qid']).agg(lambda x: tuple(x)).applymap(list).reset_index()\n","    # Split data\n","    train_set, test_set = train_test_split(qid_docid, test_size=0.05)\n","    #train_set, valid_set = train_test_split(train, test_size=0.1)\n","    # Expand the list of docids into individual rows to represent a single sample\n","    train_data = train_set.explode('docid')\n","    test_data = test_set.explode('docid')\n","    #valid_data = valid_set.explode('docid')\n","\n","    # Convert data into dictionary - key: qid, value: list of relevant docid\n","    train_label = label_to_dict(train_data)\n","    test_label = label_to_dict(test_data)\n","    #valid_label = label_to_dict(valid_data)\n","\n","    return train_label, test_label\n","\n","def split_question(train_label, test_label, queries):\n","    \"\"\"\n","    Split questions into train, test, validation sets.\n","\n","    Returns:\n","        train_questions: Dataframe with qids\n","        test_questions: Dataframe with qids\n","        valid_questions: Dataframe with qids\n","    ----------\n","    Arguments:\n","        train_label: Dictionary contraining qid and list of relevant docid\n","        test_label: Dictionary contraining qid and list of relevant docid\n","        valid_label: Dictionary contraining qid and list of relevant docid\n","        queries: Dataframe containing the question id and question text\n","    \"\"\"\n","    # Get a list of question ids\n","    train_q = list(train_label.keys())\n","    test_q = list(test_label.keys())\n","\n","    # Split question dataframe into train, test, valid set\n","    train_questions = queries[queries['qid'].isin(train_q)]\n","    test_questions = queries[queries['qid'].isin(test_q)]\n","\n","    return train_questions, test_questions\n","\n","def create_dataset(question_df, labels, cands_size):\n","    \"\"\"Retrieves the top-k candidate answers for a question and\n","    creates a list of lists of the dataset containing the question id,\n","    list of relevant answer ids, and the list of answer candidates\n","\n","    Returns:\n","        dataset: list of list in the form [qid, [pos ans], [ans candidates]]\n","    ----------\n","    Arguments:\n","        question_df: Dataframe containing the qid and question text\n","        labels: Dictonary containing the qid to text map\n","        cands_size: int - number of candidates to retrieve\n","    \"\"\"\n","    dataset = []\n","    # Calls retriever\n","    searcher = SimpleSearcher(RO_FIQA_INDEX)\n","    # For each question\n","    for i, row in question_df.iterrows():\n","        qid = row['qid']\n","        tmp = []\n","        # Append qid\n","        tmp.append(qid)\n","        # Append list of relevant docs\n","        tmp.append(labels[qid])\n","        # Retrieves answer candidates\n","        cands = []\n","        cands_score = []\n","        query = row['question']\n","        query = re.sub('[£€§]', '', query)\n","        hits = searcher.search(query, k=cands_size)\n","\n","        for docid in range(0, len(hits)):\n","            cands.append(int(hits[docid].docid))\n","            cands_score.append(hits[docid].score)\n","        # Append candidate answers\n","        tmp.append(cands)\n","        tmp.append(cands_score)\n","        dataset.append(tmp)\n","\n","    return dataset\n","\n","def get_dataset(query_path, labels_path, cands_size):\n","    \"\"\"Splits the dataset into train, validation, and test set and creates\n","    the dataset form for training, validation, and testing.\n","\n","    Returns:\n","        train_set: list of list in the form [qid, [pos ans], [ans candidates]]\n","        valid_set: list of list in the form [qid, [pos ans], [ans candidates]]\n","        test_set: list of list in the form [qid, [pos ans], [ans candidates]]\n","    ----------\n","    Arguments:\n","        query_path: str - path containing a list of qid and questions\n","        labels_path: str - path containing a list of qid and relevant docid\n","        cands_size: int - number of candidates to retrieve\n","    \"\"\"\n","    # Question id and Question text\n","    queries = load_questions_to_df(query_path)\n","    # Question id and Answer id pair\n","    qid_docid = load_qid_docid_to_df(labels_path)\n","    # qid to docid label map\n","    labels = label_to_dict(qid_docid)\n","    train_label, test_label = split_label(qid_docid)\n","    # Split Questions\n","    train_questions, test_questions = split_question(train_label, test_label, queries)\n","\n","    print(\"\\nGenerating training set...\\n\")\n","    train_set = create_dataset(train_questions, labels, cands_size)\n","    print(\"Generating test set...\\n\")\n","    test_set = create_dataset(test_questions, labels, cands_size)\n","\n","    return train_set, test_set"],"metadata":{"id":"Mi83mMEpb2Kr"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["query_path = RO_FiQA_DATA_PATH + \"FiQA_train_question_final.tsv\"\n","labels_path = RO_FiQA_DATA_PATH + \"FiQA_train_question_doc_final.tsv\"\n","train_set, test_set = get_dataset(query_path, labels_path, 50)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5SaWNGEqbRRM","executionInfo":{"status":"ok","timestamp":1658940139412,"user_tz":240,"elapsed":72494,"user":{"displayName":"jagannathan Lakshmipathy","userId":"05639691877293412421"}},"outputId":"2b077b5f-ff14-4797-ea31-434ff6b23793"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Generating training set...\n","\n","SimpleSearcher class has been deprecated, please use LuceneSearcher from pyserini.search.lucene instead\n","Generating test set...\n","\n","SimpleSearcher class has been deprecated, please use LuceneSearcher from pyserini.search.lucene instead\n"]}]},{"cell_type":"code","source":["empty_docs, empty_id = get_empty_docs(collection)\n","# Remove empty answers from collection of answers\n","collection_cleaned = collection.drop(empty_id)\n","# Remove empty answers from qa pairs\n","qid_docid = qid_docid[~qid_docid['docid'].isin(empty_docs)]\n","\n","print(\"Number of answers after cleaning: {}\".format(len(collection_cleaned)))\n","print(\"Number of QA pairs after cleaning: {}\".format(len(qid_docid)))\n","\n","processed_answers = process_answers(collection_cleaned)\n","processed_questions = process_questions(queries)\n","\n","word2index, word2count = create_vocab(processed_answers, processed_questions)\n","\n","print(\"Vocab size: {}\".format(len(word2index)))\n","print(\"Top {} common words: {}\".format(35, Counter(word2count).most_common(35)))\n","\n","qid_to_text, docid_to_text = id_to_text(collection, queries)\n","qid_to_tokenized_text, docid_to_tokenized_text = id_to_tokenized_text(processed_answers, processed_questions)\n","text_to_docid = dict([ (docid_to_text[k], k) for k in docid_to_text])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WQUWPaFgkuIS","executionInfo":{"status":"ok","timestamp":1658941064526,"user_tz":240,"elapsed":24218,"user":{"displayName":"jagannathan Lakshmipathy","userId":"05639691877293412421"}},"outputId":"c1098e94-6c93-48d8-9874-b711c055b06d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Number of answers after cleaning: 57600\n","Number of QA pairs after cleaning: 17072\n","Vocab size: 85034\n","Top 35 common words: [('the', 371203), ('to', 233559), ('a', 201620), ('you', 166702), ('and', 163066), ('of', 157574), ('is', 129894), ('in', 120019), ('that', 111416), ('for', 89366), ('it', 83822), ('i', 74100), ('your', 68153), ('are', 67255), ('if', 60689), ('be', 59266), ('on', 58382), ('have', 55754), ('as', 50088), ('this', 49868), ('not', 49227), ('or', 46080), ('with', 45894), ('they', 44485), ('but', 41690), ('can', 38863), ('will', 36865), ('at', 35548), ('an', 31392), ('money', 31003), ('so', 29980), ('$', 29096), ('would', 28750), ('from', 28582), ('more', 27378)]\n"]}]},{"cell_type":"code","source":["print(len(train_set), len(test_set))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gkSYpceHbVa-","executionInfo":{"status":"ok","timestamp":1658941069388,"user_tz":240,"elapsed":154,"user":{"displayName":"jagannathan Lakshmipathy","userId":"05639691877293412421"}},"outputId":"eace8f6e-82dd-4444-e72d-a3d71c0dcdf3"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["6315 333\n"]}]},{"cell_type":"markdown","source":["Save the following:\n","1. Save train_set, and test_set\n","2. Save qid_to_text, docid_to_text\n","3. save text_to_docid"],"metadata":{"id":"35SImqdqd_XT"}},{"cell_type":"code","source":["# define dictionary\n","save_pickle(WR_INTERIM_DATA + \"train_set.pickle\", train_set)\n","save_pickle(WR_INTERIM_DATA + \"test_set.pickle\", test_set)\n","save_pickle(WR_INTERIM_DATA + \"qid_to_text.pickle\", qid_to_text)\n","save_pickle(WR_INTERIM_DATA + \"docid_to_text.pickle\", docid_to_text)\n","save_pickle(WR_INTERIM_DATA + \"text_to_docid.pickle\", text_to_docid)"],"metadata":{"id":"qxsA81FPd82l"},"execution_count":null,"outputs":[]}]}