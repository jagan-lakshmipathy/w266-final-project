{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sT9W_F7dZo-B",
        "outputId": "c1643be2-5f33-4608-b6d9-a6bc9dd663fe"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /gdrive\n",
            "/gdrive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/gdrive')\n",
        "%cd /gdrive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hqbKb2IfaMev",
        "outputId": "2c32350d-b955-4601-ff3c-787a3f68eee2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/gdrive/MyDrive/w266-final-project-master/w266-final-project-master/FinBERT-QA\n"
          ]
        }
      ],
      "source": [
        "# %cd /gdrive/MyDrive/nlp-yuan_code/FinBERT-QA\n",
        "%cd /gdrive/MyDrive/w266-final-project-master/w266-final-project-master/FinBERT-QA"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Setting up path to the data"
      ],
      "metadata": {
        "id": "-XyUJwVOUt-Y"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TZqD1HlyamWD"
      },
      "outputs": [],
      "source": [
        "# data_path = '/gdrive/MyDrive/nlp-data/nlp-qa-datasets/FiQA/FiQA_train_task2/'\n",
        "data_path = '/gdrive/MyDrive/w266-final-project-master/w266-final-project-master/FinBERT-QA/data/raw/'\n",
        "# Document id and Answer text\n",
        "collection = load_answers_to_df(data_path+\"FiQA_train_doc_final.tsv\")\n",
        "# Question id and Question text\n",
        "queries = load_questions_to_df(data_path+\"FiQA_train_question_final.tsv\")\n",
        "# Question id and Answer id pair\n",
        "qid_docid = load_qid_docid_to_df(data_path+\"FiQA_train_question_doc_final.tsv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Install package for answer retrieval system"
      ],
      "metadata": {
        "id": "XYGc6upFVEGz"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xg9tYn8QfLOE",
        "outputId": "588d1966-5a5c-44af-d0f6-2cc4a46116ee"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pyserini\n",
            "  Downloading pyserini-0.17.0-py3-none-any.whl (109.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 109.5 MB 38 kB/s \n",
            "\u001b[?25hCollecting pyjnius>=1.4.0\n",
            "  Downloading pyjnius-1.4.2-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.3 MB 51.9 MB/s \n",
            "\u001b[?25hCollecting nmslib>=2.1.1\n",
            "  Downloading nmslib-2.1.1-cp37-cp37m-manylinux2010_x86_64.whl (13.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 13.5 MB 57.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.7/dist-packages (from pyserini) (1.7.3)\n",
            "Collecting lightgbm>=3.3.2\n",
            "  Downloading lightgbm-3.3.2-py3-none-manylinux1_x86_64.whl (2.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.0 MB 43.5 MB/s \n",
            "\u001b[?25hCollecting transformers>=4.6.0\n",
            "  Downloading transformers-4.21.0-py3-none-any.whl (4.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.7 MB 59.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: scikit-learn>=0.22.1 in /usr/local/lib/python3.7/dist-packages (from pyserini) (1.0.2)\n",
            "Collecting onnxruntime>=1.8.1\n",
            "  Downloading onnxruntime-1.12.0-cp37-cp37m-manylinux_2_27_x86_64.whl (4.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.9 MB 66.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: spacy>=3.2.1 in /usr/local/lib/python3.7/dist-packages (from pyserini) (3.4.1)\n",
            "Requirement already satisfied: pandas>=1.1.5 in /usr/local/lib/python3.7/dist-packages (from pyserini) (1.3.5)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from pyserini) (4.64.0)\n",
            "Requirement already satisfied: numpy>=1.18.1 in /usr/local/lib/python3.7/dist-packages (from pyserini) (1.21.6)\n",
            "Requirement already satisfied: Cython>=0.29.21 in /usr/local/lib/python3.7/dist-packages (from pyserini) (0.29.30)\n",
            "Collecting sentencepiece>=0.1.95\n",
            "  Downloading sentencepiece-0.1.96-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.2 MB 70.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: wheel in /usr/local/lib/python3.7/dist-packages (from lightgbm>=3.3.2->pyserini) (0.37.1)\n",
            "Collecting pybind11<2.6.2\n",
            "  Downloading pybind11-2.6.1-py2.py3-none-any.whl (188 kB)\n",
            "\u001b[K     |████████████████████████████████| 188 kB 68.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: psutil in /usr/local/lib/python3.7/dist-packages (from nmslib>=2.1.1->pyserini) (5.4.8)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.7/dist-packages (from onnxruntime>=1.8.1->pyserini) (3.17.3)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.7/dist-packages (from onnxruntime>=1.8.1->pyserini) (2.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from onnxruntime>=1.8.1->pyserini) (21.3)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.7/dist-packages (from onnxruntime>=1.8.1->pyserini) (1.7.1)\n",
            "Collecting coloredlogs\n",
            "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
            "\u001b[K     |████████████████████████████████| 46 kB 4.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=1.1.5->pyserini) (2022.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=1.1.5->pyserini) (2.8.2)\n",
            "Requirement already satisfied: six>=1.7.0 in /usr/local/lib/python3.7/dist-packages (from pyjnius>=1.4.0->pyserini) (1.15.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.22.1->pyserini) (3.1.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.22.1->pyserini) (1.1.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from spacy>=3.2.1->pyserini) (2.11.3)\n",
            "Requirement already satisfied: typer<0.5.0,>=0.3.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=3.2.1->pyserini) (0.4.2)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=3.2.1->pyserini) (2.23.0)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=3.2.1->pyserini) (1.0.7)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.7/dist-packages (from spacy>=3.2.1->pyserini) (2.0.8)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=3.2.1->pyserini) (1.0.3)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=3.2.1->pyserini) (3.0.6)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy>=3.2.1->pyserini) (57.4.0)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.7/dist-packages (from spacy>=3.2.1->pyserini) (2.4.4)\n",
            "Requirement already satisfied: thinc<8.2.0,>=8.1.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=3.2.1->pyserini) (8.1.0)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=3.2.1->pyserini) (3.3.0)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.9.1 in /usr/local/lib/python3.7/dist-packages (from spacy>=3.2.1->pyserini) (0.9.1)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=3.2.1->pyserini) (2.0.6)\n",
            "Requirement already satisfied: pathy>=0.3.5 in /usr/local/lib/python3.7/dist-packages (from spacy>=3.2.1->pyserini) (0.6.2)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.9 in /usr/local/lib/python3.7/dist-packages (from spacy>=3.2.1->pyserini) (3.0.9)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.10.0,>=1.7.4 in /usr/local/lib/python3.7/dist-packages (from spacy>=3.2.1->pyserini) (1.9.1)\n",
            "Requirement already satisfied: typing-extensions<4.2.0,>=3.7.4 in /usr/local/lib/python3.7/dist-packages (from spacy>=3.2.1->pyserini) (4.1.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from catalogue<2.1.0,>=2.0.6->spacy>=3.2.1->pyserini) (3.8.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->onnxruntime>=1.8.1->pyserini) (3.0.9)\n",
            "Requirement already satisfied: smart-open<6.0.0,>=5.2.1 in /usr/local/lib/python3.7/dist-packages (from pathy>=0.3.5->spacy>=3.2.1->pyserini) (5.2.1)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=3.2.1->pyserini) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=3.2.1->pyserini) (2022.6.15)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=3.2.1->pyserini) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=3.2.1->pyserini) (1.24.3)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.7/dist-packages (from thinc<8.2.0,>=8.1.0->spacy>=3.2.1->pyserini) (0.7.8)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers>=4.6.0->pyserini) (3.7.1)\n",
            "Collecting pyyaml>=5.1\n",
            "  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n",
            "\u001b[K     |████████████████████████████████| 596 kB 59.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers>=4.6.0->pyserini) (2022.6.2)\n",
            "Collecting tokenizers!=0.11.3,<0.13,>=0.11.1\n",
            "  Downloading tokenizers-0.12.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 6.6 MB 50.2 MB/s \n",
            "\u001b[?25hCollecting huggingface-hub<1.0,>=0.1.0\n",
            "  Downloading huggingface_hub-0.8.1-py3-none-any.whl (101 kB)\n",
            "\u001b[K     |████████████████████████████████| 101 kB 12.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers>=4.6.0->pyserini) (4.12.0)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.7/dist-packages (from typer<0.5.0,>=0.3.0->spacy>=3.2.1->pyserini) (7.1.2)\n",
            "Collecting humanfriendly>=9.1\n",
            "  Downloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
            "\u001b[K     |████████████████████████████████| 86 kB 5.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->spacy>=3.2.1->pyserini) (2.0.1)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.7/dist-packages (from sympy->onnxruntime>=1.8.1->pyserini) (1.2.1)\n",
            "Installing collected packages: pyyaml, humanfriendly, tokenizers, pybind11, huggingface-hub, coloredlogs, transformers, sentencepiece, pyjnius, onnxruntime, nmslib, lightgbm, pyserini\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "  Attempting uninstall: lightgbm\n",
            "    Found existing installation: lightgbm 2.2.3\n",
            "    Uninstalling lightgbm-2.2.3:\n",
            "      Successfully uninstalled lightgbm-2.2.3\n",
            "Successfully installed coloredlogs-15.0.1 huggingface-hub-0.8.1 humanfriendly-10.0 lightgbm-3.3.2 nmslib-2.1.1 onnxruntime-1.12.0 pybind11-2.6.1 pyjnius-1.4.2 pyserini-0.17.0 pyyaml-6.0 sentencepiece-0.1.96 tokenizers-0.12.1 transformers-4.21.0\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting faiss\n",
            "  Downloading faiss-1.5.3-cp37-cp37m-manylinux1_x86_64.whl (4.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.7 MB 14.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from faiss) (1.21.6)\n",
            "Installing collected packages: faiss\n",
            "Successfully installed faiss-1.5.3\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-460\n",
            "Use 'apt autoremove' to remove it.\n",
            "The following additional packages will be installed:\n",
            "  libomp5\n",
            "Suggested packages:\n",
            "  libomp-doc\n",
            "The following NEW packages will be installed:\n",
            "  libomp-dev libomp5\n",
            "0 upgraded, 2 newly installed, 0 to remove and 49 not upgraded.\n",
            "Need to get 239 kB of archives.\n",
            "After this operation, 804 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libomp5 amd64 5.0.1-1 [234 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libomp-dev amd64 5.0.1-1 [5,088 B]\n",
            "Fetched 239 kB in 0s (2,998 kB/s)\n",
            "Selecting previously unselected package libomp5:amd64.\n",
            "(Reading database ... 155653 files and directories currently installed.)\n",
            "Preparing to unpack .../libomp5_5.0.1-1_amd64.deb ...\n",
            "Unpacking libomp5:amd64 (5.0.1-1) ...\n",
            "Selecting previously unselected package libomp-dev.\n",
            "Preparing to unpack .../libomp-dev_5.0.1-1_amd64.deb ...\n",
            "Unpacking libomp-dev (5.0.1-1) ...\n",
            "Setting up libomp5:amd64 (5.0.1-1) ...\n",
            "Setting up libomp-dev (5.0.1-1) ...\n",
            "Processing triggers for libc-bin (2.27-3ubuntu1.3) ...\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: faiss in /usr/local/lib/python3.7/dist-packages (1.5.3)\n",
            "Collecting faiss-gpu\n",
            "  Downloading faiss_gpu-1.7.2-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (85.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 85.5 MB 36.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from faiss) (1.21.6)\n",
            "Installing collected packages: faiss-gpu\n",
            "Successfully installed faiss-gpu-1.7.2\n"
          ]
        }
      ],
      "source": [
        "!pip install pyserini\n",
        "!pip install faiss\n",
        "\n",
        "!apt install libomp-dev\n",
        "!python -m pip install --upgrade faiss faiss-gpu\n",
        "import faiss"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pydot --quiet\n",
        "!pip install gensim==3.8.3 --quiet\n",
        "!pip install tensorflow-datasets --quiet\n",
        "!pip install -U tensorflow-text==2.8.2 --quiet\n",
        "!pip install transformers --quiet\n",
        "!pip install pydot --quiet"
      ],
      "metadata": {
        "id": "mhH_k5sneHQh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Import packages"
      ],
      "metadata": {
        "id": "aYquQydaVhN-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NlnN_LjggEI4"
      },
      "outputs": [],
      "source": [
        "#from pyserini.search import SimpleSearcher\n",
        "\n",
        "import pandas as pd\n",
        "import regex as re\n",
        "import csv\n",
        "from itertools import islice\n",
        "import pickle\n",
        "import numpy as np\n",
        "import json\n",
        "import os\n",
        "import sys\n",
        "import argparse\n",
        "from pathlib import Path\n",
        "from sklearn.model_selection import train_test_split\n",
        "from pathlib import Path\n",
        "# os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-11-openjdk-amd64\"\n",
        "#from pyserini.search as pysearch\n",
        "\n",
        "from pyserini.search import SimpleSearcher\n",
        "from src.utils import *\n",
        "from statistics import mean \n",
        "from src.process_data import *"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "from tensorflow.keras.layers import Embedding, Input, Dense, Lambda\n",
        "from tensorflow.keras.models import Model\n",
        "import tensorflow.keras.backend as K\n",
        "import tensorflow_datasets as tfds\n",
        "import tensorflow_text as tf_text\n",
        "\n",
        "from transformers import BertTokenizer, TFBertModel\n",
        "\n",
        "\n",
        "import sklearn as sk\n",
        "import nltk\n",
        "from nltk.corpus import reuters\n",
        "from nltk.data import find\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import re"
      ],
      "metadata": {
        "id": "Mi4qqZW7eT-R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Parameters for model testing\n",
        "max_length=256\n",
        "top_k = 2\n",
        "labels_count = 3"
      ],
      "metadata": {
        "id": "Awc3CeyTURmV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Prepare the dataset for training, validation and test "
      ],
      "metadata": {
        "id": "7R0lLTQfZppp"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R9YJhzHufmNj"
      },
      "outputs": [],
      "source": [
        "fiqa_index = \"/gdrive/MyDrive//w266-final-project-master/w266-final-project-master/FinBERT-QA/retriever/lucene-index-fiqa/\"\n",
        "\n",
        "\n",
        "def split_label(qid_docid):\n",
        "    \"\"\"\n",
        "    Split question answer pairs into train, test, validation sets.\n",
        "\n",
        "    Returns:\n",
        "        train_label: Dictonary\n",
        "            key - question id\n",
        "            value - list of relevant docids\n",
        "        test_label: Dictonary\n",
        "            key - question id\n",
        "            value - list of relevant docids\n",
        "        valid_label: Dictonary\n",
        "            key - question id\n",
        "            value - list of relevant docids\n",
        "    ----------\n",
        "    Arguments:\n",
        "        qid_docid: Dataframe containing the question id and relevant docids\n",
        "    \"\"\"\n",
        "    # Group the answers for each question into a list\n",
        "    qid_docid = qid_docid.groupby(['qid']).agg(lambda x: tuple(x)).applymap(list).reset_index()\n",
        "    # Split data\n",
        "    train, test_set = train_test_split(qid_docid, test_size=0.05)\n",
        "    train_set, valid_set = train_test_split(train, test_size=0.1)\n",
        "    # Expand the list of docids into individual rows to represent a single sample\n",
        "    train_data = train_set.explode('docid')\n",
        "    test_data = test_set.explode('docid')\n",
        "    valid_data = valid_set.explode('docid')\n",
        "\n",
        "    # Convert data into dictionary - key: qid, value: list of relevant docid\n",
        "    train_label = label_to_dict(train_data)\n",
        "    test_label = label_to_dict(test_data)\n",
        "    valid_label = label_to_dict(valid_data)\n",
        "\n",
        "    return train_label, test_label, valid_label\n",
        "\n",
        "def split_question(train_label, test_label, valid_label, queries):\n",
        "    \"\"\"\n",
        "    Split questions into train, test, validation sets.\n",
        "\n",
        "    Returns:\n",
        "        train_questions: Dataframe with qids\n",
        "        test_questions: Dataframe with qids\n",
        "        valid_questions: Dataframe with qids\n",
        "    ----------\n",
        "    Arguments:\n",
        "        train_label: Dictionary contraining qid and list of relevant docid\n",
        "        test_label: Dictionary contraining qid and list of relevant docid\n",
        "        valid_label: Dictionary contraining qid and list of relevant docid\n",
        "        queries: Dataframe containing the question id and question text\n",
        "    \"\"\"\n",
        "    # Get a list of question ids\n",
        "    train_q = list(train_label.keys())\n",
        "    test_q = list(test_label.keys())\n",
        "    valid_q = list(valid_label.keys())\n",
        "\n",
        "    # Split question dataframe into train, test, valid set\n",
        "    train_questions = queries[queries['qid'].isin(train_q)]\n",
        "    test_questions = queries[queries['qid'].isin(test_q)]\n",
        "    valid_questions = queries[queries['qid'].isin(valid_q)]\n",
        "\n",
        "    return train_questions, test_questions, valid_questions\n",
        "\n",
        "def split_label(qid_docid):\n",
        "    \"\"\"\n",
        "    Split question answer pairs into train, test, validation sets.\n",
        "\n",
        "    Returns:\n",
        "        train_label: Dictonary\n",
        "            key - question id\n",
        "            value - list of relevant docids\n",
        "        test_label: Dictonary\n",
        "            key - question id\n",
        "            value - list of relevant docids\n",
        "        valid_label: Dictonary\n",
        "            key - question id\n",
        "            value - list of relevant docids\n",
        "    ----------\n",
        "    Arguments:\n",
        "        qid_docid: Dataframe containing the question id and relevant docids\n",
        "    \"\"\"\n",
        "    # Group the answers for each question into a list\n",
        "    qid_docid = qid_docid.groupby(['qid']).agg(lambda x: tuple(x)).applymap(list).reset_index()\n",
        "    # Split data\n",
        "    train, test_set = train_test_split(qid_docid, test_size=0.05)\n",
        "    train_set, valid_set = train_test_split(train, test_size=0.1)\n",
        "    # Expand the list of docids into individual rows to represent a single sample\n",
        "    train_data = train_set.explode('docid')\n",
        "    test_data = test_set.explode('docid')\n",
        "    valid_data = valid_set.explode('docid')\n",
        "\n",
        "    # Convert data into dictionary - key: qid, value: list of relevant docid\n",
        "    train_label = label_to_dict(train_data)\n",
        "    test_label = label_to_dict(test_data)\n",
        "    valid_label = label_to_dict(valid_data)\n",
        "\n",
        "    return train_label, test_label, valid_label\n",
        "\n",
        "def split_question(train_label, test_label, valid_label, queries):\n",
        "    \"\"\"\n",
        "    Split questions into train, test, validation sets.\n",
        "\n",
        "    Returns:\n",
        "        train_questions: Dataframe with qids\n",
        "        test_questions: Dataframe with qids\n",
        "        valid_questions: Dataframe with qids\n",
        "    ----------\n",
        "    Arguments:\n",
        "        train_label: Dictionary contraining qid and list of relevant docid\n",
        "        test_label: Dictionary contraining qid and list of relevant docid\n",
        "        valid_label: Dictionary contraining qid and list of relevant docid\n",
        "        queries: Dataframe containing the question id and question text\n",
        "    \"\"\"\n",
        "    # Get a list of question ids\n",
        "    train_q = list(train_label.keys())\n",
        "    test_q = list(test_label.keys())\n",
        "    valid_q = list(valid_label.keys())\n",
        "\n",
        "    # Split question dataframe into train, test, valid set\n",
        "    train_questions = queries[queries['qid'].isin(train_q)]\n",
        "    test_questions = queries[queries['qid'].isin(test_q)]\n",
        "    valid_questions = queries[queries['qid'].isin(valid_q)]\n",
        "\n",
        "    return train_questions, test_questions, valid_questions\n",
        "\n",
        "def create_dataset(question_df, labels, cands_size):\n",
        "    \"\"\"Retrieves the top-k candidate answers for a question and\n",
        "    creates a list of lists of the dataset containing the question id,\n",
        "    list of relevant answer ids, and the list of answer candidates\n",
        "\n",
        "    Returns:\n",
        "        dataset: list of list in the form [qid, [pos ans], [ans candidates]]\n",
        "    ----------\n",
        "    Arguments:\n",
        "        question_df: Dataframe containing the qid and question text\n",
        "        labels: Dictonary containing the qid to text map\n",
        "        cands_size: int - number of candidates to retrieve\n",
        "    \"\"\"\n",
        "    dataset = []\n",
        "    # Calls retriever\n",
        "    searcher = SimpleSearcher(fiqa_index)\n",
        "    # For each question\n",
        "    for i, row in question_df.iterrows():\n",
        "        qid = row['qid']\n",
        "        tmp = []\n",
        "        # Append qid\n",
        "        tmp.append(qid)\n",
        "        # Append list of relevant docs\n",
        "        tmp.append(labels[qid])\n",
        "        # Retrieves answer candidates\n",
        "        cands = []\n",
        "        cands_score = []\n",
        "        query = row['question']\n",
        "        query = re.sub('[£€§]', '', query)\n",
        "        hits = searcher.search(query, k=cands_size)\n",
        "\n",
        "        for docid in range(0, len(hits)):\n",
        "            cands.append(int(hits[docid].docid))\n",
        "            cands_score.append(hits[docid].score)\n",
        "        # Append candidate answers\n",
        "        tmp.append(cands)\n",
        "        tmp.append(cands_score)\n",
        "        dataset.append(tmp)\n",
        "\n",
        "    return dataset\n",
        "\n",
        "def get_dataset(query_path, labels_path, cands_size):\n",
        "    \"\"\"Splits the dataset into train, validation, and test set and creates\n",
        "    the dataset form for training, validation, and testing.\n",
        "\n",
        "    Returns:\n",
        "        train_set: list of list in the form [qid, [pos ans], [ans candidates]]\n",
        "        valid_set: list of list in the form [qid, [pos ans], [ans candidates]]\n",
        "        test_set: list of list in the form [qid, [pos ans], [ans candidates]]\n",
        "    ----------\n",
        "    Arguments:\n",
        "        query_path: str - path containing a list of qid and questions\n",
        "        labels_path: str - path containing a list of qid and relevant docid\n",
        "        cands_size: int - number of candidates to retrieve\n",
        "    \"\"\"\n",
        "    # Question id and Question text\n",
        "    queries = load_questions_to_df(query_path)\n",
        "    # Question id and Answer id pair\n",
        "    qid_docid = load_qid_docid_to_df(labels_path)\n",
        "    # qid to docid label map\n",
        "    labels = label_to_dict(qid_docid)\n",
        "    train_label, test_label, valid_label = split_label(qid_docid)\n",
        "    # Split Questions\n",
        "    train_questions, test_questions, \\\n",
        "    valid_questions = split_question(train_label, test_label, valid_label, queries)\n",
        "\n",
        "    print(\"\\nGenerating training set...\\n\")\n",
        "    train_set = create_dataset(train_questions, labels, cands_size)\n",
        "    print(\"Generating validation set...\\n\")\n",
        "    valid_set = create_dataset(valid_questions, labels, cands_size)\n",
        "    print(\"Generating test set...\\n\")\n",
        "    test_set = create_dataset(test_questions, labels, cands_size)\n",
        "\n",
        "    return train_set, valid_set, test_set\n",
        "\n",
        "def main():\n",
        "\n",
        "    parser = argparse.ArgumentParser()\n",
        "    # Required parameters\n",
        "    parser.add_argument(\"--query_path\", default=None, type=str, required=True,\n",
        "    help=\"Path to the question id to text data in .tsv format. Each line should have at least two columns named (qid, question) separated by tab\")\n",
        "    parser.add_argument(\"--label_path\", default=None, type=str, required=True,\n",
        "    help=\"Path to the question id and answer id data in .tsv format. Each line should have at two columns named (qid, docid) separated by tab\")\n",
        "\n",
        "    # Optional parameters\n",
        "    parser.add_argument(\"--cands_size\", default=50, type=int, required=False,\n",
        "    help=\"Number of candidates to retrieve per question.\")\n",
        "    parser.add_argument(\"--output_dir\", default=Path.cwd()/'data/data_pickle/',\n",
        "    type=str, required=False, help=\"The output directory where the generated data will be stored.\")\n",
        "\n",
        "    args = parser.parse_args()\n",
        "\n",
        "    if len(sys.argv) < 4:\n",
        "        print(\"Usage: python3 src/generate_data.py <query_path> <label_path>\")\n",
        "        sys.exit()\n",
        "\n",
        "    train_set, valid_set, test_set = get_dataset(args.query_path, \\\n",
        "                                                 args.label_path, \\\n",
        "                                                 args.cands_size)\n",
        "\n",
        "    save_pickle(args.output_dir + \"train_set.pickle\", train_set)\n",
        "    save_pickle(args.output_dir + \"valid_set.pickle\", valid_set)\n",
        "    save_pickle(args.output_dir + \"test_set.pickle\", test_set)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iwakhfkgm0Em",
        "outputId": "9cd4bb45-e843-448a-c571-2d5ca15cad03"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Generating training set...\n",
            "\n",
            "SimpleSearcher class has been deprecated, please use LuceneSearcher from pyserini.search.lucene instead\n",
            "Generating validation set...\n",
            "\n",
            "SimpleSearcher class has been deprecated, please use LuceneSearcher from pyserini.search.lucene instead\n",
            "Generating test set...\n",
            "\n",
            "SimpleSearcher class has been deprecated, please use LuceneSearcher from pyserini.search.lucene instead\n"
          ]
        }
      ],
      "source": [
        "#Define train dataset, validation dataset and test dataset\n",
        "query_path = \"/gdrive/MyDrive/w266-final-project-master/w266-final-project-master/FinBERT-QA/data/raw/FiQA_train_question_final.tsv\"\n",
        "labels_path = \"/gdrive/MyDrive/w266-final-project-master/w266-final-project-master/FinBERT-QA/data/raw/FiQA_train_question_doc_final.tsv\"\n",
        "train_set, valid_set, test_set = get_dataset(query_path, labels_path, 50)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J0uZM0DCAUVk",
        "outputId": "88b920da-7891-4e79-d45c-f0bf2f72ec6e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of answers after cleaning: 57600\n",
            "Number of QA pairs after cleaning: 17072\n"
          ]
        }
      ],
      "source": [
        "# Cleaning data\n",
        "empty_docs, empty_id = get_empty_docs(collection)\n",
        "# Remove empty answers from collection of answers\n",
        "collection_cleaned = collection.drop(empty_id)\n",
        "# Remove empty answers from qa pairs\n",
        "qid_docid = qid_docid[~qid_docid['docid'].isin(empty_docs)]\n",
        "\n",
        "print(\"Number of answers after cleaning: {}\".format(len(collection_cleaned)))\n",
        "print(\"Number of QA pairs after cleaning: {}\".format(len(qid_docid)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MUCwxaEFAd0H"
      },
      "outputs": [],
      "source": [
        "# Write collection df to file\n",
        "save_tsv(\"retriever/collection_cleaned.tsv\", collection_cleaned)\n",
        "\n",
        "# Convert collection df to JSON file for Anserini's document indexer\n",
        "collection_to_json(\"retriever/collection_json/docs.json\", \"retriever/collection_cleaned.tsv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Metrics calculation"
      ],
      "metadata": {
        "id": "BDR4oumeZxig"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M7cUbkrmwVLP"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics import ndcg_score\n",
        "from sklearn.metrics import average_precision_score\n",
        "\n",
        "def run_baseline(data, top_k):\n",
        "  ap = []\n",
        "  rr = []\n",
        "  cg = []\n",
        "\n",
        "\n",
        "  #for i, seq in enumerate(tqdm(train_set)):\n",
        "  for i, seq in enumerate(data):\n",
        "    qid, ans_labels, cands, cands_score = seq[0], seq[1], seq[2], seq[3]\n",
        "    \n",
        "    # Map question id to text\n",
        "    #q_text = qid_to_text[qid]\n",
        "\n",
        "    max_width = -1\n",
        "    rr_ = 0\n",
        "    ap_ = 0.0\n",
        "    precision_ = 0.0\n",
        "    relcnt_ = 0\n",
        "\n",
        "    # top_k = 2\n",
        "\n",
        "    # For each answer in the candidates\n",
        "    for i in range(top_k):\n",
        "      docid = cands[i]\n",
        "      if docid in ans_labels and rr_ == 0:\n",
        "        rr_ = 1/(i+1)\n",
        "\n",
        "\n",
        "    relscores = [1 if docid in ans_labels else 0 for docid in cands[:top_k]]\n",
        "    pos = [1.0/(i+1) for i in range(top_k)]\n",
        "    ap_ = average_precision_score(relscores,pos) if sum(relscores) != 0 else 0 \n",
        "\n",
        "    relscores = np.asarray([[cands_score[i] if (cands[i] in ans_labels) else 0.001 for i in range(top_k)]])\n",
        "    pos = np.asarray([[np.log2(i+2) for i in range(top_k)]])\n",
        "\n",
        "\n",
        "    # Our calculation of NDCG\n",
        "    relscores_sorted = np.asarray([sorted(relscores[0], reverse=True)])\n",
        "    dcg = 0\n",
        "    idcg = 0\n",
        "    for i in range(top_k):\n",
        "      dcg += relscores[0][i]/pos[0][i]\n",
        "      idcg += relscores_sorted[0][i]/pos[0][i]\n",
        "    cg_ = dcg/idcg\n",
        "\n",
        "    # cg_ = ndcg_score(relscores, pos)\n",
        "\n",
        "    ap.append(ap_)\n",
        "    rr.append(rr_)\n",
        "    cg.append(cg_)\n",
        "  return rr, ap, cg\n",
        "\n",
        "\n",
        "      "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kow15bGbwcmz",
        "outputId": "718bc884-0f2d-42d4-cfb6-415e6c1352c3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean Reciprocal Rank (MRR): 0.27206874303478207\n",
            "Mean average Precision (MAP) 0.2701331456390404\n",
            "Normalized Discounted Cumulative Gain (NDCG) 0.9516887851317029\n"
          ]
        }
      ],
      "source": [
        "rr, ap, cg = run_baseline(train_set, top_k)\n",
        "\n",
        "print('Mean Reciprocal Rank (MRR):', np.mean(rr))\n",
        "print('Mean average Precision (MAP)', np.mean(ap))\n",
        "print('Normalized Discounted Cumulative Gain (NDCG)', np.mean(cg))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Processing the questions and answers"
      ],
      "metadata": {
        "id": "m9Hc8q-5cM-_"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "epp_ysv6Cygj"
      },
      "outputs": [],
      "source": [
        "processed_answers = process_answers(collection_cleaned)\n",
        "processed_questions = process_questions(queries)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MzDxFMF0C2oi",
        "outputId": "7fe566ba-61a5-46aa-c72c-29dcd79dbf70"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vocab size: 85034\n",
            "Top 35 common words: [('the', 371203), ('to', 233559), ('a', 201620), ('you', 166702), ('and', 163066), ('of', 157574), ('is', 129894), ('in', 120019), ('that', 111416), ('for', 89366), ('it', 83822), ('i', 74100), ('your', 68153), ('are', 67255), ('if', 60689), ('be', 59266), ('on', 58382), ('have', 55754), ('as', 50088), ('this', 49868), ('not', 49227), ('or', 46080), ('with', 45894), ('they', 44485), ('but', 41690), ('can', 38863), ('will', 36865), ('at', 35548), ('an', 31392), ('money', 31003), ('so', 29980), ('$', 29096), ('would', 28750), ('from', 28582), ('more', 27378)]\n"
          ]
        }
      ],
      "source": [
        "word2index, word2count = create_vocab(processed_answers, processed_questions)\n",
        "\n",
        "print(\"Vocab size: {}\".format(len(word2index)))\n",
        "print(\"Top {} common words: {}\".format(35, Counter(word2count).most_common(35)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZGOGzYQ7DKfo"
      },
      "outputs": [],
      "source": [
        "qid_to_text, docid_to_text = id_to_text(collection, queries)\n",
        "qid_to_tokenized_text, docid_to_tokenized_text = id_to_tokenized_text(processed_answers, processed_questions)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 371
        },
        "id": "UunSA66_m5X4",
        "outputId": "c798be2a-07c5-46a4-9d84-575abcb2f6ca"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   qid  \\\n",
              "0    0   \n",
              "1    1   \n",
              "2    2   \n",
              "3    3   \n",
              "4    4   \n",
              "\n",
              "                                                                                        question  \\\n",
              "0                                      What is considered a business expense on a business trip?   \n",
              "1                                       Claiming business expenses for a business with no income   \n",
              "2                     Transferring money from One business checking to another business checking   \n",
              "3           Having a separate bank account for business/investing, but not a “business account?”   \n",
              "4  Business Expense - Car Insurance Deductible For Accident That Occurred During a Business Trip   \n",
              "\n",
              "                                                                                     q_processed  \\\n",
              "0                                      what is considered a business expense on a business trip    \n",
              "1                                       claiming business expenses for a business with no income   \n",
              "2                     transferring money from one business checking to another business checking   \n",
              "3           having a separate bank account for business investing  but not a  business account     \n",
              "4  business expense   car insurance deductible for accident that occurred during a business trip   \n",
              "\n",
              "                                                                                                 tokenized_q  \\\n",
              "0                                        [what, is, considered, a, business, expense, on, a, business, trip]   \n",
              "1                                         [claiming, business, expenses, for, a, business, with, no, income]   \n",
              "2                      [transferring, money, from, one, business, checking, to, another, business, checking]   \n",
              "3             [having, a, separate, bank, account, for, business, investing, but, not, a, business, account]   \n",
              "4  [business, expense, car, insurance, deductible, for, accident, that, occurred, during, a, business, trip]   \n",
              "\n",
              "   q_len  \n",
              "0     10  \n",
              "1      9  \n",
              "2     10  \n",
              "3     13  \n",
              "4     13  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-59ef2514-667d-49ce-88e8-2f5034942a67\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>qid</th>\n",
              "      <th>question</th>\n",
              "      <th>q_processed</th>\n",
              "      <th>tokenized_q</th>\n",
              "      <th>q_len</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>What is considered a business expense on a business trip?</td>\n",
              "      <td>what is considered a business expense on a business trip</td>\n",
              "      <td>[what, is, considered, a, business, expense, on, a, business, trip]</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>Claiming business expenses for a business with no income</td>\n",
              "      <td>claiming business expenses for a business with no income</td>\n",
              "      <td>[claiming, business, expenses, for, a, business, with, no, income]</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>Transferring money from One business checking to another business checking</td>\n",
              "      <td>transferring money from one business checking to another business checking</td>\n",
              "      <td>[transferring, money, from, one, business, checking, to, another, business, checking]</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>Having a separate bank account for business/investing, but not a “business account?”</td>\n",
              "      <td>having a separate bank account for business investing  but not a  business account</td>\n",
              "      <td>[having, a, separate, bank, account, for, business, investing, but, not, a, business, account]</td>\n",
              "      <td>13</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>Business Expense - Car Insurance Deductible For Accident That Occurred During a Business Trip</td>\n",
              "      <td>business expense   car insurance deductible for accident that occurred during a business trip</td>\n",
              "      <td>[business, expense, car, insurance, deductible, for, accident, that, occurred, during, a, business, trip]</td>\n",
              "      <td>13</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-59ef2514-667d-49ce-88e8-2f5034942a67')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-59ef2514-667d-49ce-88e8-2f5034942a67 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-59ef2514-667d-49ce-88e8-2f5034942a67');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "pd.set_option('display.max_colwidth', None)\n",
        "processed_questions.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "BvX0nznZoJ7k",
        "outputId": "6d002537-2b0a-4638-9675-3015eb1185a2"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   docid  \\\n",
              "0      3   \n",
              "1     31   \n",
              "2     56   \n",
              "3     59   \n",
              "4     63   \n",
              "\n",
              "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     doc  \\\n",
              "0                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           I'm not saying I don't like the idea of on-the-job training too, but you can't expect the company to do that. Training workers is not their job - they're building software. Perhaps educational systems in the U.S. (or their students) should worry a little about getting marketable skills in exchange for their massive investment in education, rather than getting out with thousands in student debt and then complaining that they aren't qualified to do anything.   \n",
              "1                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            So nothing preventing false ratings besides additional scrutiny from the market/investors, but there are some newer controls in place to prevent institutions from using them. Under the DFA banks can no longer solely rely on credit ratings as due diligence to buy a financial instrument, so that's a plus. The intent being that if financial institutions do their own leg work then *maybe* they'll figure out that a certain CDO is garbage or not.  Edit: lead in   \n",
              "2                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             You can never use a health FSA for individual health insurance premiums.  Moreover, FSA plan sponsors can limit what they are will to reimburse.  While you can't use a health FSA for premiums, you could previously use a 125 cafeteria plan to pay premiums, but it had to be a separate election from the health FSA. However, under N. 2013-54, even using a cafeteria plan to pay for indivdiual premiums is effectively prohibited.   \n",
              "3                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              Samsung created the LCD and other flat screen technology like OLED. a few years ago every flat screen came from Samsung factories and were reshelled. I think the 21 Hanns screen I am looking at now is Samsung and it is only a couple of years old. Samsung seem to be a good company.   \n",
              "4  Here are the SEC requirements: The federal securities laws define the term accredited investor in   Rule 501 of Regulation D as: a bank, insurance company, registered investment company, business development company, or small business investment company; an employee benefit plan, within the meaning of the Employee Retirement Income Security Act, if a bank, insurance company, or   registered investment adviser makes the investment decisions, or if   the plan has total assets in excess of $5 million; a charitable organization, corporation, or partnership with assets exceeding $5 million; a director, executive officer, or general partner of the company selling the securities; a business in which all the equity owners are accredited investors; a natural person who has individual net worth, or joint net worth with the person’s spouse, that exceeds $1 million at the time of the   purchase, excluding the value of the primary residence of such person; a natural person with income exceeding $200,000 in each of the two most recent years or joint income with a spouse exceeding $300,000 for   those years and a reasonable expectation of the same income level in   the current year; or a trust with assets in excess of $5 million, not formed to acquire the securities offered, whose purchases a sophisticated person makes. No citizenship/residency requirements.   \n",
              "\n",
              "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         doc_processed  \\\n",
              "0                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   im not saying i dont like the idea of on the job training too  but you cant expect the company to do that training workers is not their job   theyre building software perhaps educational systems in the us  or their students  should worry a little about getting marketable skills in exchange for their massive investment in education  rather than getting out with thousands in student debt and then complaining that they arent qualified to do anything   \n",
              "1                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               so nothing preventing false ratings besides additional scrutiny from the market investors  but there are some newer controls in place to prevent institutions from using them under the dfa banks can no longer solely rely on credit ratings as due diligence to buy a financial instrument  so thats a plus the intent being that if financial institutions do their own leg work then  maybe  theyll figure out that a certain cdo is garbage or not  edit  lead in   \n",
              "2                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 you can never use a health fsa for individual health insurance premiums  moreover  fsa plan sponsors can limit what they are will to reimburse  while you cant use a health fsa for premiums  you could previously use a 125 cafeteria plan to pay premiums  but it had to be a separate election from the health fsa however  under n 2013 54  even using a cafeteria plan to pay for indivdiual premiums is effectively prohibited   \n",
              "3                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                samsung created the lcd and other flat screen technology like oled a few years ago every flat screen came from samsung factories and were reshelled i think the 21 hanns screen i am looking at now is samsung and it is only a couple of years old samsung seem to be a good company   \n",
              "4  here are the sec requirements  the federal securities laws define the term accredited investor in   rule 501 of regulation d as  a bank  insurance company  registered investment company  business development company  or small business investment company  an employee benefit plan  within the meaning of the employee retirement income security act  if a bank  insurance company  or   registered investment adviser makes the investment decisions  or if   the plan has total assets in excess of $5 million  a charitable organization  corporation  or partnership with assets exceeding $5 million  a director  executive officer  or general partner of the company selling the securities  a business in which all the equity owners are accredited investors  a natural person who has individual net worth  or joint net worth with the person’s spouse  that exceeds $1 million at the time of the   purchase  excluding the value of the primary residence of such person  a natural person with income exceeding $200 000 in each of the two most recent years or joint income with a spouse exceeding $300 000 for   those years and a reasonable expectation of the same income level in   the current year  or a trust with assets in excess of $5 million  not formed to acquire the securities offered  whose purchases a sophisticated person makes no citizenship residency requirements   \n",
              "\n",
              "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       tokenized_ans  \\\n",
              "0                                                                                                                                                                                                                                          [im, not, saying, i, dont, like, the, idea, of, on, the, job, training, too, but, you, cant, expect, the, company, to, do, that, training, workers, is, not, their, job, theyre, building, software, perhaps, educational, systems, in, the, us, or, their, students, should, worry, a, little, about, getting, marketable, skills, in, exchange, for, their, massive, investment, in, education, rather, than, getting, out, with, thousands, in, student, debt, and, then, complaining, that, they, arent, qualified, to, do, anything]   \n",
              "1                                                                                                                                                                                                                                    [so, nothing, preventing, false, ratings, besides, additional, scrutiny, from, the, market, investors, but, there, are, some, newer, controls, in, place, to, prevent, institutions, from, using, them, under, the, dfa, banks, can, no, longer, solely, rely, on, credit, ratings, as, due, diligence, to, buy, a, financial, instrument, so, thats, a, plus, the, intent, being, that, if, financial, institutions, do, their, own, leg, work, then, maybe, theyll, figure, out, that, a, certain, cdo, is, garbage, or, not, edit, lead, in]   \n",
              "2                                                                                                                                                                                                                                                                           [you, can, never, use, a, health, fsa, for, individual, health, insurance, premiums, moreover, fsa, plan, sponsors, can, limit, what, they, are, will, to, reimburse, while, you, cant, use, a, health, fsa, for, premiums, you, could, previously, use, a, 125, cafeteria, plan, to, pay, premiums, but, it, had, to, be, a, separate, election, from, the, health, fsa, however, under, n, 2013, 54, even, using, a, cafeteria, plan, to, pay, for, indivdiual, premiums, is, effectively, prohibited]   \n",
              "3                                                                                                                                                                                                                                                                                                                                                                                                                                       [samsung, created, the, lcd, and, other, flat, screen, technology, like, oled, a, few, years, ago, every, flat, screen, came, from, samsung, factories, and, were, reshelled, i, think, the, 21, hanns, screen, i, am, looking, at, now, is, samsung, and, it, is, only, a, couple, of, years, old, samsung, seem, to, be, a, good, company]   \n",
              "4  [here, are, the, sec, requirements, the, federal, securities, laws, define, the, term, accredited, investor, in, rule, 501, of, regulation, d, as, a, bank, insurance, company, registered, investment, company, business, development, company, or, small, business, investment, company, an, employee, benefit, plan, within, the, meaning, of, the, employee, retirement, income, security, act, if, a, bank, insurance, company, or, registered, investment, adviser, makes, the, investment, decisions, or, if, the, plan, has, total, assets, in, excess, of, $, 5, million, a, charitable, organization, corporation, or, partnership, with, assets, exceeding, $, 5, million, a, director, executive, officer, or, general, partner, of, the, company, selling, the, ...]   \n",
              "\n",
              "   ans_len  \n",
              "0       76  \n",
              "1       78  \n",
              "2       74  \n",
              "3       54  \n",
              "4      222  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-26593b5b-62bb-46f8-aee6-90fd51e46f28\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>docid</th>\n",
              "      <th>doc</th>\n",
              "      <th>doc_processed</th>\n",
              "      <th>tokenized_ans</th>\n",
              "      <th>ans_len</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>3</td>\n",
              "      <td>I'm not saying I don't like the idea of on-the-job training too, but you can't expect the company to do that. Training workers is not their job - they're building software. Perhaps educational systems in the U.S. (or their students) should worry a little about getting marketable skills in exchange for their massive investment in education, rather than getting out with thousands in student debt and then complaining that they aren't qualified to do anything.</td>\n",
              "      <td>im not saying i dont like the idea of on the job training too  but you cant expect the company to do that training workers is not their job   theyre building software perhaps educational systems in the us  or their students  should worry a little about getting marketable skills in exchange for their massive investment in education  rather than getting out with thousands in student debt and then complaining that they arent qualified to do anything</td>\n",
              "      <td>[im, not, saying, i, dont, like, the, idea, of, on, the, job, training, too, but, you, cant, expect, the, company, to, do, that, training, workers, is, not, their, job, theyre, building, software, perhaps, educational, systems, in, the, us, or, their, students, should, worry, a, little, about, getting, marketable, skills, in, exchange, for, their, massive, investment, in, education, rather, than, getting, out, with, thousands, in, student, debt, and, then, complaining, that, they, arent, qualified, to, do, anything]</td>\n",
              "      <td>76</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>31</td>\n",
              "      <td>So nothing preventing false ratings besides additional scrutiny from the market/investors, but there are some newer controls in place to prevent institutions from using them. Under the DFA banks can no longer solely rely on credit ratings as due diligence to buy a financial instrument, so that's a plus. The intent being that if financial institutions do their own leg work then *maybe* they'll figure out that a certain CDO is garbage or not.  Edit: lead in</td>\n",
              "      <td>so nothing preventing false ratings besides additional scrutiny from the market investors  but there are some newer controls in place to prevent institutions from using them under the dfa banks can no longer solely rely on credit ratings as due diligence to buy a financial instrument  so thats a plus the intent being that if financial institutions do their own leg work then  maybe  theyll figure out that a certain cdo is garbage or not  edit  lead in</td>\n",
              "      <td>[so, nothing, preventing, false, ratings, besides, additional, scrutiny, from, the, market, investors, but, there, are, some, newer, controls, in, place, to, prevent, institutions, from, using, them, under, the, dfa, banks, can, no, longer, solely, rely, on, credit, ratings, as, due, diligence, to, buy, a, financial, instrument, so, thats, a, plus, the, intent, being, that, if, financial, institutions, do, their, own, leg, work, then, maybe, theyll, figure, out, that, a, certain, cdo, is, garbage, or, not, edit, lead, in]</td>\n",
              "      <td>78</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>56</td>\n",
              "      <td>You can never use a health FSA for individual health insurance premiums.  Moreover, FSA plan sponsors can limit what they are will to reimburse.  While you can't use a health FSA for premiums, you could previously use a 125 cafeteria plan to pay premiums, but it had to be a separate election from the health FSA. However, under N. 2013-54, even using a cafeteria plan to pay for indivdiual premiums is effectively prohibited.</td>\n",
              "      <td>you can never use a health fsa for individual health insurance premiums  moreover  fsa plan sponsors can limit what they are will to reimburse  while you cant use a health fsa for premiums  you could previously use a 125 cafeteria plan to pay premiums  but it had to be a separate election from the health fsa however  under n 2013 54  even using a cafeteria plan to pay for indivdiual premiums is effectively prohibited</td>\n",
              "      <td>[you, can, never, use, a, health, fsa, for, individual, health, insurance, premiums, moreover, fsa, plan, sponsors, can, limit, what, they, are, will, to, reimburse, while, you, cant, use, a, health, fsa, for, premiums, you, could, previously, use, a, 125, cafeteria, plan, to, pay, premiums, but, it, had, to, be, a, separate, election, from, the, health, fsa, however, under, n, 2013, 54, even, using, a, cafeteria, plan, to, pay, for, indivdiual, premiums, is, effectively, prohibited]</td>\n",
              "      <td>74</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>59</td>\n",
              "      <td>Samsung created the LCD and other flat screen technology like OLED. a few years ago every flat screen came from Samsung factories and were reshelled. I think the 21 Hanns screen I am looking at now is Samsung and it is only a couple of years old. Samsung seem to be a good company.</td>\n",
              "      <td>samsung created the lcd and other flat screen technology like oled a few years ago every flat screen came from samsung factories and were reshelled i think the 21 hanns screen i am looking at now is samsung and it is only a couple of years old samsung seem to be a good company</td>\n",
              "      <td>[samsung, created, the, lcd, and, other, flat, screen, technology, like, oled, a, few, years, ago, every, flat, screen, came, from, samsung, factories, and, were, reshelled, i, think, the, 21, hanns, screen, i, am, looking, at, now, is, samsung, and, it, is, only, a, couple, of, years, old, samsung, seem, to, be, a, good, company]</td>\n",
              "      <td>54</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>63</td>\n",
              "      <td>Here are the SEC requirements: The federal securities laws define the term accredited investor in   Rule 501 of Regulation D as: a bank, insurance company, registered investment company, business development company, or small business investment company; an employee benefit plan, within the meaning of the Employee Retirement Income Security Act, if a bank, insurance company, or   registered investment adviser makes the investment decisions, or if   the plan has total assets in excess of $5 million; a charitable organization, corporation, or partnership with assets exceeding $5 million; a director, executive officer, or general partner of the company selling the securities; a business in which all the equity owners are accredited investors; a natural person who has individual net worth, or joint net worth with the person’s spouse, that exceeds $1 million at the time of the   purchase, excluding the value of the primary residence of such person; a natural person with income exceeding $200,000 in each of the two most recent years or joint income with a spouse exceeding $300,000 for   those years and a reasonable expectation of the same income level in   the current year; or a trust with assets in excess of $5 million, not formed to acquire the securities offered, whose purchases a sophisticated person makes. No citizenship/residency requirements.</td>\n",
              "      <td>here are the sec requirements  the federal securities laws define the term accredited investor in   rule 501 of regulation d as  a bank  insurance company  registered investment company  business development company  or small business investment company  an employee benefit plan  within the meaning of the employee retirement income security act  if a bank  insurance company  or   registered investment adviser makes the investment decisions  or if   the plan has total assets in excess of $5 million  a charitable organization  corporation  or partnership with assets exceeding $5 million  a director  executive officer  or general partner of the company selling the securities  a business in which all the equity owners are accredited investors  a natural person who has individual net worth  or joint net worth with the person’s spouse  that exceeds $1 million at the time of the   purchase  excluding the value of the primary residence of such person  a natural person with income exceeding $200 000 in each of the two most recent years or joint income with a spouse exceeding $300 000 for   those years and a reasonable expectation of the same income level in   the current year  or a trust with assets in excess of $5 million  not formed to acquire the securities offered  whose purchases a sophisticated person makes no citizenship residency requirements</td>\n",
              "      <td>[here, are, the, sec, requirements, the, federal, securities, laws, define, the, term, accredited, investor, in, rule, 501, of, regulation, d, as, a, bank, insurance, company, registered, investment, company, business, development, company, or, small, business, investment, company, an, employee, benefit, plan, within, the, meaning, of, the, employee, retirement, income, security, act, if, a, bank, insurance, company, or, registered, investment, adviser, makes, the, investment, decisions, or, if, the, plan, has, total, assets, in, excess, of, $, 5, million, a, charitable, organization, corporation, or, partnership, with, assets, exceeding, $, 5, million, a, director, executive, officer, or, general, partner, of, the, company, selling, the, ...]</td>\n",
              "      <td>222</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-26593b5b-62bb-46f8-aee6-90fd51e46f28')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-26593b5b-62bb-46f8-aee6-90fd51e46f28 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-26593b5b-62bb-46f8-aee6-90fd51e46f28');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "source": [
        "processed_answers.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training a model using BERT"
      ],
      "metadata": {
        "id": "EfK1X1pBecLO"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 113,
          "referenced_widgets": [
            "919632840d134dd3897e07e565790047",
            "3b2547e5cc094800af09613a4e920057",
            "c11e480a6f79441498d91ffaf82ca468",
            "5e049c1ee72a479985020386d0e1b1a4",
            "12796276d36e491680c2100ba20ae940",
            "adbf654ebd1b42849d6bb4e5c5faf0e4",
            "6bc6be28dd98434bb3c6560cd897d6fc",
            "6499ceffc0d346b1be1d9b7aaec18e5a",
            "9d7838644cf84f3c85964262ec765bc1",
            "756a595c9839404995d03c8b55d0743b",
            "af4f2e4e14b44e92b551461c58a086c4",
            "70cc16088a24447a98b5d74fd0276a48",
            "2b6262c3ac4043a0bcc136b66b13eae4",
            "0f112447a7be4338aaec5a70986d8da4",
            "02537e1ee9e54a2cb53c4a298ba175b2",
            "04fdfd825d0b4167b266387162ede764",
            "d2d028d3eda34091905ee8b15fb80c9e",
            "dd348f47a854415f8dcd61ff78f352c7",
            "c4d368fdbce4476ea187f2ce227afd21",
            "0af56adc0c184a9aaea0c7a708985ce4",
            "4f45b1ae83f74720aaa328b832bef165",
            "58b922dfd8a348ac895cf776dfd850ab",
            "df131e0e01334f30ac4502431b1e9a18",
            "446445f2f43f4d89826467732223dcb2",
            "9c1a3bbe3ebb463f9d0f5691b8b62992",
            "c18387ae76044e83a39509c5c35f97b2",
            "477edfd3134f41f8a7aa88f55ae174f8",
            "869f3abcb86c4aeb8f37b2ce90f297d6",
            "912e21e449ae43758c78ac4b94d24834",
            "f13f0e3fd6dd4264a7d5bd6ccd94c252",
            "5d56567e012d48379f5ab7d92f4ec708",
            "fa9761feabf94723999f0afaff172669",
            "74848a656aa04e1980aa7bb478600704"
          ]
        },
        "id": "iC4drcIUEFz-",
        "outputId": "f1906b25-edcb-4104-8114-9230616f88ab"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading vocab.txt:   0%|          | 0.00/208k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "919632840d134dd3897e07e565790047"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading tokenizer_config.json:   0%|          | 0.00/29.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "70cc16088a24447a98b5d74fd0276a48"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "df131e0e01334f30ac4502431b1e9a18"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "bert_tokenizer = BertTokenizer.from_pretrained('bert-base-cased') #generate tokens from BERT pretrained model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VgT0QbGg1dfb"
      },
      "outputs": [],
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "\n",
        "#bert_model = TFBertModel.from_pretrained('bert-base-cased')\n",
        "\n",
        "def generate_bert_tokens(data, max_length, labels_count):\n",
        "  input_ids = []\n",
        "  token_type_ids = []\n",
        "  att_masks = []\n",
        "  labels = []\n",
        "  data_modified = []\n",
        "\n",
        "\n",
        "  #for i, seq in enumerate(tqdm(train_set)):\n",
        "  for i, seq in enumerate(data):\n",
        "    qid, ans_labels, cands = seq[0], seq[1], seq[2]\n",
        "    \n",
        "    # Map question id to text\n",
        "    q_text = qid_to_text[qid]\n",
        "\n",
        "    max_width = -1\n",
        "   \n",
        "    ans_labels_dict = {k: v for v, k in enumerate(ans_labels)}\n",
        "    cands_valid = []\n",
        "    cands_invalid = []\n",
        " \n",
        "    for x in cands:\n",
        "      if x in ans_labels_dict: # and pos_counter<pos_labels_count\n",
        "        cands_valid.append(x)\n",
        "        # pos_counter += 1\n",
        "      else:   #  and neg_counter<neg_labels_count\n",
        "        cands_invalid.append(x)\n",
        "        # neg_counter += 1\n",
        "    # cands_modified = cands_valid[:pos_labels_count] + cands_invalid[-neg_labels_count:]\n",
        "    if len(cands_valid) >= labels_count:\n",
        "      cands_modified = cands_valid[:labels_count]\n",
        "    else:\n",
        "      cands_modified = cands_valid + cands_invalid[-(labels_count-len(cands_valid)):]\n",
        " \n",
        "    # For each answer in the chosen candidates\n",
        "    for docid in cands_modified:\n",
        "      # Map the docid to text\n",
        "      ans_text = docid_to_text[docid] if docid_to_text.get(docid) else ''\n",
        "\n",
        "      # Encode the sequence using BERT tokenizer\n",
        "      encoded_seq = bert_tokenizer.encode_plus(q_text, ans_text[:500],\n",
        "                                              max_length=max_length,\n",
        "                                              pad_to_max_length=True,\n",
        "                                              return_token_type_ids=True,\n",
        "                                              truncation=True,\n",
        "                                              return_attention_mask = True)\n",
        "\n",
        " \n",
        "\n",
        "      # Get parameters\n",
        "      input_ids.append(encoded_seq['input_ids'])\n",
        "      token_type_ids.append(encoded_seq['token_type_ids'])\n",
        "      att_masks.append(encoded_seq['attention_mask'])\n",
        "\n",
        "      # If an answer is in the list of relevant answers assign\n",
        "      # positive label\n",
        "      labels.append(1 if docid in ans_labels else 0)\n",
        "      data_modified.append([qid, ans_labels, docid])\n",
        "\n",
        "\n",
        "      #max_width = max(max_width, len(ans_text+q_text))\n",
        "      #print(max_width)\n",
        "  return input_ids, token_type_ids, att_masks, labels, data_modified"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Generate BERT tokens by dividing the training dataset into several buckets. This was done to improve performance.First we save the output from BERT tokenizer as pickle files and later we load them as a list and concatenate them."
      ],
      "metadata": {
        "id": "g7uWCze5fIHm"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7lFv3bz4uB6C",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a981ffc8-cfef-48fc-8f6e-bcb5fdb64893"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2329: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ]
        }
      ],
      "source": [
        "input_ids, token_type_ids, att_masks, labels, data_modified = generate_bert_tokens(train_set[:1000], max_length, labels_count)\n",
        "save_pickle('/gdrive/MyDrive/w266-final-project-master/w266-final-project-master/FinBERT-QA/data/data_pickle/' + \"input_ids1.pickle\", input_ids)\n",
        "save_pickle('/gdrive/MyDrive/w266-final-project-master/w266-final-project-master/FinBERT-QA/data/data_pickle/' + \"token_type_ids1.pickle\", token_type_ids)\n",
        "save_pickle('/gdrive/MyDrive/w266-final-project-master/w266-final-project-master/FinBERT-QA/data/data_pickle/' + \"att_masks1.pickle\", att_masks)\n",
        "save_pickle('/gdrive/MyDrive/w266-final-project-master/w266-final-project-master/FinBERT-QA/data/data_pickle/' + \"labels1.pickle\", labels)\n",
        "save_pickle('/gdrive/MyDrive/w266-final-project-master/w266-final-project-master/FinBERT-QA/data/data_pickle/' + \"data_modified1.pickle\", data_modified)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D0lpaXceoycW",
        "outputId": "2ec15e60-d85a-41c1-8353-03b730d7c797"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2329: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ]
        }
      ],
      "source": [
        "input_ids, token_type_ids, att_masks, labels, data_modified = generate_bert_tokens(train_set[1000:2000], max_length, labels_count)\n",
        "save_pickle('/gdrive/MyDrive/w266-final-project-master/w266-final-project-master/FinBERT-QA/data/data_pickle/' + \"input_ids2.pickle\", input_ids)\n",
        "save_pickle('/gdrive/MyDrive/w266-final-project-master/w266-final-project-master/FinBERT-QA/data/data_pickle/' + \"token_type_ids2.pickle\", token_type_ids)\n",
        "save_pickle('/gdrive/MyDrive/w266-final-project-master/w266-final-project-master/FinBERT-QA/data/data_pickle/' + \"att_masks2.pickle\", att_masks)\n",
        "save_pickle('/gdrive/MyDrive/w266-final-project-master/w266-final-project-master/FinBERT-QA/data/data_pickle/' + \"labels2.pickle\", labels)\n",
        "save_pickle('/gdrive/MyDrive/w266-final-project-master/w266-final-project-master/FinBERT-QA/data/data_pickle/' + \"data_modified2.pickle\", data_modified)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OSLsVZP7tGN_",
        "outputId": "341c1ddb-c54a-4ea8-da56-232dd59bee45"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2329: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
          ]
        }
      ],
      "source": [
        "input_ids, token_type_ids, att_masks, labels, data_modified = generate_bert_tokens(train_set[2000:3000], max_length, labels_count)\n",
        "save_pickle('/gdrive/MyDrive/w266-final-project-master/w266-final-project-master/FinBERT-QA/data/data_pickle/' + \"input_ids3.pickle\", input_ids)\n",
        "save_pickle('/gdrive/MyDrive/w266-final-project-master/w266-final-project-master/FinBERT-QA/data/data_pickle/' + \"token_type_ids3.pickle\", token_type_ids)\n",
        "save_pickle('/gdrive/MyDrive/w266-final-project-master/w266-final-project-master/FinBERT-QA/data/data_pickle/' + \"att_masks3.pickle\", att_masks)\n",
        "save_pickle('/gdrive/MyDrive/w266-final-project-master/w266-final-project-master/FinBERT-QA/data/data_pickle/' + \"labels3.pickle\", labels)\n",
        "save_pickle('/gdrive/MyDrive/w266-final-project-master/w266-final-project-master/FinBERT-QA/data/data_pickle/' + \"data_modified3.pickle\", data_modified)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Eq57viKLyD4-",
        "outputId": "af4dd3ee-6703-4973-ee34-a60c0bffece2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2329: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ]
        }
      ],
      "source": [
        "input_ids, token_type_ids, att_masks, labels, data_modified = generate_bert_tokens(train_set[3000:4000], max_length, labels_count)\n",
        "save_pickle('/gdrive/MyDrive/w266-final-project-master/w266-final-project-master/FinBERT-QA/data/data_pickle/' + \"input_ids4.pickle\", input_ids)\n",
        "save_pickle('/gdrive/MyDrive/w266-final-project-master/w266-final-project-master/FinBERT-QA/data/data_pickle/' + \"token_type_ids4.pickle\", token_type_ids)\n",
        "save_pickle('/gdrive/MyDrive/w266-final-project-master/w266-final-project-master/FinBERT-QA/data/data_pickle/' + \"att_masks4.pickle\", att_masks)\n",
        "save_pickle('/gdrive/MyDrive/w266-final-project-master/w266-final-project-master/FinBERT-QA/data/data_pickle/' + \"labels4.pickle\", labels)\n",
        "save_pickle('/gdrive/MyDrive/w266-final-project-master/w266-final-project-master/FinBERT-QA/data/data_pickle/' + \"data_modified4.pickle\", data_modified)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ynPNjTFpA9oX",
        "outputId": "a5287d69-5e37-4234-9d15-162f52502eca"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2329: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
          ]
        }
      ],
      "source": [
        "input_ids, token_type_ids, att_masks, labels, data_modified = generate_bert_tokens(train_set[4000:], max_length, labels_count)\n",
        "save_pickle('/gdrive/MyDrive/w266-final-project-master/w266-final-project-master/FinBERT-QA/data/data_pickle/' + \"input_ids5.pickle\", input_ids)\n",
        "save_pickle('/gdrive/MyDrive/w266-final-project-master/w266-final-project-master/FinBERT-QA/data/data_pickle/' + \"token_type_ids5.pickle\", token_type_ids)\n",
        "save_pickle('/gdrive/MyDrive/w266-final-project-master/w266-final-project-master/FinBERT-QA/data/data_pickle/' + \"att_masks5.pickle\", att_masks)\n",
        "save_pickle('/gdrive/MyDrive/w266-final-project-master/w266-final-project-master/FinBERT-QA/data/data_pickle/' + \"labels5.pickle\", labels)\n",
        "save_pickle('/gdrive/MyDrive/w266-final-project-master/w266-final-project-master/FinBERT-QA/data/data_pickle/' + \"data_modified5.pickle\", data_modified)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c2Se0WcC2_VI"
      },
      "outputs": [],
      "source": [
        "# save_pickle('/gdrive/MyDrive/nlp-yuan_code/FinBERT-QA/data/data_pickle/' + \"input_ids5.pickle\", input_ids)\n",
        "# save_pickle('/gdrive/MyDrive/nlp-yuan_code/FinBERT-QA/data/data_pickle/' + \"token_type_ids5.pickle\", token_type_ids)\n",
        "# save_pickle('/gdrive/MyDrive/nlp-yuan_code/FinBERT-QA/data/data_pickle/' + \"att_masks5.pickle\", att_masks)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2IPr2b_ejFC2",
        "outputId": "f6951594-df9d-4879-e8af-2f4e67d4eea6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4000 4000 4000 4000 4000\n",
            "228\n"
          ]
        }
      ],
      "source": [
        "id1 = load_pickle('/gdrive/MyDrive/w266-final-project-master/w266-final-project-master/FinBERT-QA/data/data_pickle/' + \"input_ids1.pickle\")\n",
        "type1 = load_pickle('/gdrive/MyDrive/w266-final-project-master/w266-final-project-master/FinBERT-QA/data/data_pickle/' + \"token_type_ids1.pickle\")\n",
        "mask1 = load_pickle('/gdrive/MyDrive/w266-final-project-master/w266-final-project-master/FinBERT-QA/data/data_pickle/' + \"att_masks1.pickle\")\n",
        "label1 = load_pickle('/gdrive/MyDrive/w266-final-project-master/w266-final-project-master/FinBERT-QA/data/data_pickle/' + \"labels1.pickle\")\n",
        "data_modified1 = load_pickle('/gdrive/MyDrive/w266-final-project-master/w266-final-project-master/FinBERT-QA/data/data_pickle/' + \"data_modified1.pickle\")\n",
        "print(len(id1), len(type1), len(mask1), len(label1), len(data_modified1))\n",
        "print(sum(max(mask1, key = sum)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tdxW1ngfGXNJ",
        "outputId": "fa1902c1-e633-4141-a03e-c2eaab9e91b7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "256 [101, 1327, 1110, 1737, 170, 1671, 11013, 1113, 170, 1671, 3868, 136, 102, 1109, 146, 8900, 144, 16423, 3923, 22383, 1106, 1103, 2548, 119, 1130, 1704, 1103, 1436, 146, 1169, 1474, 1110, 1240, 1671, 11013, 1336, 1129, 1260, 13890, 5225, 119, 1252, 1122, 9113, 1113, 1103, 5607, 1105, 1184, 1122, 1110, 1128, 1328, 1106, 1260, 13890, 119, 7938, 13429, 27452, 1150, 3201, 1283, 1121, 1313, 1113, 1671, 1336, 1260, 13890, 2272, 11928, 117, 1259, 1103, 2616, 1104, 3634, 1147, 7680, 117, 1103, 2616, 1104, 25338, 13556, 1105, 13077, 1105, 1168, 6655, 1105, 3238, 11928, 119, 13429, 27452, 1132, 1737, 789, 6934, 1283, 1121, 1313, 790, 1191, 1147, 5078, 4752, 1172, 1106, 1129, 1283, 175, 1197, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "256 [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "256 [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "228\n"
          ]
        }
      ],
      "source": [
        "# labels0 = []\n",
        "# (bad, good)[x in goodvals].append(x)\n",
        "# print(len(label1), sum(label1), label1[:100])\n",
        "print(len(id1[0]), id1[0])\n",
        "print(len(type1[0]), type1[0])\n",
        "print(len(mask1[0]), mask1[0])\n",
        "print(sum(max(mask1, key = sum)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rbAvUgD3qu75",
        "outputId": "36c35a10-e7c2-4ae2-e0c4-7eec7bdf79cf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4000 4000 4000 4000\n",
            "227\n"
          ]
        }
      ],
      "source": [
        "id2 = load_pickle('/gdrive/MyDrive/w266-final-project-master/w266-final-project-master/FinBERT-QA/data/data_pickle/' + \"input_ids2.pickle\")\n",
        "type2 = load_pickle('/gdrive/MyDrive/w266-final-project-master/w266-final-project-master/FinBERT-QA/data/data_pickle/' + \"token_type_ids2.pickle\")\n",
        "mask2 = load_pickle('/gdrive/MyDrive/w266-final-project-master/w266-final-project-master/FinBERT-QA/data/data_pickle/' + \"att_masks2.pickle\")\n",
        "label2 = load_pickle('/gdrive/MyDrive/w266-final-project-master/w266-final-project-master/FinBERT-QA/data/data_pickle/' + \"labels2.pickle\")\n",
        "data_modified2 = load_pickle('/gdrive/MyDrive/w266-final-project-master/w266-final-project-master/FinBERT-QA/data/data_pickle/' + \"data_modified2.pickle\")\n",
        "print(len(id2), len(type2), len(mask2), len(label2))\n",
        "print(sum(max(mask2, key = sum)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G-4XLngOvpw7",
        "outputId": "b69027de-2352-4588-aaaf-d76122fa86fe"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4000 4000 4000 4000\n",
            "256\n"
          ]
        }
      ],
      "source": [
        "id3 = load_pickle('/gdrive/MyDrive/w266-final-project-master/w266-final-project-master/FinBERT-QA/data/data_pickle/' + \"input_ids3.pickle\")\n",
        "type3 = load_pickle('/gdrive/MyDrive/w266-final-project-master/w266-final-project-master/FinBERT-QA/data/data_pickle/' + \"token_type_ids3.pickle\")\n",
        "mask3 = load_pickle('/gdrive/MyDrive/w266-final-project-master/w266-final-project-master/FinBERT-QA/data/data_pickle/' + \"att_masks3.pickle\")\n",
        "label3 = load_pickle('/gdrive/MyDrive/w266-final-project-master/w266-final-project-master/FinBERT-QA/data/data_pickle/' + \"labels3.pickle\")\n",
        "data_modified3 = load_pickle('/gdrive/MyDrive/w266-final-project-master/w266-final-project-master/FinBERT-QA/data/data_pickle/' + \"data_modified3.pickle\")\n",
        "print(len(id3), len(type3), len(mask3), len(label3))\n",
        "print(sum(max(mask3, key = sum)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SEoJXLzOwAR5",
        "outputId": "55259a96-7df1-488f-d918-db2ef37355db"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4000 4000 4000 4000\n",
            "229\n"
          ]
        }
      ],
      "source": [
        "id4 = load_pickle('/gdrive/MyDrive/w266-final-project-master/w266-final-project-master/FinBERT-QA/data/data_pickle/' + \"input_ids4.pickle\")\n",
        "type4 = load_pickle('/gdrive/MyDrive/w266-final-project-master/w266-final-project-master/FinBERT-QA/data/data_pickle/' + \"token_type_ids4.pickle\")\n",
        "mask4 = load_pickle('/gdrive/MyDrive/w266-final-project-master/w266-final-project-master/FinBERT-QA/data/data_pickle/' + \"att_masks4.pickle\")\n",
        "label4 = load_pickle('/gdrive/MyDrive/w266-final-project-master/w266-final-project-master/FinBERT-QA/data/data_pickle/' + \"labels4.pickle\")\n",
        "data_modified4 = load_pickle('/gdrive/MyDrive/w266-final-project-master/w266-final-project-master/FinBERT-QA/data/data_pickle/' + \"data_modified4.pickle\")\n",
        "print(len(id4), len(type4), len(mask4), len(label4))\n",
        "print(sum(max(mask4, key = sum)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uQe1lPa1wVfE",
        "outputId": "3869da78-0db9-47b9-9b95-68dbf0debaf8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "6732 6732 6732 6732\n",
            "256\n"
          ]
        }
      ],
      "source": [
        "id5 = load_pickle('/gdrive/MyDrive/w266-final-project-master/w266-final-project-master/FinBERT-QA/data/data_pickle/' + \"input_ids5.pickle\")\n",
        "type5 = load_pickle('/gdrive/MyDrive/w266-final-project-master/w266-final-project-master/FinBERT-QA/data/data_pickle/' + \"token_type_ids5.pickle\")\n",
        "mask5 = load_pickle('/gdrive/MyDrive/w266-final-project-master/w266-final-project-master/FinBERT-QA/data/data_pickle/' + \"att_masks5.pickle\")\n",
        "label5 = load_pickle('/gdrive/MyDrive/w266-final-project-master/w266-final-project-master/FinBERT-QA/data/data_pickle/' + \"labels5.pickle\")\n",
        "data_modified5 = load_pickle('/gdrive/MyDrive/w266-final-project-master/w266-final-project-master/FinBERT-QA/data/data_pickle/' + \"data_modified5.pickle\")\n",
        "print(len(id5), len(type5), len(mask5), len(label5))\n",
        "print(sum(max(mask5, key = sum)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "msJ662MFwm0h",
        "outputId": "5c7a38c3-557b-41ee-f5d0-d4c4c5e8e8cf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "22732 22732 22732 22732\n",
            "256\n"
          ]
        }
      ],
      "source": [
        "id_all = id1 + id2 + id3 + id4 + id5\n",
        "type_all = type1 + type2 + type3 + type4 + type5\n",
        "mask_all = mask1 + mask2 + mask3 + mask4 + mask5\n",
        "label_all = label1 + label2 + label3 + label4 + label5\n",
        "data_modified_all = data_modified1 + data_modified2 + data_modified3 + data_modified4 + data_modified5\n",
        "print(len(id_all), len(type_all), len(mask_all), len(label_all))\n",
        "print(sum(max(mask_all, key = sum)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jN3FFg9Alwgd",
        "outputId": "690bf63c-3df5-4204-c640-7387f3853a86"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2329: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ]
        }
      ],
      "source": [
        "input_ids, token_type_ids, att_masks, labels, data_modified = generate_bert_tokens(valid_set, max_length, labels_count)\n",
        "save_pickle('/gdrive/MyDrive/w266-final-project-master/w266-final-project-master/FinBERT-QA/data/data_pickle/' + \"input_ids_val.pickle\", input_ids)\n",
        "save_pickle('/gdrive/MyDrive/w266-final-project-master/w266-final-project-master/FinBERT-QA/data/data_pickle/' + \"token_type_val.pickle\", token_type_ids)\n",
        "save_pickle('/gdrive/MyDrive/w266-final-project-master/w266-final-project-master/FinBERT-QA/data/data_pickle/' + \"att_masks_val.pickle\", att_masks)\n",
        "save_pickle('/gdrive/MyDrive/w266-final-project-master/w266-final-project-master/FinBERT-QA/data/data_pickle/' + \"labels_val.pickle\", labels)\n",
        "save_pickle('/gdrive/MyDrive/w266-final-project-master/w266-final-project-master/FinBERT-QA/data/data_pickle/' + \"data_modified_val.pickle\", data_modified)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fBgJifopLQck",
        "outputId": "0f5d803b-34db-4403-f8e1-83fb320dc7ec"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2528 2528 2528 2528\n",
            "237\n"
          ]
        }
      ],
      "source": [
        "id_val = load_pickle('/gdrive/MyDrive/w266-final-project-master/w266-final-project-master/FinBERT-QA/data/data_pickle/' + \"input_ids_val.pickle\")\n",
        "type_val = load_pickle('/gdrive/MyDrive/w266-final-project-master/w266-final-project-master/FinBERT-QA/data/data_pickle/' + \"token_type_val.pickle\")\n",
        "mask_val = load_pickle('/gdrive/MyDrive/w266-final-project-master/w266-final-project-master/FinBERT-QA/data/data_pickle/' + \"att_masks_val.pickle\")\n",
        "label_val = load_pickle('/gdrive/MyDrive/w266-final-project-master/w266-final-project-master/FinBERT-QA/data/data_pickle/' + \"labels_val.pickle\")\n",
        "data_modified_val = load_pickle('/gdrive/MyDrive/w266-final-project-master/w266-final-project-master/FinBERT-QA/data/data_pickle/' + \"data_modified_val.pickle\")\n",
        "print(len(id_val), len(type_val), len(mask_val), len(label_val))\n",
        "print(sum(max(mask_val, key = sum)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J36OhXaRL8fZ",
        "outputId": "c3bf294c-2f56-470b-f1bb-7173218d35ff"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2329: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ]
        }
      ],
      "source": [
        "input_ids, token_type_ids, att_masks, labels, test_set_modified = generate_bert_tokens(test_set, max_length, labels_count)\n",
        "save_pickle('/gdrive/MyDrive/w266-final-project-master/w266-final-project-master/FinBERT-QA/data/data_pickle/' + \"input_ids_test.pickle\", input_ids)\n",
        "save_pickle('/gdrive/MyDrive/w266-final-project-master/w266-final-project-master/FinBERT-QA/data/data_pickle/' + \"token_type_test.pickle\", token_type_ids)\n",
        "save_pickle('/gdrive/MyDrive/w266-final-project-master/w266-final-project-master/FinBERT-QA/data/data_pickle/' + \"att_masks_test.pickle\", att_masks)\n",
        "save_pickle('/gdrive/MyDrive/w266-final-project-master/w266-final-project-master/FinBERT-QA/data/data_pickle/' + \"labels_test.pickle\", labels)\n",
        "save_pickle('/gdrive/MyDrive/w266-final-project-master/w266-final-project-master/FinBERT-QA/data/data_pickle/' + \"test_set_modified.pickle\", test_set_modified)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vtkQj0yuMSHT",
        "outputId": "eff3498c-9b43-4f3c-e691-afd254bcd4a6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "999 999 999 999 999\n",
            "226\n"
          ]
        }
      ],
      "source": [
        "id_test = load_pickle('/gdrive/MyDrive/w266-final-project-master/w266-final-project-master/FinBERT-QA/data/data_pickle/' + \"input_ids_test.pickle\")\n",
        "type_test = load_pickle('/gdrive/MyDrive/w266-final-project-master/w266-final-project-master/FinBERT-QA/data/data_pickle/' + \"token_type_test.pickle\")\n",
        "mask_test = load_pickle('/gdrive/MyDrive/w266-final-project-master/w266-final-project-master/FinBERT-QA/data/data_pickle/' + \"att_masks_test.pickle\")\n",
        "label_test = load_pickle('/gdrive/MyDrive/w266-final-project-master/w266-final-project-master/FinBERT-QA/data/data_pickle/' + \"labels_test.pickle\")\n",
        "test_set_modified = load_pickle('/gdrive/MyDrive/w266-final-project-master/w266-final-project-master/FinBERT-QA/data/data_pickle/' + \"test_set_modified.pickle\")\n",
        "\n",
        "print(len(id_test), len(type_test), len(mask_test), len(label_test), len(test_set_modified))\n",
        "print(sum(max(mask_test, key = sum)))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Creating a BERT classification model "
      ],
      "metadata": {
        "id": "uAGmXYJHgxYi"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "58YNBDglqlQK"
      },
      "outputs": [],
      "source": [
        "def create_bert_model(max_length):\n",
        "    \"\"\"\n",
        "    Build a simple classification model with BERT. Use the CLS Token output for classification purposes.\n",
        "    \"\"\"\n",
        "    \n",
        "    ### YOUR CODE HERE\n",
        "    train_layers = 2\n",
        "    hidden_size = 100\n",
        "    dropout = 0.3\n",
        "    learning_rate= 0.00005\n",
        "    bert_model = TFBertModel.from_pretrained('bert-base-cased')\n",
        "\n",
        "    # max_length = 64\n",
        "\n",
        "    # #restrict training to the train_layers outer transformer layers\n",
        "    # if not train_layers == -1:\n",
        "\n",
        "    #         retrain_layers = []\n",
        "\n",
        "    #         for retrain_layer_number in range(train_layers):\n",
        "\n",
        "    #             layer_code = '_' + str(11 - retrain_layer_number)\n",
        "    #             retrain_layers.append(layer_code)\n",
        "\n",
        "    #         for w in bert_model.weights:\n",
        "    #             if not any([x in w.name for x in retrain_layers]):\n",
        "    #                 w._trainable = False\n",
        "\n",
        "    for i in range(12-train_layers):\n",
        "      bert_model.bert.encoder.layer[i].trainable = False\n",
        "\n",
        "    #restrict training to the train_layers outer transformer layers\n",
        "    input_ids = tf.keras.layers.Input(shape=(max_length,), dtype=tf.int64, name='input_ids_layer') #--SOLUTION--\n",
        "    token_type_ids = tf.keras.layers.Input(shape=(max_length,), dtype=tf.int64, name='token_type_ids_layer')\n",
        "    attention_mask = tf.keras.layers.Input(shape=(max_length,), dtype=tf.int64, name='attention_mask_layer')\n",
        "\n",
        "    bert_inputs = {'input_ids': input_ids,\n",
        "                   'token_type_ids': token_type_ids,\n",
        "                   'attention_mask': attention_mask}         \n",
        "\n",
        "    bert_out = bert_model(bert_inputs) \n",
        "\n",
        "    cls_token = bert_out[0][:,0,:]\n",
        "    #cls_token = bert_out[1]\n",
        "\n",
        "    hidden = tf.keras.layers.Dense(hidden_size, activation='relu', name='hidden_layer')(cls_token)\n",
        "    hidden = tf.keras.layers.Dropout(dropout)(hidden)  \n",
        "\n",
        "    classification = tf.keras.layers.Dense(1, activation='sigmoid',name='classification_layer')(hidden)\n",
        "\n",
        "    \n",
        "    classification_model = tf.keras.Model(inputs=[input_ids, token_type_ids, attention_mask], outputs=[classification])\n",
        "    \n",
        "    classification_model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate),\n",
        "                            loss=tf.keras.losses.BinaryCrossentropy(from_logits=False), \n",
        "                            metrics='accuracy') \n",
        "    ### END YOUR CODE\n",
        "    \n",
        "    return classification_model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 159,
          "referenced_widgets": [
            "9a39a0b3e064433cb748e109c0f7113f",
            "12abd0d3661a4a00a00a895cbaefb0e3",
            "8c04cc2c280a4a0f8d7c97f66ee28813",
            "fd45720088fd4ecea6db1f12041e9bcf",
            "74229ab307ab422eabe0357efc28e761",
            "6ecdd73971844c9b8247bd6a22b63177",
            "f520d43e681f4f7fae079a0283c9c4cd",
            "f151e53688904c6b9f966ddd11da42ac",
            "d31ca70b1c4348c7a5e70fd59f7423ae",
            "ffb95d76e9e34469a621d753b177d5a7",
            "5ea8a994f289407598c51b58b21ed004"
          ]
        },
        "id": "ULaWJZqSNsry",
        "outputId": "1d82f55e-d19f-4cde-93f6-5c4b8942cb71"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading tf_model.h5:   0%|          | 0.00/502M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9a39a0b3e064433cb748e109c0f7113f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some layers from the model checkpoint at bert-base-cased were not used when initializing TFBertModel: ['nsp___cls', 'mlm___cls']\n",
            "- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the layers of TFBertModel were initialized from the model checkpoint at bert-base-cased.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
          ]
        }
      ],
      "source": [
        "model = create_bert_model(max_length) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7TgYR02g0GHs"
      },
      "outputs": [],
      "source": [
        "#clean up\n",
        "del input_ids\n",
        "del token_type_ids\n",
        "del att_masks\n",
        "del labels"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Checking the the size of the embeddings"
      ],
      "metadata": {
        "id": "WVqP-HhNnxnK"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OMZWLjf-7GQ_",
        "outputId": "87da7615-1176-48c7-ccf9-3b48d7b60696"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "256\n",
            "256\n",
            "256\n"
          ]
        }
      ],
      "source": [
        "n = len(id1[0])\n",
        "for i in range(len(id1)):\n",
        "  if len(id1[i]) != n:\n",
        "    print(i, len(id1[i]))\n",
        "    break\n",
        "print(n)\n",
        "\n",
        "n = len(type1[0])\n",
        "for i in range(len(type1)):\n",
        "  if len(type1[i]) != n:\n",
        "    print(i, len(type1[i]))\n",
        "    break\n",
        "print(n)\n",
        "\n",
        "n = len(mask1[0])\n",
        "for i in range(len(mask1)):\n",
        "  if len(mask1[i]) != n:\n",
        "    print(i, len(mask1[i]))\n",
        "    break\n",
        "print(n)\n",
        "\n",
        "n = len(label1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bBI4BglBmiQ8"
      },
      "outputs": [],
      "source": [
        "# bert_avg_model_history = model.fit([np.array(id1[:100]), np.array(type1[:100]), np.array(mask1[:100])],np.array(label1[:100]),\n",
        "#                                    validation_data=([np.array(id1[:10]), np.array(type1[:10]), np.array(mask1[:10])],np.array(label1[:10])),\n",
        "#                                    batch_size=8,epochs=1)  "
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model fitting and saving weights"
      ],
      "metadata": {
        "id": "ry-8n0J8n5G7"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mO2uCfpQwDXv"
      },
      "outputs": [],
      "source": [
        "bert_avg_model_all = model.fit([np.array(id_all), np.array(type_all), np.array(mask_all)],np.array(label_all),\n",
        "                                   validation_data=([np.array(id_val), np.array(type_val), np.array(mask_val)],np.array(label_val)),\n",
        "                                   batch_size=8,epochs=1) \n",
        "model.save_weights(f\"bert_avg_model_L{labels_count}_{max_length}.h5\")\n",
        "print(model.summary())"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Creating BERT classification model and loading weights from saved model"
      ],
      "metadata": {
        "id": "p9rGToNkoN4x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model2 = create_bert_model(max_length)\n",
        "# model2.load_weights(f\"bert_avg_model_L{labels_count}_{max_length}.h5\")\n",
        "model2.load_weights(f\"model_weight_{labels_count}_{max_length}.h5\")\n",
        "print(model2.summary())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SL6hUkhDOTeO",
        "outputId": "f96d2caa-d6cb-4713-9cc3-e0cd67e7fd10"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some layers from the model checkpoint at bert-base-cased were not used when initializing TFBertModel: ['nsp___cls', 'mlm___cls']\n",
            "- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the layers of TFBertModel were initialized from the model checkpoint at bert-base-cased.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " attention_mask_layer (InputLay  [(None, 256)]       0           []                               \n",
            " er)                                                                                              \n",
            "                                                                                                  \n",
            " input_ids_layer (InputLayer)   [(None, 256)]        0           []                               \n",
            "                                                                                                  \n",
            " token_type_ids_layer (InputLay  [(None, 256)]       0           []                               \n",
            " er)                                                                                              \n",
            "                                                                                                  \n",
            " tf_bert_model_1 (TFBertModel)  TFBaseModelOutputWi  108310272   ['attention_mask_layer[0][0]',   \n",
            "                                thPoolingAndCrossAt               'input_ids_layer[0][0]',        \n",
            "                                tentions(last_hidde               'token_type_ids_layer[0][0]']   \n",
            "                                n_state=(None, 256,                                               \n",
            "                                 768),                                                            \n",
            "                                 pooler_output=(Non                                               \n",
            "                                e, 768),                                                          \n",
            "                                 past_key_values=No                                               \n",
            "                                ne, hidden_states=N                                               \n",
            "                                one, attentions=Non                                               \n",
            "                                e, cross_attentions                                               \n",
            "                                =None)                                                            \n",
            "                                                                                                  \n",
            " tf.__operators__.getitem_1 (Sl  (None, 768)         0           ['tf_bert_model_1[0][0]']        \n",
            " icingOpLambda)                                                                                   \n",
            "                                                                                                  \n",
            " hidden_layer (Dense)           (None, 100)          76900       ['tf.__operators__.getitem_1[0][0\n",
            "                                                                 ]']                              \n",
            "                                                                                                  \n",
            " dropout_75 (Dropout)           (None, 100)          0           ['hidden_layer[0][0]']           \n",
            "                                                                                                  \n",
            " classification_layer (Dense)   (None, 1)            101         ['dropout_75[0][0]']             \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 108,387,273\n",
            "Trainable params: 37,508,553\n",
            "Non-trainable params: 70,878,720\n",
            "__________________________________________________________________________________________________\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model prediction with test data"
      ],
      "metadata": {
        "id": "WlRNi-nOogNd"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P5SbvqP6Qp0U"
      },
      "outputs": [],
      "source": [
        "# bert_avg_model_predict = model.predict([np.array(id_test), np.array(type_test), np.array(mask_test)]) \n",
        "bert_avg_model_predict = model2.predict([np.array(id_test), np.array(type_test), np.array(mask_test)]) "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# bert_avg_model_predict[0]\n"
      ],
      "metadata": {
        "id": "REGF6J_oesOE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Test Model accuracy"
      ],
      "metadata": {
        "id": "p196wt1cok6C"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0evoG9iXekls",
        "outputId": "0f556ad0-b636-4ea1-b621-7b2a4d1aff36"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "999\n",
            "[0.02918151 0.03474799 0.1118913  0.27082923 0.07827142 0.09202135\n",
            " 0.01853544 0.07087332 0.6603873  0.00728986]\n",
            "[1, 0, 0, 1, 0, 0, 0, 0, 0, 0]\n",
            "[[101, 9743, 1139, 2252, 112, 188, 1671, 2653, 1139, 1671, 136, 102, 2066, 1121, 1139, 1319, 2541, 113, 146, 1821, 1136, 1126, 23195, 114, 131, 1130, 1901, 1106, 11128, 1112, 112, 1671, 2467, 112, 113, 9377, 1568, 1413, 1367, 164, 122, 166, 114, 1240, 109, 11975, 113, 1137, 3451, 114, 1209, 1129, 2548, 1106, 199, 1405, 110, 2191, 118, 6233, 3641, 117, 1113, 23070, 12342, 119, 1188, 7450, 1106, 1240, 9377, 1568, 1413, 199, 4667, 117, 1134, 1110, 1170, 1155, 1240, 112, 27939, 1106, 2467, 112, 117, 22346, 1116, 117, 1105, 1260, 11243, 1116, 118, 1177, 117, 1343, 1274, 112, 189, 4851, 1122, 119, 8636, 1104, 1103, 1405, 110, 1110, 1260, 13890, 5225, 1113, 1413, 199, 1765, 117, 1191, 1128, 1138, 1536, 27522, 2165, 2467, 1111, 1122, 1106, 2187, 132, 1133, 117, 1107, 1251, 1692, 117, 1128, 1209, 12972, 1120, 1655, 122, 120, 123, 1104, 1103, 1405, 110, 117, 1113, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [101, 9743, 1139, 2252, 112, 188, 1671, 2653, 1139, 1671, 136, 102, 143, 9741, 1592, 7538, 1132, 2767, 1121, 2877, 1105, 1352, 2467, 7538, 119, 1249, 170, 6753, 25543, 1128, 12972, 1155, 1104, 1343, 119, 5533, 117, 1175, 1110, 170, 3719, 1114, 143, 9741, 1592, 1165, 1128, 1132, 4071, 5016, 119, 2191, 4071, 119, 16304, 143, 9741, 1592, 7538, 1132, 2140, 3325, 1206, 1103, 11440, 1105, 1103, 7775, 117, 1177, 1128, 2653, 1544, 117, 1152, 2653, 1544, 119, 1252, 1165, 1128, 112, 1231, 2191, 4071, 117, 1128, 2653, 1241, 26853, 119, 1188, 1110, 1184, 1110, 3337, 2752, 1106, 1112, 1103, 2191, 6233, 3641, 119, 1409, 1128, 1132, 1241, 4071, 1105, 2191, 4071, 1112, 146, 1821, 117, 1240, 11440, 15539, 1147, 185, 1186, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [101, 9743, 1139, 2252, 112, 188, 1671, 2653, 1139, 1671, 136, 102, 1327, 6665, 1202, 146, 1138, 136, 5230, 5562, 2716, 136, 3949, 170, 2366, 1554, 1159, 2261, 119, 6955, 1120, 1122, 1111, 170, 1214, 1137, 1177, 1105, 1173, 1267, 1164, 9241, 170, 1402, 119, 1337, 1163, 117, 146, 3055, 3310, 170, 11858, 1313, 119, 146, 1821, 2191, 118, 4071, 1105, 1139, 2467, 1110, 3023, 27450, 119, 4187, 1106, 1293, 1139, 7550, 2653, 1143, 117, 1139, 1671, 1547, 1301, 170, 2337, 1808, 1114, 7284, 1185, 10009, 119, 1438, 117, 146, 112, 1396, 1151, 1120, 1142, 1111, 2385, 170, 1374, 1201, 119, 1573, 117, 1256, 1463, 1139, 1671, 2467, 1110, 27450, 117, 146, 2653, 1991, 4857, 1517, 170, 2370, 119, 1130, 1546, 1106, 1601, 1103, 2239, 1114, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [101, 13429, 1895, 2467, 1113, 1554, 118, 1159, 2261, 116, 1671, 18155, 102, 1130, 1754, 117, 1251, 2467, 1128, 7379, 1110, 27522, 2165, 2693, 1187, 1122, 1338, 1121, 119, 7993, 1240, 1859, 1240, 27522, 2165, 2467, 1110, 109, 3102, 117, 1288, 119, 7947, 1107, 1713, 1115, 1114, 170, 1671, 1256, 1112, 170, 6753, 22574, 1251, 1671, 11928, 1115, 8681, 1106, 1103, 6957, 1104, 1240, 1671, 2467, 1110, 1260, 13890, 5225, 117, 7914, 1103, 1509, 2971, 1104, 3641, 1128, 112, 1325, 1138, 1106, 2653, 119, 1109, 13020, 2346, 3265, 1144, 7424, 1104, 1363, 1869, 1105, 5136, 1106, 1440, 1120, 1259, 3641, 5600, 119, 1409, 1240, 1703, 2467, 1110, 5859, 1154, 170, 2299, 3641, 26083, 1166, 1476, 1665, 3641, 1679, 109, 122, 7379, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [101, 13429, 1895, 2467, 1113, 1554, 118, 1159, 2261, 116, 1671, 18155, 102, 11336, 4060, 19364, 2217, 4385, 1111, 1671, 11928, 1132, 2412, 1136, 27522, 2165, 117, 1133, 1103, 3254, 13601, 1566, 1121, 1313, 1106, 1103, 2261, 1105, 1171, 1110, 1136, 1737, 1671, 3201, 1105, 1191, 1152, 112, 1231, 6573, 1111, 1115, 1122, 1110, 27522, 2165, 2467, 119, 146, 1274, 112, 189, 1341, 1610, 13764, 1158, 2607, 1115, 117, 1133, 146, 1821, 1136, 170, 3641, 4545, 1137, 23195, 119, 1109, 1832, 1104, 1240, 3243, 3166, 1106, 1129, 1419, 2818, 2492, 119, 1247, 1110, 1185, 107, 1431, 107, 1303, 119, 1192, 4597, 112, 189, 2320, 1106, 3368, 1146, 1103, 1168, 3713, 117, 1133, 1119, 2762, 112, 189, 2320, 1106, 1231, 4060, 19364, 2217, 1343, 1829, 113, 1137, 12912, 1128, 114, 1177, 1341, 4727, 1164, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [101, 13429, 1895, 2467, 1113, 1554, 118, 1159, 2261, 116, 1671, 18155, 102, 1327, 6665, 1202, 146, 1138, 136, 5230, 5562, 2716, 136, 3949, 170, 2366, 1554, 1159, 2261, 119, 6955, 1120, 1122, 1111, 170, 1214, 1137, 1177, 1105, 1173, 1267, 1164, 9241, 170, 1402, 119, 1337, 1163, 117, 146, 3055, 3310, 170, 11858, 1313, 119, 146, 1821, 2191, 118, 4071, 1105, 1139, 2467, 1110, 3023, 27450, 119, 4187, 1106, 1293, 1139, 7550, 2653, 1143, 117, 1139, 1671, 1547, 1301, 170, 2337, 1808, 1114, 7284, 1185, 10009, 119, 1438, 117, 146, 112, 1396, 1151, 1120, 1142, 1111, 2385, 170, 1374, 1201, 119, 1573, 117, 1256, 1463, 1139, 1671, 2467, 1110, 27450, 117, 146, 2653, 1991, 4857, 1517, 170, 2370, 119, 1130, 1546, 1106, 1601, 1103, 2239, 1114, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [101, 2825, 3225, 118, 11336, 19094, 1906, 4326, 1129, 170, 3518, 16409, 11741, 2217, 136, 102, 1192, 1274, 112, 189, 1444, 170, 1520, 117, 1128, 1444, 1106, 11902, 1154, 1103, 1671, 1105, 2437, 1184, 1144, 2014, 119, 1731, 1263, 1144, 1175, 1151, 170, 5637, 1106, 1294, 3769, 2283, 136, 1327, 13286, 1785, 5903, 1111, 1103, 1671, 136, 4785, 1120, 1103, 1669, 118, 1166, 118, 1669, 1849, 1111, 1296, 3317, 4370, 1112, 1218, 1112, 1296, 1413, 8926, 11013, 117, 1105, 1525, 18741, 1116, 1115, 1336, 4056, 119, 1409, 1122, 112, 188, 1936, 117, 1525, 1861, 24180, 1164, 2208, 118, 118, 1241, 5003, 118, 1105, 118, 16597, 1112, 1218, 1112, 3294, 119, 1135, 112, 188, 1696, 1106, 19774, 1103, 2686, 1104, 1103, 1671, 1106, 2437, 113, 122, 114, 189, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [101, 2825, 3225, 118, 11336, 19094, 1906, 4326, 1129, 170, 3518, 16409, 11741, 2217, 136, 102, 1302, 117, 1136, 1113, 6030, 140, 117, 1618, 119, 2098, 1126, 107, 1807, 1103, 1413, 107, 1260, 11243, 113, 1413, 1853, 1113, 1240, 9377, 1568, 114, 119, 3446, 112, 188, 1103, 189, 2149, 4043, 3641, 3342, 1113, 1122, 119, 1109, 7953, 1111, 1142, 1413, 1383, 2218, 13004, 1115, 1128, 1538, 1321, 1154, 1103, 3300, 117, 1105, 4208, 118, 1122, 1110, 2609, 1106, 1103, 5795, 5022, 1121, 1103, 1671, 119, 1448, 1104, 1103, 1378, 8477, 1538, 1129, 2276, 119, 1192, 1127, 2191, 118, 4071, 1105, 1125, 170, 5795, 5022, 1111, 1103, 1214, 119, 1192, 1127, 170, 3547, 1114, 5795, 18155, 1121, 2191, 118, 6233, 119, 1192, 1215, 1141, 1104, 1103, 13027, 4069, 1106, 2482, 1240, 5795, 3811, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [101, 2825, 3225, 118, 11336, 19094, 1906, 4326, 1129, 170, 3518, 16409, 11741, 2217, 136, 102, 15559, 3073, 4163, 2386, 1826, 1431, 1129, 2364, 2200, 1166, 1103, 1669, 3073, 4163, 2386, 119, 1252, 1191, 1122, 1110, 1146, 1106, 170, 1214, 118, 1128, 1169, 1198, 11013, 1172, 119, 1249, 1106, 1103, 4301, 4233, 118, 1128, 1169, 3232, 1130, 7926, 2875, 1619, 117, 1133, 1128, 1431, 1129, 1682, 1106, 1508, 1122, 1107, 1103, 1269, 1298, 1187, 1128, 1508, 1155, 1240, 1168, 1671, 11928, 119, 1409, 1128, 112, 1231, 170, 6753, 25543, 118, 1115, 1156, 1129, 23070, 140, 119, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [101, 3949, 170, 4891, 1114, 1822, 2199, 2603, 1113, 1353, 1671, 102, 146, 1274, 112, 189, 1221, 1277, 1164, 1293, 2377, 11453, 1250, 117, 1177, 1175, 1547, 1129, 1199, 5812, 9971, 113, 174, 119, 176, 119, 1674, 1103, 2199, 2603, 2215, 4836, 117, 1202, 1128, 1243, 170, 23290, 1191, 1128, 2653, 1228, 1346, 3576, 119, 114, 119, 27853, 1343, 5812, 9971, 131, 1109, 2199, 1113, 1128, 2377, 4891, 2736, 2385, 1353, 119, 3177, 11741, 3680, 170, 2113, 1187, 1128, 1132, 1107, 1103, 1362, 117, 1133, 1122, 3093, 1304, 2620, 1115, 1128, 1169, 1243, 1167, 2199, 1190, 1115, 1113, 170, 1620, 110, 13008, 5151, 1532, 117, 174, 119, 176, 119, 1858, 3085, 10009, 119, 1573, 117, 1122, 3093, 170, 1185, 118, 3575, 1200, 1106, 1136, 2653, 1171, 1128, 2377, 4891, 1105, 17557, 1103, 1948, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]\n",
            "Test accuracy: 0.912912905216217\n"
          ]
        }
      ],
      "source": [
        "print(len(bert_avg_model_predict))\n",
        "print(np.squeeze(bert_avg_model_predict[:10]))\n",
        "print(label_test[:10])\n",
        "print(id_test[:10])\n",
        "m = tf.keras.metrics.BinaryAccuracy()\n",
        "m.update_state(label_test, np.squeeze(bert_avg_model_predict))\n",
        "print('Test accuracy:', float(m.result()))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model evaluation with Ranking Metrics"
      ],
      "metadata": {
        "id": "Q3KaVZSso1rg"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0TWzw8vf4DrG",
        "outputId": "c76ed8aa-2dd8-4813-f2d3-8b2438e9f786"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "999 999\n",
            "    qid                         ans_label    cand  bert_score\n",
            "0    48  [108062, 401260, 329810, 512151]  512151    0.029182\n",
            "1    48  [108062, 401260, 329810, 512151]  252843    0.034748\n",
            "2    48  [108062, 401260, 329810, 512151]  272279    0.111891\n",
            "3    54          [590775, 109546, 511651]  590775    0.270829\n",
            "4    54          [590775, 109546, 511651]  192843    0.078271\n",
            "5    54          [590775, 109546, 511651]  272279    0.092021\n",
            "6    60                          [381151]  291717    0.018535\n",
            "7    60                          [381151]  524134    0.070873\n",
            "8    60                          [381151]  183500    0.660387\n",
            "9    80                          [252473]  210673    0.007290\n",
            "10   80                          [252473]  170511    0.016846\n",
            "11   80                          [252473]   37070    0.008381\n",
            "12  444  [573518, 175824, 483282, 479203]  175824    0.154781\n",
            "13  444  [573518, 175824, 483282, 479203]  479203    0.861560\n",
            "14  444  [573518, 175824, 483282, 479203]  573518    0.926755\n",
            "15  475                          [366761]  366761    0.990035\n",
            "16  475                          [366761]    1873    0.080092\n",
            "17  475                          [366761]  512803    0.085961\n",
            "18  487                          [399115]   12382    0.060390\n",
            "19  487                          [399115]   44916    0.025779\n",
            "[[48, [108062, 401260, 329810, 512151], [512151, 252843, 272279], [0.02918151021003723, 0.03474798798561096, 0.11189129948616028]], [54, [590775, 109546, 511651], [590775, 192843, 272279], [0.2708292305469513, 0.07827141880989075, 0.09202134609222412]], [60, [381151], [291717, 524134, 183500], [0.01853543519973755, 0.07087332010269165, 0.6603872776031494]]]\n",
            "Mean Reciprocal Rank (MRR): 0.6276276276276276\n",
            "Mean average Precision (MAP) 0.6276276276276276\n",
            "Normalized Discounted Cumulative Gain (NDCG) 0.9908590055295612\n"
          ]
        }
      ],
      "source": [
        "print(len(test_set_modified), len(id_test))\n",
        "\n",
        "temp = pd.DataFrame(test_set_modified)\n",
        "temp.columns = ['qid', 'ans_label', 'cand']\n",
        "temp['bert_score'] = np.squeeze(bert_avg_model_predict)\n",
        "temp2 = temp.groupby('qid').agg({'ans_label': 'first', 'cand': lambda x: tuple(x), 'bert_score': lambda x: tuple(x)}).applymap(list).reset_index()\n",
        "print(temp.head(20))\n",
        "test_set_bert_score_list = temp2.values.tolist()\n",
        "print(test_set_bert_score_list[:3])\n",
        "\n",
        "rr, ap, cg = run_baseline(test_set_bert_score_list, top_k)\n",
        "\n",
        "print('Mean Reciprocal Rank (MRR):', np.mean(rr))\n",
        "print('Mean average Precision (MAP)', np.mean(ap))\n",
        "print('Normalized Discounted Cumulative Gain (NDCG)', np.mean(cg))\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Example Question, Answer from the above result (ranking)"
      ],
      "metadata": {
        "id": "7SQIRgXOpCm8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(qid_to_text[444])\n",
        "print(docid_to_text[573518],'\\n', docid_to_text[479203],'\\n', docid_to_text[175824])"
      ],
      "metadata": {
        "id": "UJvlocT_hLj4",
        "outputId": "1abfdbb0-97a3-40b6-ec56-e47e96e1926f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Why do most banks in Canada charge monthly fee?\n",
            "Arguably, \"because they can\".  Canada's banking industry is dominated by five chartered banks who by virtue of their size, pretty much determine how banking is done in Canada. Yes, they have to abide by government regulation, but they carry enough weight to influence government and to some extent shape the regulation they have to follow. While this situation makes Canada's financial system very stable and efficient, it also permits anti-competitive behavior.  There was a time (when U.S. banks were not permitted to operate across state lines) when the smallest of Canada's \"big 5\" was bigger than the biggest U.S. bank, despite our economy having always been about 1/10 the size of the U.S. That scale and their small number gives the \"big 5\" the ability to invest heavily in and collaborate on whatever they decide to be in their own interest. So, if they want to charge fees, they do. \n",
            " You have to check your contract to be sure what is it you're paying for. Typically, you get some of the following features which can be unavailable to you in banks which don't charge a monthly fee: Arguably, these expenses could be paid by the interest rates your money earn to the bank. Notice how banks which don't charge a fee usually require you to have a minimum amount of cash in your account or a minimum monthly cash flow. When you pay for your bank's services in cash, there's no such restrictions. I'm not sure if typical banks in the UK would take away your credit card if you lose your job and don't qualify for that kind of card any more, but I do know banks who would. The choice is yours, and while it's indeed sad that you don't have this kind of choice in Canada, it's also not like you're paying solely for the privilege of letting them invest your money behind your back. \n",
            " Lending isn't profitable when interest rates are this low.  Consider what's involved to offer a savings or checking account.  The bank must maintain branches with tellers.  The bank has to pay rent (or buy and pay property taxes and utilities).  The bank has to pay salaries.  The bank has to maintain cash so as to make change.  And pay for insurance against robbery.  All of that costs money.   At 6% interest, a bank can sort of make money.  Not great money, but it takes in more than it has to pay out.  At 4% interest, which is about where ten year mortgage rates are in Canada, the bank doesn't make enough margin.  They are better off selling the loan and closing their branches than offering free checking accounts.   An additional problem is that banks tend to make money from overdraft fees.  But there's been a move to limit overdraft fees, as they target the most economically vulnerable.  So Canadian banks tend to charge monthly fees instead.  UK banks may also start charging monthly fees if interest rates stay low and other fees get curtailed.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e3axLTgE8Kig"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "machine_shape": "hm",
      "name": "QA_Pipeline_bert.ipynb",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "919632840d134dd3897e07e565790047": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3b2547e5cc094800af09613a4e920057",
              "IPY_MODEL_c11e480a6f79441498d91ffaf82ca468",
              "IPY_MODEL_5e049c1ee72a479985020386d0e1b1a4"
            ],
            "layout": "IPY_MODEL_12796276d36e491680c2100ba20ae940"
          }
        },
        "3b2547e5cc094800af09613a4e920057": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_adbf654ebd1b42849d6bb4e5c5faf0e4",
            "placeholder": "​",
            "style": "IPY_MODEL_6bc6be28dd98434bb3c6560cd897d6fc",
            "value": "Downloading vocab.txt: 100%"
          }
        },
        "c11e480a6f79441498d91ffaf82ca468": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6499ceffc0d346b1be1d9b7aaec18e5a",
            "max": 213450,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9d7838644cf84f3c85964262ec765bc1",
            "value": 213450
          }
        },
        "5e049c1ee72a479985020386d0e1b1a4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_756a595c9839404995d03c8b55d0743b",
            "placeholder": "​",
            "style": "IPY_MODEL_af4f2e4e14b44e92b551461c58a086c4",
            "value": " 208k/208k [00:00&lt;00:00, 620kB/s]"
          }
        },
        "12796276d36e491680c2100ba20ae940": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "adbf654ebd1b42849d6bb4e5c5faf0e4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6bc6be28dd98434bb3c6560cd897d6fc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6499ceffc0d346b1be1d9b7aaec18e5a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9d7838644cf84f3c85964262ec765bc1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "756a595c9839404995d03c8b55d0743b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "af4f2e4e14b44e92b551461c58a086c4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "70cc16088a24447a98b5d74fd0276a48": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2b6262c3ac4043a0bcc136b66b13eae4",
              "IPY_MODEL_0f112447a7be4338aaec5a70986d8da4",
              "IPY_MODEL_02537e1ee9e54a2cb53c4a298ba175b2"
            ],
            "layout": "IPY_MODEL_04fdfd825d0b4167b266387162ede764"
          }
        },
        "2b6262c3ac4043a0bcc136b66b13eae4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d2d028d3eda34091905ee8b15fb80c9e",
            "placeholder": "​",
            "style": "IPY_MODEL_dd348f47a854415f8dcd61ff78f352c7",
            "value": "Downloading tokenizer_config.json: 100%"
          }
        },
        "0f112447a7be4338aaec5a70986d8da4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c4d368fdbce4476ea187f2ce227afd21",
            "max": 29,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0af56adc0c184a9aaea0c7a708985ce4",
            "value": 29
          }
        },
        "02537e1ee9e54a2cb53c4a298ba175b2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4f45b1ae83f74720aaa328b832bef165",
            "placeholder": "​",
            "style": "IPY_MODEL_58b922dfd8a348ac895cf776dfd850ab",
            "value": " 29.0/29.0 [00:00&lt;00:00, 747B/s]"
          }
        },
        "04fdfd825d0b4167b266387162ede764": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d2d028d3eda34091905ee8b15fb80c9e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dd348f47a854415f8dcd61ff78f352c7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c4d368fdbce4476ea187f2ce227afd21": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0af56adc0c184a9aaea0c7a708985ce4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4f45b1ae83f74720aaa328b832bef165": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "58b922dfd8a348ac895cf776dfd850ab": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "df131e0e01334f30ac4502431b1e9a18": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_446445f2f43f4d89826467732223dcb2",
              "IPY_MODEL_9c1a3bbe3ebb463f9d0f5691b8b62992",
              "IPY_MODEL_c18387ae76044e83a39509c5c35f97b2"
            ],
            "layout": "IPY_MODEL_477edfd3134f41f8a7aa88f55ae174f8"
          }
        },
        "446445f2f43f4d89826467732223dcb2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_869f3abcb86c4aeb8f37b2ce90f297d6",
            "placeholder": "​",
            "style": "IPY_MODEL_912e21e449ae43758c78ac4b94d24834",
            "value": "Downloading config.json: 100%"
          }
        },
        "9c1a3bbe3ebb463f9d0f5691b8b62992": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f13f0e3fd6dd4264a7d5bd6ccd94c252",
            "max": 570,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5d56567e012d48379f5ab7d92f4ec708",
            "value": 570
          }
        },
        "c18387ae76044e83a39509c5c35f97b2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fa9761feabf94723999f0afaff172669",
            "placeholder": "​",
            "style": "IPY_MODEL_74848a656aa04e1980aa7bb478600704",
            "value": " 570/570 [00:00&lt;00:00, 13.1kB/s]"
          }
        },
        "477edfd3134f41f8a7aa88f55ae174f8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "869f3abcb86c4aeb8f37b2ce90f297d6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "912e21e449ae43758c78ac4b94d24834": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f13f0e3fd6dd4264a7d5bd6ccd94c252": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5d56567e012d48379f5ab7d92f4ec708": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "fa9761feabf94723999f0afaff172669": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "74848a656aa04e1980aa7bb478600704": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9a39a0b3e064433cb748e109c0f7113f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_12abd0d3661a4a00a00a895cbaefb0e3",
              "IPY_MODEL_8c04cc2c280a4a0f8d7c97f66ee28813",
              "IPY_MODEL_fd45720088fd4ecea6db1f12041e9bcf"
            ],
            "layout": "IPY_MODEL_74229ab307ab422eabe0357efc28e761"
          }
        },
        "12abd0d3661a4a00a00a895cbaefb0e3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6ecdd73971844c9b8247bd6a22b63177",
            "placeholder": "​",
            "style": "IPY_MODEL_f520d43e681f4f7fae079a0283c9c4cd",
            "value": "Downloading tf_model.h5: 100%"
          }
        },
        "8c04cc2c280a4a0f8d7c97f66ee28813": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f151e53688904c6b9f966ddd11da42ac",
            "max": 526681800,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d31ca70b1c4348c7a5e70fd59f7423ae",
            "value": 526681800
          }
        },
        "fd45720088fd4ecea6db1f12041e9bcf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ffb95d76e9e34469a621d753b177d5a7",
            "placeholder": "​",
            "style": "IPY_MODEL_5ea8a994f289407598c51b58b21ed004",
            "value": " 502M/502M [00:10&lt;00:00, 52.9MB/s]"
          }
        },
        "74229ab307ab422eabe0357efc28e761": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6ecdd73971844c9b8247bd6a22b63177": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f520d43e681f4f7fae079a0283c9c4cd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f151e53688904c6b9f966ddd11da42ac": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d31ca70b1c4348c7a5e70fd59f7423ae": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ffb95d76e9e34469a621d753b177d5a7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5ea8a994f289407598c51b58b21ed004": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}