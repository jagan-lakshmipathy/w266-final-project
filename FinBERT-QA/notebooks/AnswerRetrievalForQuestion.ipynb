{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"AnswerRetrievalForQuestion.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyNnuhqujSUdKHv26OzG86bw"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["#Answer Retrieval for a given question:\n","\n","### This notebook gradually builds upon the QA System\n","\n","Here we mount my google drive to this notebook."],"metadata":{"id":"pGywka6UgNMP"}},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/gdrive')\n","%cd /gdrive"],"metadata":{"id":"UxjBaU1OgH9n","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1658435544960,"user_tz":240,"elapsed":83284,"user":{"displayName":"jagannathan Lakshmipathy","userId":"05639691877293412421"}},"outputId":"67888e42-9602-4231-ccdd-82f1cdaa1f30"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /gdrive\n","/gdrive\n"]}]},{"cell_type":"code","source":["!pip install pyserini\n","!pip install faiss\n","\n","!apt install libomp-dev\n","!python -m pip install --upgrade faiss faiss-gpu\n","import faiss"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4jc1iIPyiALg","executionInfo":{"status":"ok","timestamp":1658435591278,"user_tz":240,"elapsed":46324,"user":{"displayName":"jagannathan Lakshmipathy","userId":"05639691877293412421"}},"outputId":"e245ff23-6925-4e39-ed41-9546d21b7ac1"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting pyserini\n","  Downloading pyserini-0.17.0-py3-none-any.whl (109.5 MB)\n","\u001b[K     |████████████████████████████████| 109.5 MB 34 kB/s \n","\u001b[?25hRequirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.7/dist-packages (from pyserini) (1.7.3)\n","Collecting sentencepiece>=0.1.95\n","  Downloading sentencepiece-0.1.96-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n","\u001b[K     |████████████████████████████████| 1.2 MB 78.9 MB/s \n","\u001b[?25hRequirement already satisfied: spacy>=3.2.1 in /usr/local/lib/python3.7/dist-packages (from pyserini) (3.3.1)\n","Requirement already satisfied: pandas>=1.1.5 in /usr/local/lib/python3.7/dist-packages (from pyserini) (1.3.5)\n","Requirement already satisfied: numpy>=1.18.1 in /usr/local/lib/python3.7/dist-packages (from pyserini) (1.21.6)\n","Requirement already satisfied: Cython>=0.29.21 in /usr/local/lib/python3.7/dist-packages (from pyserini) (0.29.30)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from pyserini) (4.64.0)\n","Collecting nmslib>=2.1.1\n","  Downloading nmslib-2.1.1-cp37-cp37m-manylinux2010_x86_64.whl (13.5 MB)\n","\u001b[K     |████████████████████████████████| 13.5 MB 52.9 MB/s \n","\u001b[?25hRequirement already satisfied: scikit-learn>=0.22.1 in /usr/local/lib/python3.7/dist-packages (from pyserini) (1.0.2)\n","Collecting lightgbm>=3.3.2\n","  Downloading lightgbm-3.3.2-py3-none-manylinux1_x86_64.whl (2.0 MB)\n","\u001b[K     |████████████████████████████████| 2.0 MB 64.8 MB/s \n","\u001b[?25hCollecting transformers>=4.6.0\n","  Downloading transformers-4.20.1-py3-none-any.whl (4.4 MB)\n","\u001b[K     |████████████████████████████████| 4.4 MB 51.2 MB/s \n","\u001b[?25hCollecting onnxruntime>=1.8.1\n","  Downloading onnxruntime-1.11.1-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.2 MB)\n","\u001b[K     |████████████████████████████████| 5.2 MB 49.0 MB/s \n","\u001b[?25hCollecting pyjnius>=1.4.0\n","  Downloading pyjnius-1.4.2-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n","\u001b[K     |████████████████████████████████| 1.3 MB 46.4 MB/s \n","\u001b[?25hRequirement already satisfied: wheel in /usr/local/lib/python3.7/dist-packages (from lightgbm>=3.3.2->pyserini) (0.37.1)\n","Requirement already satisfied: psutil in /usr/local/lib/python3.7/dist-packages (from nmslib>=2.1.1->pyserini) (5.4.8)\n","Collecting pybind11<2.6.2\n","  Downloading pybind11-2.6.1-py2.py3-none-any.whl (188 kB)\n","\u001b[K     |████████████████████████████████| 188 kB 74.6 MB/s \n","\u001b[?25hRequirement already satisfied: flatbuffers in /usr/local/lib/python3.7/dist-packages (from onnxruntime>=1.8.1->pyserini) (2.0)\n","Requirement already satisfied: protobuf in /usr/local/lib/python3.7/dist-packages (from onnxruntime>=1.8.1->pyserini) (3.17.3)\n","Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=1.1.5->pyserini) (2022.1)\n","Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=1.1.5->pyserini) (2.8.2)\n","Requirement already satisfied: six>=1.7.0 in /usr/local/lib/python3.7/dist-packages (from pyjnius>=1.4.0->pyserini) (1.15.0)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.22.1->pyserini) (3.1.0)\n","Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.22.1->pyserini) (1.1.0)\n","Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=3.2.1->pyserini) (2.0.6)\n","Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=3.2.1->pyserini) (2.23.0)\n","Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=3.2.1->pyserini) (1.0.3)\n","Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=3.2.1->pyserini) (3.3.0)\n","Requirement already satisfied: typer<0.5.0,>=0.3.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=3.2.1->pyserini) (0.4.2)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy>=3.2.1->pyserini) (57.4.0)\n","Requirement already satisfied: thinc<8.1.0,>=8.0.14 in /usr/local/lib/python3.7/dist-packages (from spacy>=3.2.1->pyserini) (8.0.17)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from spacy>=3.2.1->pyserini) (2.11.3)\n","Requirement already satisfied: wasabi<1.1.0,>=0.9.1 in /usr/local/lib/python3.7/dist-packages (from spacy>=3.2.1->pyserini) (0.9.1)\n","Requirement already satisfied: typing-extensions<4.2.0,>=3.7.4 in /usr/local/lib/python3.7/dist-packages (from spacy>=3.2.1->pyserini) (4.1.1)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=3.2.1->pyserini) (21.3)\n","Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.7/dist-packages (from spacy>=3.2.1->pyserini) (2.4.3)\n","Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.7/dist-packages (from spacy>=3.2.1->pyserini) (2.0.7)\n","Requirement already satisfied: pathy>=0.3.5 in /usr/local/lib/python3.7/dist-packages (from spacy>=3.2.1->pyserini) (0.6.2)\n","Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4 in /usr/local/lib/python3.7/dist-packages (from spacy>=3.2.1->pyserini) (1.8.2)\n","Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=3.2.1->pyserini) (1.0.7)\n","Requirement already satisfied: blis<0.8.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=3.2.1->pyserini) (0.7.8)\n","Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=3.2.1->pyserini) (3.0.6)\n","Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.9 in /usr/local/lib/python3.7/dist-packages (from spacy>=3.2.1->pyserini) (3.0.9)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from catalogue<2.1.0,>=2.0.6->spacy>=3.2.1->pyserini) (3.8.1)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->spacy>=3.2.1->pyserini) (3.0.9)\n","Requirement already satisfied: smart-open<6.0.0,>=5.2.1 in /usr/local/lib/python3.7/dist-packages (from pathy>=0.3.5->spacy>=3.2.1->pyserini) (5.2.1)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=3.2.1->pyserini) (2.10)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=3.2.1->pyserini) (3.0.4)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=3.2.1->pyserini) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=3.2.1->pyserini) (2022.6.15)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers>=4.6.0->pyserini) (3.7.1)\n","Collecting tokenizers!=0.11.3,<0.13,>=0.11.1\n","  Downloading tokenizers-0.12.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.6 MB)\n","\u001b[K     |████████████████████████████████| 6.6 MB 48.5 MB/s \n","\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers>=4.6.0->pyserini) (2022.6.2)\n","Collecting pyyaml>=5.1\n","  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n","\u001b[K     |████████████████████████████████| 596 kB 78.0 MB/s \n","\u001b[?25hCollecting huggingface-hub<1.0,>=0.1.0\n","  Downloading huggingface_hub-0.8.1-py3-none-any.whl (101 kB)\n","\u001b[K     |████████████████████████████████| 101 kB 11.7 MB/s \n","\u001b[?25hRequirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers>=4.6.0->pyserini) (4.12.0)\n","Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.7/dist-packages (from typer<0.5.0,>=0.3.0->spacy>=3.2.1->pyserini) (7.1.2)\n","Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->spacy>=3.2.1->pyserini) (2.0.1)\n","Installing collected packages: pyyaml, tokenizers, pybind11, huggingface-hub, transformers, sentencepiece, pyjnius, onnxruntime, nmslib, lightgbm, pyserini\n","  Attempting uninstall: pyyaml\n","    Found existing installation: PyYAML 3.13\n","    Uninstalling PyYAML-3.13:\n","      Successfully uninstalled PyYAML-3.13\n","  Attempting uninstall: lightgbm\n","    Found existing installation: lightgbm 2.2.3\n","    Uninstalling lightgbm-2.2.3:\n","      Successfully uninstalled lightgbm-2.2.3\n","Successfully installed huggingface-hub-0.8.1 lightgbm-3.3.2 nmslib-2.1.1 onnxruntime-1.11.1 pybind11-2.6.1 pyjnius-1.4.2 pyserini-0.17.0 pyyaml-6.0 sentencepiece-0.1.96 tokenizers-0.12.1 transformers-4.20.1\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting faiss\n","  Downloading faiss-1.5.3-cp37-cp37m-manylinux1_x86_64.whl (4.7 MB)\n","\u001b[K     |████████████████████████████████| 4.7 MB 13.0 MB/s \n","\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from faiss) (1.21.6)\n","Installing collected packages: faiss\n","Successfully installed faiss-1.5.3\n","Reading package lists... Done\n","Building dependency tree       \n","Reading state information... Done\n","The following package was automatically installed and is no longer required:\n","  libnvidia-common-460\n","Use 'apt autoremove' to remove it.\n","The following additional packages will be installed:\n","  libomp5\n","Suggested packages:\n","  libomp-doc\n","The following NEW packages will be installed:\n","  libomp-dev libomp5\n","0 upgraded, 2 newly installed, 0 to remove and 49 not upgraded.\n","Need to get 239 kB of archives.\n","After this operation, 804 kB of additional disk space will be used.\n","Get:1 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libomp5 amd64 5.0.1-1 [234 kB]\n","Get:2 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libomp-dev amd64 5.0.1-1 [5,088 B]\n","Fetched 239 kB in 0s (2,595 kB/s)\n","Selecting previously unselected package libomp5:amd64.\n","(Reading database ... 155653 files and directories currently installed.)\n","Preparing to unpack .../libomp5_5.0.1-1_amd64.deb ...\n","Unpacking libomp5:amd64 (5.0.1-1) ...\n","Selecting previously unselected package libomp-dev.\n","Preparing to unpack .../libomp-dev_5.0.1-1_amd64.deb ...\n","Unpacking libomp-dev (5.0.1-1) ...\n","Setting up libomp5:amd64 (5.0.1-1) ...\n","Setting up libomp-dev (5.0.1-1) ...\n","Processing triggers for libc-bin (2.27-3ubuntu1.3) ...\n","/sbin/ldconfig.real: /usr/local/lib/python3.7/dist-packages/ideep4py/lib/libmkldnn.so.0 is not a symbolic link\n","\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: faiss in /usr/local/lib/python3.7/dist-packages (1.5.3)\n","Collecting faiss-gpu\n","  Downloading faiss_gpu-1.7.2-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (85.5 MB)\n","\u001b[K     |████████████████████████████████| 85.5 MB 140 kB/s \n","\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from faiss) (1.21.6)\n","Installing collected packages: faiss-gpu\n","Successfully installed faiss-gpu-1.7.2\n"]}]},{"cell_type":"code","source":["import pandas as pd\n","import regex as re\n","import csv\n","from itertools import islice\n","import pickle\n","import numpy as np\n","import json\n","import os\n","import sys\n","import argparse\n","from pathlib import Path\n","from sklearn.model_selection import train_test_split\n","from pathlib import Path\n","# os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-11-openjdk-amd64\"\n","#from pyserini.search as pysearch\n","\n","from pyserini.search import SimpleSearcher"],"metadata":{"id":"6VtN7XXgiG3E","executionInfo":{"status":"ok","timestamp":1658435598011,"user_tz":240,"elapsed":6749,"user":{"displayName":"jagannathan Lakshmipathy","userId":"05639691877293412421"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["!pip install pydot --quiet\n","!pip install gensim==3.8.3 --quiet\n","!pip install tensorflow-datasets --quiet\n","!pip install -U tensorflow-text --quiet\n","!pip install transformers --quiet\n","!pip install pydot --quiet"],"metadata":{"id":"BpfXdf7YiNcV","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1658435697256,"user_tz":240,"elapsed":99253,"user":{"displayName":"jagannathan Lakshmipathy","userId":"05639691877293412421"}},"outputId":"07f5d821-a1a1-47b4-fa70-742d6611176c"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[K     |████████████████████████████████| 24.2 MB 1.5 MB/s \n","\u001b[K     |████████████████████████████████| 4.6 MB 14.2 MB/s \n","\u001b[K     |████████████████████████████████| 511.7 MB 7.0 kB/s \n","\u001b[K     |████████████████████████████████| 1.6 MB 47.4 MB/s \n","\u001b[K     |████████████████████████████████| 5.8 MB 54.7 MB/s \n","\u001b[K     |████████████████████████████████| 438 kB 47.6 MB/s \n","\u001b[?25h"]}]},{"cell_type":"code","source":["!pip install -q tensorflow-recommenders\n","!pip install -q scann"],"metadata":{"id":"Hfqaj9lLXXQt","executionInfo":{"status":"ok","timestamp":1658435712323,"user_tz":240,"elapsed":15073,"user":{"displayName":"jagannathan Lakshmipathy","userId":"05639691877293412421"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"c2292f94-d2d0-407e-e2e7-c8e0c8b9ed8a"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[K     |████████████████████████████████| 88 kB 4.0 MB/s \n","\u001b[K     |████████████████████████████████| 11.2 MB 13.7 MB/s \n","\u001b[?25h"]}]},{"cell_type":"code","source":["import tensorflow as tf\n","from tensorflow import keras\n","\n","from tensorflow.keras.layers import Embedding, Input, Dense, Lambda\n","from tensorflow.keras.models import Model\n","import tensorflow.keras.backend as K\n","import tensorflow_datasets as tfds\n","import tensorflow_text as tf_text\n","\n","from transformers import BertTokenizer, TFBertModel\n","\n","\n","import sklearn as sk\n","import nltk\n","from nltk.corpus import reuters\n","from nltk.data import find\n","\n","import matplotlib.pyplot as plt\n","\n","import re"],"metadata":{"id":"_JWmbqnRYSLi","executionInfo":{"status":"ok","timestamp":1658435716343,"user_tz":240,"elapsed":4041,"user":{"displayName":"jagannathan Lakshmipathy","userId":"05639691877293412421"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["import os\n","import pprint\n","import tempfile\n","\n","from typing import Dict, Text\n","import numpy as np\n","import tensorflow_recommenders as tfrs"],"metadata":{"id":"ygM0Cf6gXY9n","executionInfo":{"status":"ok","timestamp":1658435716344,"user_tz":240,"elapsed":6,"user":{"displayName":"jagannathan Lakshmipathy","userId":"05639691877293412421"}}},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":["### FiQA dataset\n","\n","Here we load the FiQA dataset. The FiQA 2018 open challenge test collection is based on the use of unstructured text documents from different financial open data sources in English. This data comes in two flavors (a) Task 1: sentiment analysis train, and (b) Task 2:  Opinion-based QA. We are interested only in the QA dataset in task 2 collection.  The task 2 collection consists of three files:\n","\n","- FiQA question.tsv\n","- FiQA question-doc.tsv\n","- FiQA doc.tsv. \n","\n","1. FiQA_train_question_final.tsv: This file contains a set of natural language questions on topics related to finance and investment. It consists ofl a .tsv file with tab-seaprated columns:\n","  - qid: question id number;\n","  - question: question text;\n","  - timestamp: the date and time value that represents when the question was posted.\n","\n","2. FiQA_train_question_doc_final.tsv: This file contains information about the corresponding question-answer matchings. It also columns:\n","  - qid: question id number;\n","  - docid: document id number.\n","\n","3. FiQA_train_doc_final.tsv: This file contains a set of answers and comments that the systems need to find the matching one.\n","\n","In the following cell we change directory to FinBERT-QA and import all the code relevant to processing the data"],"metadata":{"id":"4wt7Ml5egbMK"}},{"cell_type":"code","source":["%cd /gdrive/MyDrive/nlp-yuan_code/FinBERT-QA\n","from src.process_data import *"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"l3s770oMNbfE","executionInfo":{"status":"ok","timestamp":1658435718733,"user_tz":240,"elapsed":2394,"user":{"displayName":"jagannathan Lakshmipathy","userId":"05639691877293412421"}},"outputId":"ab490921-71ea-4f9d-b6d1-68ec6d040d5d"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["/gdrive/MyDrive/nlp-yuan_code/FinBERT-QA\n"]},{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Unzipping tokenizers/punkt.zip.\n"]}]},{"cell_type":"code","source":["data_path = '/gdrive/MyDrive/nlp-data/nlp-qa-datasets/FiQA/FiQA_train_task2/'\n","# Document id and Answer text\n","collection = load_answers_to_df(data_path+\"FiQA_train_doc_final.tsv\")\n","# Question id and Question text\n","queries = load_questions_to_df(data_path+\"FiQA_train_question_final.tsv\")\n","# Question id and Answer id pair\n","qid_docid = load_qid_docid_to_df(data_path+\"FiQA_train_question_doc_final.tsv\")"],"metadata":{"id":"g_zYwVi4f6Sc","executionInfo":{"status":"ok","timestamp":1658435722837,"user_tz":240,"elapsed":4110,"user":{"displayName":"jagannathan Lakshmipathy","userId":"05639691877293412421"}}},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":["In the above cell we have read the three files into three pandas dataframe collection, queries, and qid_docid. 'collection' is a pair of (docid (int), and doc (str)). 'queries' is a pair of qid (int), and question (str). Similarly, 'qid_docid is a pair of qid(int) and docid(int)."],"metadata":{"id":"OwIfz8GAN-VI"}},{"cell_type":"code","source":["fiqa_index = \"/gdrive/MyDrive/nlp-yuan_code/FinBERT-QA/retriever/lucene-index-fiqa/\"\n","\n","\n","def split_label(qid_docid):\n","    \"\"\"\n","    Split question answer pairs into train, test, validation sets.\n","\n","    Returns:\n","        train_label: Dictonary\n","            key - question id\n","            value - list of relevant docids\n","        test_label: Dictonary\n","            key - question id\n","            value - list of relevant docids\n","        valid_label: Dictonary\n","            key - question id\n","            value - list of relevant docids\n","    ----------\n","    Arguments:\n","        qid_docid: Dataframe containing the question id and relevant docids\n","    \"\"\"\n","    # Group the answers for each question into a list\n","    qid_docid = qid_docid.groupby(['qid']).agg(lambda x: tuple(x)).applymap(list).reset_index()\n","    # Split data\n","    train, test_set = train_test_split(qid_docid, test_size=0.05)\n","    train_set, valid_set = train_test_split(train, test_size=0.1)\n","    # Expand the list of docids into individual rows to represent a single sample\n","    train_data = train_set.explode('docid')\n","    test_data = test_set.explode('docid')\n","    valid_data = valid_set.explode('docid')\n","\n","    # Convert data into dictionary - key: qid, value: list of relevant docid\n","    train_label = label_to_dict(train_data)\n","    test_label = label_to_dict(test_data)\n","    valid_label = label_to_dict(valid_data)\n","\n","    return train_label, test_label, valid_label\n","\n","def split_question(train_label, test_label, valid_label, queries):\n","    \"\"\"\n","    Split questions into train, test, validation sets.\n","\n","    Returns:\n","        train_questions: Dataframe with qids\n","        test_questions: Dataframe with qids\n","        valid_questions: Dataframe with qids\n","    ----------\n","    Arguments:\n","        train_label: Dictionary contraining qid and list of relevant docid\n","        test_label: Dictionary contraining qid and list of relevant docid\n","        valid_label: Dictionary contraining qid and list of relevant docid\n","        queries: Dataframe containing the question id and question text\n","    \"\"\"\n","    # Get a list of question ids\n","    train_q = list(train_label.keys())\n","    test_q = list(test_label.keys())\n","    valid_q = list(valid_label.keys())\n","\n","    # Split question dataframe into train, test, valid set\n","    train_questions = queries[queries['qid'].isin(train_q)]\n","    test_questions = queries[queries['qid'].isin(test_q)]\n","    valid_questions = queries[queries['qid'].isin(valid_q)]\n","\n","    return train_questions, test_questions, valid_questions\n","\n","def split_label(qid_docid):\n","    \"\"\"\n","    Split question answer pairs into train, test, validation sets.\n","\n","    Returns:\n","        train_label: Dictonary\n","            key - question id\n","            value - list of relevant docids\n","        test_label: Dictonary\n","            key - question id\n","            value - list of relevant docids\n","        valid_label: Dictonary\n","            key - question id\n","            value - list of relevant docids\n","    ----------\n","    Arguments:\n","        qid_docid: Dataframe containing the question id and relevant docids\n","    \"\"\"\n","    # Group the answers for each question into a list\n","    qid_docid = qid_docid.groupby(['qid']).agg(lambda x: tuple(x)).applymap(list).reset_index()\n","    # Split data\n","    train, test_set = train_test_split(qid_docid, test_size=0.05)\n","    train_set, valid_set = train_test_split(train, test_size=0.1)\n","    # Expand the list of docids into individual rows to represent a single sample\n","    train_data = train_set.explode('docid')\n","    test_data = test_set.explode('docid')\n","    valid_data = valid_set.explode('docid')\n","\n","    # Convert data into dictionary - key: qid, value: list of relevant docid\n","    train_label = label_to_dict(train_data)\n","    test_label = label_to_dict(test_data)\n","    valid_label = label_to_dict(valid_data)\n","\n","    return train_label, test_label, valid_label\n","\n","def split_question(train_label, test_label, valid_label, queries):\n","    \"\"\"\n","    Split questions into train, test, validation sets.\n","\n","    Returns:\n","        train_questions: Dataframe with qids\n","        test_questions: Dataframe with qids\n","        valid_questions: Dataframe with qids\n","    ----------\n","    Arguments:\n","        train_label: Dictionary contraining qid and list of relevant docid\n","        test_label: Dictionary contraining qid and list of relevant docid\n","        valid_label: Dictionary contraining qid and list of relevant docid\n","        queries: Dataframe containing the question id and question text\n","    \"\"\"\n","    # Get a list of question ids\n","    train_q = list(train_label.keys())\n","    test_q = list(test_label.keys())\n","    valid_q = list(valid_label.keys())\n","\n","    # Split question dataframe into train, test, valid set\n","    train_questions = queries[queries['qid'].isin(train_q)]\n","    test_questions = queries[queries['qid'].isin(test_q)]\n","    valid_questions = queries[queries['qid'].isin(valid_q)]\n","\n","    return train_questions, test_questions, valid_questions\n","\n","def create_dataset(question_df, labels, cands_size):\n","    \"\"\"Retrieves the top-k candidate answers for a question and\n","    creates a list of lists of the dataset containing the question id,\n","    list of relevant answer ids, and the list of answer candidates\n","\n","    Returns:\n","        dataset: list of list in the form [qid, [pos ans], [ans candidates]]\n","    ----------\n","    Arguments:\n","        question_df: Dataframe containing the qid and question text\n","        labels: Dictonary containing the qid to text map\n","        cands_size: int - number of candidates to retrieve\n","    \"\"\"\n","    dataset = []\n","    # Calls retriever\n","    searcher = SimpleSearcher(fiqa_index)\n","    # For each question\n","    for i, row in question_df.iterrows():\n","        qid = row['qid']\n","        tmp = []\n","        # Append qid\n","        tmp.append(qid)\n","        # Append list of relevant docs\n","        tmp.append(labels[qid])\n","        # Retrieves answer candidates\n","        cands = []\n","        cands_score = []\n","        query = row['question']\n","        query = re.sub('[£€§]', '', query)\n","        hits = searcher.search(query, k=cands_size)\n","\n","        for docid in range(0, len(hits)):\n","            cands.append(int(hits[docid].docid))\n","            cands_score.append(hits[docid].score)\n","        # Append candidate answers\n","        tmp.append(cands)\n","        tmp.append(cands_score)\n","        dataset.append(tmp)\n","\n","    return dataset\n","\n","def get_dataset(query_path, labels_path, cands_size):\n","    \"\"\"Splits the dataset into train, validation, and test set and creates\n","    the dataset form for training, validation, and testing.\n","\n","    Returns:\n","        train_set: list of list in the form [qid, [pos ans], [ans candidates]]\n","        valid_set: list of list in the form [qid, [pos ans], [ans candidates]]\n","        test_set: list of list in the form [qid, [pos ans], [ans candidates]]\n","    ----------\n","    Arguments:\n","        query_path: str - path containing a list of qid and questions\n","        labels_path: str - path containing a list of qid and relevant docid\n","        cands_size: int - number of candidates to retrieve\n","    \"\"\"\n","    # Question id and Question text\n","    queries = load_questions_to_df(query_path)\n","    # Question id and Answer id pair\n","    qid_docid = load_qid_docid_to_df(labels_path)\n","    # qid to docid label map\n","    labels = label_to_dict(qid_docid)\n","    train_label, test_label, valid_label = split_label(qid_docid)\n","    # Split Questions\n","    train_questions, test_questions, \\\n","    valid_questions = split_question(train_label, test_label, valid_label, queries)\n","\n","    print(\"\\nGenerating training set...\\n\")\n","    train_set = create_dataset(train_questions, labels, cands_size)\n","    print(\"Generating validation set...\\n\")\n","    valid_set = create_dataset(valid_questions, labels, cands_size)\n","    print(\"Generating test set...\\n\")\n","    test_set = create_dataset(test_questions, labels, cands_size)\n","\n","    return train_set, valid_set, test_set"],"metadata":{"id":"L7Kv2wqBN4gk","executionInfo":{"status":"ok","timestamp":1658435723039,"user_tz":240,"elapsed":222,"user":{"displayName":"jagannathan Lakshmipathy","userId":"05639691877293412421"}}},"execution_count":10,"outputs":[]},{"cell_type":"code","source":["query_path = \"/gdrive/MyDrive/nlp-data/nlp-qa-datasets/FiQA/FiQA_train_task2/FiQA_train_question_final.tsv\"\n","labels_path = \"/gdrive/MyDrive/nlp-data/nlp-qa-datasets/FiQA/FiQA_train_task2/FiQA_train_question_doc_final.tsv\"\n","train_set, valid_set, test_set = get_dataset(query_path, labels_path, 50)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pnkwQ9l2i26P","executionInfo":{"status":"ok","timestamp":1658435780522,"user_tz":240,"elapsed":57485,"user":{"displayName":"jagannathan Lakshmipathy","userId":"05639691877293412421"}},"outputId":"f4a5eb86-5f99-4ad9-9138-f86cd0e994be"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Generating training set...\n","\n","SimpleSearcher class has been deprecated, please use LuceneSearcher from pyserini.search.lucene instead\n","Generating validation set...\n","\n","SimpleSearcher class has been deprecated, please use LuceneSearcher from pyserini.search.lucene instead\n","Generating test set...\n","\n","SimpleSearcher class has been deprecated, please use LuceneSearcher from pyserini.search.lucene instead\n"]}]},{"cell_type":"code","source":["print(len(train_set), len(valid_set), len(test_set))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BpfcyNQfDeYT","executionInfo":{"status":"ok","timestamp":1658435780522,"user_tz":240,"elapsed":23,"user":{"displayName":"jagannathan Lakshmipathy","userId":"05639691877293412421"}},"outputId":"c273329d-291c-4c3c-b281-9a713aca36c6"},"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["5683 632 333\n"]}]},{"cell_type":"code","source":["# Cleaning data\n","empty_docs, empty_id = get_empty_docs(collection)\n","# Remove empty answers from collection of answers\n","collection_cleaned = collection.drop(empty_id)\n","# Remove empty answers from qa pairs\n","qid_docid = qid_docid[~qid_docid['docid'].isin(empty_docs)]\n","\n","print(\"Number of answers after cleaning: {}\".format(len(collection_cleaned)))\n","print(\"Number of QA pairs after cleaning: {}\".format(len(qid_docid)))"],"metadata":{"id":"Ta8HcYXojySM","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1658435784336,"user_tz":240,"elapsed":3833,"user":{"displayName":"jagannathan Lakshmipathy","userId":"05639691877293412421"}},"outputId":"e8486d51-1a80-46c9-c0bc-19d1dbd6a4b4"},"execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":["Number of answers after cleaning: 57600\n","Number of QA pairs after cleaning: 17072\n"]}]},{"cell_type":"code","source":["# Write collection df to file\n","save_tsv(\"retriever/collection_cleaned.tsv\", collection_cleaned)\n","\n","# Convert collection df to JSON file for Anserini's document indexer\n","collection_to_json(\"retriever/collection_json/docs.json\", \"retriever/collection_cleaned.tsv\")"],"metadata":{"id":"b1TWd5DZj5dl","executionInfo":{"status":"ok","timestamp":1658435788530,"user_tz":240,"elapsed":4199,"user":{"displayName":"jagannathan Lakshmipathy","userId":"05639691877293412421"}}},"execution_count":14,"outputs":[]},{"cell_type":"code","source":["import numpy as np\n","from sklearn.metrics import ndcg_score\n","from sklearn.metrics import average_precision_score\n","\n","def run_baseline(data):\n","  ap = []\n","  rr = []\n","  cg = []\n","\n","\n","  #for i, seq in enumerate(tqdm(train_set)):\n","  for i, seq in enumerate(data):\n","    qid, ans_labels, cands, cands_score = seq[0], seq[1], seq[2], seq[3]\n","    \n","    # Map question id to text\n","    #q_text = qid_to_text[qid]\n","\n","    max_width = -1\n","    rr_ = 0\n","    ap_ = 0.0\n","    precision_ = 0.0\n","    relcnt_ = 0\n","\n","    top_k = 10\n","\n","    # For each answer in the candidates\n","    for i in range(top_k):\n","      docid = cands[i]\n","      if docid in ans_labels and rr_ == 0:\n","        rr_ = 1/(i+1)\n","    \n","    relscores = [1 if docid in ans_labels else 0 for docid in cands[:top_k]]\n","    pos = [1.0/(i+1) for i in range(top_k)]\n","    ap_ = average_precision_score(relscores,pos) if sum(relscores) != 0 else 0 \n","\n","    #print(ap_, [1 if docid in ans_labels else 0 for docid in cands[:top_k]], [1.0/(i+1) for i in range(top_k)])\n","    relscores = np.asarray([[np.log2(cands_score[i]) if (cands[i] in ans_labels) else 0.001 for i in range(top_k)]])\n","    pos = np.asarray([[np.log2(i+2) for i in range(top_k)]])\n","\n","    cg_ = ndcg_score(relscores, pos)\n","\n","    ap.append(ap_)\n","    rr.append(rr_)\n","    cg.append(cg_)\n","  return rr, ap, cg\n","\n","      "],"metadata":{"id":"TPgiCQxXkWCG","executionInfo":{"status":"ok","timestamp":1658435788531,"user_tz":240,"elapsed":22,"user":{"displayName":"jagannathan Lakshmipathy","userId":"05639691877293412421"}}},"execution_count":15,"outputs":[]},{"cell_type":"code","source":[""],"metadata":{"id":"eXfrmGKeDcoj","executionInfo":{"status":"ok","timestamp":1658435788531,"user_tz":240,"elapsed":20,"user":{"displayName":"jagannathan Lakshmipathy","userId":"05639691877293412421"}}},"execution_count":15,"outputs":[]},{"cell_type":"code","source":["rr, ap, cg = run_baseline(train_set)\n","\n","print('Mean Reciprocal Rank (MRR):', np.mean(rr))\n","print('Mean average Precision (MAP)', np.mean(ap))\n","print('Normalized Discounted Cumulative Gain (NDCG)', np.mean(cg))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"R0429RQG_Wjg","executionInfo":{"status":"ok","timestamp":1658435791386,"user_tz":240,"elapsed":2874,"user":{"displayName":"jagannathan Lakshmipathy","userId":"05639691877293412421"}},"outputId":"4740fd37-7194-462f-d4bd-3aa6864f5e57"},"execution_count":16,"outputs":[{"output_type":"stream","name":"stdout","text":["Mean Reciprocal Rank (MRR): 0.29531790720863393\n","Mean average Precision (MAP) 0.28095505082788585\n","Normalized Discounted Cumulative Gain (NDCG) 0.7160566544381635\n"]}]},{"cell_type":"code","source":["print(len(train_set), len(valid_set), len(test_set))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vMO4zgbgIbjz","executionInfo":{"status":"ok","timestamp":1658435791386,"user_tz":240,"elapsed":23,"user":{"displayName":"jagannathan Lakshmipathy","userId":"05639691877293412421"}},"outputId":"f28f598e-34a2-4c83-ca1b-7a5ec626a24a"},"execution_count":17,"outputs":[{"output_type":"stream","name":"stdout","text":["5683 632 333\n"]}]},{"cell_type":"code","source":["embedding_dimension = 128"],"metadata":{"id":"zxmlDGecpbD8","executionInfo":{"status":"ok","timestamp":1658435791387,"user_tz":240,"elapsed":21,"user":{"displayName":"jagannathan Lakshmipathy","userId":"05639691877293412421"}}},"execution_count":18,"outputs":[]},{"cell_type":"code","source":["def generate_ids(data):\n","  qids = []\n","  aids = []\n","  qa_pairs = []\n","\n","\n","  #for i, seq in enumerate(tqdm(train_set)):\n","  for i, seq in enumerate(data):\n","    qid, ans_labels, cands = seq[0], seq[1], seq[2]\n","    #print (qid, ans_labels, cands)\n","    \n","\n","    # For each answer in the candidates\n","    for docid in ans_labels:\n","      qids.append(qid)\n","      aids.append(docid)\n","      qa_pairs.append((qid, docid))\n","\n","  unique_qids = np.unique(qids)\n","  unique_aids = np.unique(aids)\n","  return unique_qids, unique_aids, qa_pairs\n","\n","data = []\n","data.extend(train_set)\n","data.extend(valid_set)\n","data.extend(test_set)\n","      \n","qids, aids, qa_pairs = generate_ids(data)"],"metadata":{"id":"px0XMr98qk6u","executionInfo":{"status":"ok","timestamp":1658435791387,"user_tz":240,"elapsed":20,"user":{"displayName":"jagannathan Lakshmipathy","userId":"05639691877293412421"}}},"execution_count":19,"outputs":[]},{"cell_type":"code","source":["print(len(qids), len(aids), len(qa_pairs))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"aNwi2E_28P4L","executionInfo":{"status":"ok","timestamp":1658435791387,"user_tz":240,"elapsed":19,"user":{"displayName":"jagannathan Lakshmipathy","userId":"05639691877293412421"}},"outputId":"9065b17e-623c-4cc5-8fb9-a303954a6479"},"execution_count":20,"outputs":[{"output_type":"stream","name":"stdout","text":["6648 17110 17110\n"]}]},{"cell_type":"code","source":["processed_answers = process_answers(collection_cleaned)\n","processed_questions = process_questions(queries)"],"metadata":{"id":"qfdtvpLRrhw8","executionInfo":{"status":"ok","timestamp":1658435798045,"user_tz":240,"elapsed":6435,"user":{"displayName":"jagannathan Lakshmipathy","userId":"05639691877293412421"}}},"execution_count":21,"outputs":[]},{"cell_type":"code","source":["word2index, word2count = create_vocab(processed_answers, processed_questions)\n","\n","print(\"Vocab size: {}\".format(len(word2index)))\n","print(\"Top {} common words: {}\".format(35, Counter(word2count).most_common(35)))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KUSTTgSKrnw6","executionInfo":{"status":"ok","timestamp":1658435803568,"user_tz":240,"elapsed":5534,"user":{"displayName":"jagannathan Lakshmipathy","userId":"05639691877293412421"}},"outputId":"7e847ffe-4024-4619-c9c0-81ffccca38ee"},"execution_count":22,"outputs":[{"output_type":"stream","name":"stdout","text":["Vocab size: 85034\n","Top 35 common words: [('the', 371203), ('to', 233559), ('a', 201620), ('you', 166702), ('and', 163066), ('of', 157574), ('is', 129894), ('in', 120019), ('that', 111416), ('for', 89366), ('it', 83822), ('i', 74100), ('your', 68153), ('are', 67255), ('if', 60689), ('be', 59266), ('on', 58382), ('have', 55754), ('as', 50088), ('this', 49868), ('not', 49227), ('or', 46080), ('with', 45894), ('they', 44485), ('but', 41690), ('can', 38863), ('will', 36865), ('at', 35548), ('an', 31392), ('money', 31003), ('so', 29980), ('$', 29096), ('would', 28750), ('from', 28582), ('more', 27378)]\n"]}]},{"cell_type":"code","source":["qid_to_text, docid_to_text = id_to_text(collection, queries)\n","qid_to_tokenized_text, docid_to_tokenized_text = id_to_tokenized_text(processed_answers, processed_questions)"],"metadata":{"id":"QYW5upWDrsL3","executionInfo":{"status":"ok","timestamp":1658435810687,"user_tz":240,"elapsed":7137,"user":{"displayName":"jagannathan Lakshmipathy","userId":"05639691877293412421"}}},"execution_count":23,"outputs":[]},{"cell_type":"code","source":["unique_questions = np.unique([qid_to_text[qid] for qid in qids])\n","\n","question_model = tf.keras.Sequential([\n","  tf.keras.layers.StringLookup(\n","      vocabulary=unique_questions, mask_token=None),\n","  # We add an additional embedding to account for unknown tokens.\n","  tf.keras.layers.Embedding(len(qids) + 1, embedding_dimension)\n","])"],"metadata":{"id":"YRMq83nTpvhd","executionInfo":{"status":"ok","timestamp":1658435810688,"user_tz":240,"elapsed":22,"user":{"displayName":"jagannathan Lakshmipathy","userId":"05639691877293412421"}}},"execution_count":24,"outputs":[]},{"cell_type":"code","source":[""],"metadata":{"id":"CijO3oUArfJp","executionInfo":{"status":"ok","timestamp":1658435810688,"user_tz":240,"elapsed":20,"user":{"displayName":"jagannathan Lakshmipathy","userId":"05639691877293412421"}}},"execution_count":24,"outputs":[]},{"cell_type":"code","source":["unique_answers = np.unique([docid_to_text[aid] for aid in aids])\n","\n","answer_model = tf.keras.Sequential([\n","  tf.keras.layers.StringLookup(\n","      vocabulary=unique_answers, mask_token=None),\n","  # We add an additional embedding to account for unknown tokens.\n","  tf.keras.layers.Embedding(len(aids) + 1, embedding_dimension)\n","])"],"metadata":{"id":"rQHTTkyUXUts","executionInfo":{"status":"ok","timestamp":1658435813466,"user_tz":240,"elapsed":2798,"user":{"displayName":"jagannathan Lakshmipathy","userId":"05639691877293412421"}}},"execution_count":25,"outputs":[]},{"cell_type":"code","source":["questions = tf.data.Dataset.from_tensor_slices([qid_to_text[qid] if isinstance(qid_to_text.get(qid),str) else '' for qid, aid in qa_pairs])\n","answers = tf.data.Dataset.from_tensor_slices([docid_to_text[aid] if isinstance(docid_to_text.get(aid),str) else '' for qid, aid in qa_pairs])\n","\n","metrics = tfrs.metrics.FactorizedTopK(\n","  candidates=answers.batch(128).map(answer_model)\n",")\n","task = tfrs.tasks.Retrieval(\n","  metrics=metrics\n",")"],"metadata":{"id":"9FSP8rWAvR9v","executionInfo":{"status":"ok","timestamp":1658435813774,"user_tz":240,"elapsed":310,"user":{"displayName":"jagannathan Lakshmipathy","userId":"05639691877293412421"}}},"execution_count":26,"outputs":[]},{"cell_type":"code","source":["ds = tf.data.Dataset.zip((questions, answers))\n","ds = ds.map(lambda x, y : {\"question\": x, \"answer\": y})\n","\n","tf.random.set_seed(42)\n","shuffled = ds.shuffle(17_110, seed=42, reshuffle_each_iteration=False)\n","\n","#train = shuffled.take(16_242)\n"],"metadata":{"id":"NmvgVMtyq3gf","executionInfo":{"status":"ok","timestamp":1658435813775,"user_tz":240,"elapsed":6,"user":{"displayName":"jagannathan Lakshmipathy","userId":"05639691877293412421"}}},"execution_count":27,"outputs":[]},{"cell_type":"code","source":["print(5683/(5683+632+333), 632/(5683+632+333), 333/(5683+632+333))\n","print((17100)*0.8548435619735258, (17100)*0.0950661853188929, (17100)*0.050090252707581225)\n","14617+1625"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NP6Zu-eqZIJc","executionInfo":{"status":"ok","timestamp":1658435813775,"user_tz":240,"elapsed":5,"user":{"displayName":"jagannathan Lakshmipathy","userId":"05639691877293412421"}},"outputId":"3e06c377-ba4c-4f29-bfff-7d468128296d"},"execution_count":28,"outputs":[{"output_type":"stream","name":"stdout","text":["0.8548435619735258 0.0950661853188929 0.050090252707581225\n","14617.824909747293 1625.6317689530686 856.5433212996389\n"]},{"output_type":"execute_result","data":{"text/plain":["16242"]},"metadata":{},"execution_count":28}]},{"cell_type":"code","source":["class QAModel(tfrs.Model):\n","\n","  def __init__(self, question_model, answer_model):\n","    super().__init__()\n","    self.question_model: tf.keras.Model = question_model\n","    self.answer_model: tf.keras.Model = answer_model\n","    self.task: tf.keras.layers.Layer = task\n","\n","  def compute_loss(self, features: Dict[Text, tf.Tensor], training=False) -> tf.Tensor:\n","    # We pick out the user features and pass them into the user model.\n","    q_embeddings = self.question_model(features[\"question\"])\n","    # And pick out the movie features and pass them into the movie model,\n","    # getting embeddings back.\n","    a_embeddings = self.answer_model(features[\"answer\"])\n","\n","    # The task computes the loss and the metrics.\n","    return self.task(q_embeddings, a_embeddings)"],"metadata":{"id":"YpTIvmbqZL2M","executionInfo":{"status":"ok","timestamp":1658435814017,"user_tz":240,"elapsed":6,"user":{"displayName":"jagannathan Lakshmipathy","userId":"05639691877293412421"}}},"execution_count":29,"outputs":[]},{"cell_type":"code","source":["cached_train = shuffled.shuffle(17_110).batch(1300)\n","cached_test =  shuffled.take(856).batch(150)"],"metadata":{"id":"ynXtzkHlZPhZ","executionInfo":{"status":"ok","timestamp":1658435814018,"user_tz":240,"elapsed":5,"user":{"displayName":"jagannathan Lakshmipathy","userId":"05639691877293412421"}}},"execution_count":30,"outputs":[]},{"cell_type":"code","source":["model = QAModel(question_model, answer_model)\n","model.compile(optimizer=tf.keras.optimizers.Adagrad(learning_rate=0.1))\n","\n","model.fit(cached_train, epochs=5)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dpYzIqrPZUOK","executionInfo":{"status":"ok","timestamp":1658435988962,"user_tz":240,"elapsed":174949,"user":{"displayName":"jagannathan Lakshmipathy","userId":"05639691877293412421"}},"outputId":"afd7174f-b7e1-4a04-8e61-c626258264d4"},"execution_count":31,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/5\n","14/14 [==============================] - 26s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 1.1689e-04 - factorized_top_k/top_10_categorical_accuracy: 2.3378e-04 - factorized_top_k/top_50_categorical_accuracy: 0.0023 - factorized_top_k/top_100_categorical_accuracy: 0.0054 - loss: 8228.0671 - regularization_loss: 0.0000e+00 - total_loss: 8228.0671\n","Epoch 2/5\n","14/14 [==============================] - 25s 2s/step - factorized_top_k/top_1_categorical_accuracy: 1.1689e-04 - factorized_top_k/top_5_categorical_accuracy: 0.6100 - factorized_top_k/top_10_categorical_accuracy: 0.7778 - factorized_top_k/top_50_categorical_accuracy: 0.9620 - factorized_top_k/top_100_categorical_accuracy: 0.9894 - loss: 8133.4665 - regularization_loss: 0.0000e+00 - total_loss: 8133.4665\n","Epoch 3/5\n","14/14 [==============================] - 26s 2s/step - factorized_top_k/top_1_categorical_accuracy: 2.9223e-04 - factorized_top_k/top_5_categorical_accuracy: 0.6622 - factorized_top_k/top_10_categorical_accuracy: 0.8361 - factorized_top_k/top_50_categorical_accuracy: 0.9905 - factorized_top_k/top_100_categorical_accuracy: 0.9989 - loss: 7906.2176 - regularization_loss: 0.0000e+00 - total_loss: 7906.2176\n","Epoch 4/5\n","14/14 [==============================] - 25s 2s/step - factorized_top_k/top_1_categorical_accuracy: 5.2601e-04 - factorized_top_k/top_5_categorical_accuracy: 0.7219 - factorized_top_k/top_10_categorical_accuracy: 0.9153 - factorized_top_k/top_50_categorical_accuracy: 0.9961 - factorized_top_k/top_100_categorical_accuracy: 0.9992 - loss: 7289.9659 - regularization_loss: 0.0000e+00 - total_loss: 7289.9659\n","Epoch 5/5\n","14/14 [==============================] - 26s 2s/step - factorized_top_k/top_1_categorical_accuracy: 0.0014 - factorized_top_k/top_5_categorical_accuracy: 0.7464 - factorized_top_k/top_10_categorical_accuracy: 0.9448 - factorized_top_k/top_50_categorical_accuracy: 0.9988 - factorized_top_k/top_100_categorical_accuracy: 1.0000 - loss: 6046.9809 - regularization_loss: 0.0000e+00 - total_loss: 6046.9809\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.History at 0x7f7338dc64d0>"]},"metadata":{},"execution_count":31}]},{"cell_type":"code","source":["model.evaluate(cached_test, return_dict=True)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DxBDPFPogAb8","executionInfo":{"status":"ok","timestamp":1658435991293,"user_tz":240,"elapsed":2351,"user":{"displayName":"jagannathan Lakshmipathy","userId":"05639691877293412421"}},"outputId":"a2b50154-c267-424e-f367-305391a16d08"},"execution_count":32,"outputs":[{"output_type":"stream","name":"stdout","text":["6/6 [==============================] - 2s 292ms/step - factorized_top_k/top_1_categorical_accuracy: 0.2570 - factorized_top_k/top_5_categorical_accuracy: 0.8879 - factorized_top_k/top_10_categorical_accuracy: 0.9720 - factorized_top_k/top_50_categorical_accuracy: 1.0000 - factorized_top_k/top_100_categorical_accuracy: 1.0000 - loss: 313.0547 - regularization_loss: 0.0000e+00 - total_loss: 313.0547\n"]},{"output_type":"execute_result","data":{"text/plain":["{'factorized_top_k/top_100_categorical_accuracy': 1.0,\n"," 'factorized_top_k/top_10_categorical_accuracy': 0.9719626307487488,\n"," 'factorized_top_k/top_1_categorical_accuracy': 0.257009357213974,\n"," 'factorized_top_k/top_50_categorical_accuracy': 1.0,\n"," 'factorized_top_k/top_5_categorical_accuracy': 0.8878504633903503,\n"," 'loss': 209.40826416015625,\n"," 'regularization_loss': 0,\n"," 'total_loss': 209.40826416015625}"]},"metadata":{},"execution_count":32}]},{"cell_type":"code","source":["scann_index = tfrs.layers.factorized_top_k.ScaNN(model.question_model)\n","scann_index.index_from_dataset(\n","  tf.data.Dataset.zip((answers.batch(100), answers.batch(100).map(model.answer_model)))\n",")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8tV8vQBFjStB","executionInfo":{"status":"ok","timestamp":1658435992915,"user_tz":240,"elapsed":1626,"user":{"displayName":"jagannathan Lakshmipathy","userId":"05639691877293412421"}},"outputId":"fa1a0924-1fa1-4ef9-84da-63dc57bfeee6"},"execution_count":33,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<tensorflow_recommenders.layers.factorized_top_k.ScaNN at 0x7f733673a210>"]},"metadata":{},"execution_count":33}]},{"cell_type":"code","source":["# Get recommendations.\n","_, cands = scann_index(tf.constant([qid_to_text[5]]))\n","\n","print(f'QUESTION: ', qid_to_text[5])\n","print(f\"Recommendations for user 42: {cands[0, :10]}\")"],"metadata":{"id":"-p_7VOlvjYft","executionInfo":{"status":"ok","timestamp":1658435992915,"user_tz":240,"elapsed":8,"user":{"displayName":"jagannathan Lakshmipathy","userId":"05639691877293412421"}},"outputId":"1006a83a-a603-49bf-d7e3-11c1171c4256","colab":{"base_uri":"https://localhost:8080/"}},"execution_count":34,"outputs":[{"output_type":"stream","name":"stdout","text":["QUESTION:  Starting a new online business\n","Recommendations for user 42: [b\"Switzerland was once known for its high regard for private property rights.  Recently it is has started to violate those rights by forcing banks to turn over the names of account holders to the US government.  Not a great trend. Another aspect that makes Switzerland an attractive place for people and businesses is the Swiss governemnt's neutral policy.  The Swiss government is not deploying the Swiss military around the globe to fight terrorism, to spread democracy, to advance its own power, or other such murderous government programs.  The Swiss people do not have to worry about the payback that arrives because of such depraved government programs. The Swiss were traditionally extreme advocates of individual gun rights which allows the people to provide protection for themselves against others and against the government.  This too is changing (read section on The Enemy Within) in a not so favorable direction. I also belive the Swiss Franc was the last major currency to sever its tie to gold.  The currency use to be highly desired due to its tie to gold.  I think the currency is still highly regarded but the Swiss central bank is participating in the currency war and has attempted multiple times in the past couple of years to debase its currency so it does not appreciate against the euro or dollar.\"\n"," b'In addition to what George said, there are other things that probably benefit Switzerland:'\n"," b'The lake is beautiful. The Swiss people are really good educated The companies want to be a part of these great reputation. We have low taxes We are political stable Our currency is stable We are company-friendly'\n"," b'The cost of living is quite high in New York City.  It has the highest CPI (Consumer Price Index) of any city in the U.S.  Salaries also tend to be highest in NYC.  Just about any bicycle lock sold in the U.S. has an exception in its warranty for NYC.  It is the most populous American city. So, why do people deal with all the hassles of living here? Because, it is a hotbed of activity.   I venture that the advantages are basically the same in Zurich:'\n"," b\"Let's ask another question:  Why do you buy X at price $Y? Here are some answers: Now, another question:  Are you guaranteed to get at least $Y worth of value when you buy X? Of course not!  A lot of things can happen.  Your car can be a lemon.  Your pedigreed Dachshund can get run over by a snowblower.  Or, the prices of the underlying commodity or security can go against your futures contract. You can raise your chances of getting appropriate value out of X by doing your homework and hedging your risk.  The more homework you do, the less of a gamble you're taking.\"\n"," b\"This is not hypothetical, this is an accurate story. I am a long-term investor. I have a bunch of money that I'd like to invest and I plan on spreading it out over five or six mutual funds and ETFs, roughly according to the Canadian Couch Potato model portfolio (that is, passive mutual funds and ETFs rather than specific stocks). I am concerned that if I invest the full amount and the stock market crashes 30% next month, I will have paid more than I had to. As I am investing for the long term, I expect to more than regain my investment, but I still wouldn't be thrilled with paying 30% more than I had to. Instead, I am investing my money in three stages. I invested the first third earlier this month. I'll invest the next third in a few months, and the final third a few months after that. If the stock market climbs, as I expect is more likely the case, I will have lost out on some potential upside. However, if the stock market crashes next month, I will end up paying a lower average cost as two of my three purchases will occur after the crash. On average, as a long-term investor, I expect the stock market to go up. In the short term, I expect much more fluctuation. Statistically speaking, I'd do better to invest all the money at once as most of the time, the trend is upward. However, I am willing to trade some potential upside for a somewhat reduced risk of downside over the course of the next few months. If we were talking a price difference of 1% as mentioned in the question, I wouldn't care. I expect to see average annual returns far above this. But stock market crashes can cause the loss of 20 to 30% or more, and those are numbers I care about. I'd much rather buy in at 30% less than the current price, after all.\"\n"," b'No, CFD is not viable as a long term trading strategy.  You have a minimum margin to maintain, and you are given X days to top up your margin should you not meet the margin requirements. Failure to meet margin requirements will result in a forced sell where you are no longer able to hold onto the stock. A long term trading strategy is where you hold onto the stock through the bad times of the company and keep it long enough to see the good times. However, with CFD, you may be forced to sell before you see the good times. In addition, you incur additional lending charges (e.g. 4%-6%) for the ability to leverage.'\n"," b\"As per Wikipedia of right now, here are unemployment figures for Switzerland and surrounding countries: Liechtenstein, unfortunately, does not have a large job market, given its total population of about 37,000 people. And note that the German figure of 4.5% is the lowest it has been for decades - I'd expect this number to go up and the Swiss one to stay constant. Bottom line: you will have an easier time finding a job in Switzerland. (Plus all the other good points the other answers raised: great mountains, great chocolate, low taxes, clean streets etc.)\"\n"," b\"Here's my take: 1) Having a car loan and paying it on time helps build credit. Not as much as having credit cards (and keeping them paid or carrying balance just enough to be reported and then paying it), but it counts. 2) Can't you set in your bank, not the lender, something to pay the car automagically for you? Then you will be paying it on time without having to think on it. 3) As others said, do read the fine print.\"\n"," b\"I'm not sure who specifically you are talking about. Those are some pretty broad generalizations. Where do you draw the line about what is too much concern about entry price? On what basis do you make the assertion that they are overly concerned with it? For those that do: Probably because when you are buying anything, a lower price is preferable in general. Why WOULDN'T you want to get the best deal possible? I think you are making assumptions (about whom I don't know) that people always invest based on cold hard logic. This is not often the case.\"]\n"]}]},{"cell_type":"code","source":["recommendations, cands = scann_index(tf.constant([qid_to_text[5]]))"],"metadata":{"id":"Wk2Gsa-80JV5","executionInfo":{"status":"ok","timestamp":1658435992915,"user_tz":240,"elapsed":5,"user":{"displayName":"jagannathan Lakshmipathy","userId":"05639691877293412421"}}},"execution_count":35,"outputs":[]},{"cell_type":"code","source":["type(cands[0, 0].numpy().decode())\n","#cands[0, 0]\n","[type(t.numpy().decode()) for t in cands[0]]"],"metadata":{"id":"wtsbSaG10SDy","executionInfo":{"status":"ok","timestamp":1658443211079,"user_tz":240,"elapsed":238,"user":{"displayName":"jagannathan Lakshmipathy","userId":"05639691877293412421"}},"outputId":"5aafcb34-f051-4cbd-a7dd-692943890dc1","colab":{"base_uri":"https://localhost:8080/"}},"execution_count":85,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[str, str, str, str, str, str, str, str, str, str]"]},"metadata":{},"execution_count":85}]},{"cell_type":"code","source":["text_to_docid = dict([ (docid_to_text[k], k) for k in docid_to_text])\n","\n","def run_twotower_scores(data):\n","  ap = []\n","  rr = []\n","  cg = []\n","\n","  #for i, seq in enumerate(tqdm(train_set)):\n","  for j, seq in enumerate(data):\n","    qid, ans_labels, _ , _ = seq[0], seq[1], seq[2], seq[3]\n","    cands_score, cand_ans = scann_index(tf.constant([qid_to_text[qid]]))\n","    cands = [t.numpy().decode() for t in cand_ans]\n","    #cands = [s.decode('utf-8') for s in np.ravel(cands).tolist()]\n","    cands_score = np.ravel(cands_score).tolist()\n","\n","    \n","    # Map question id to text\n","    #q_text = qid_to_text[qid]\n","\n","    max_width = -1\n","    rr_ = 0\n","    ap_ = 0.0\n","    precision_ = 0.0\n","    relcnt_ = 0\n","\n","    top_k = 10\n","\n","    # For each answer in the candidates\n","    for i in range(top_k):\n","      docid = cands[i]\n","      print(docid)\n","      if docid in ans_labels and rr_ == 0:\n","        rr_ = 1/(i+1)\n","    \n","    relscores = [1 if docid in ans_labels else 0 for docid in cands[:top_k]]\n","    pos = [1.0/(i+1) for i in range(top_k)]\n","    ap_ = average_precision_score(relscores,pos) if sum(relscores) != 0 else 0 \n","\n","    #print(ap_, [1 if docid in ans_labels else 0 for docid in cands[:top_k]], [1.0/(i+1) for i in range(top_k)])\n","    relscores = np.asarray([[np.log2(cands_score[i]) if (cands[i] in ans_labels) else 0.001 for i in range(top_k)]])\n","    pos = np.asarray([[np.log2(i+2) for i in range(top_k)]])\n","\n","    cg_ = ndcg_score(relscores, pos)\n","\n","    print('>>>', i, ap_, rr_, cg_)\n","\n","    ap.append(ap_)\n","    rr.append(rr_)\n","    cg.append(cg_)\n","  return rr, ap, cg"],"metadata":{"id":"bmursBRIfunM","executionInfo":{"status":"ok","timestamp":1658443142434,"user_tz":240,"elapsed":201,"user":{"displayName":"jagannathan Lakshmipathy","userId":"05639691877293412421"}}},"execution_count":83,"outputs":[]},{"cell_type":"code","source":["rr, ap, cg = run_twotower_scores(train_set)\n","\n","print('Mean Reciprocal Rank (MRR):', np.mean(rr))\n","print('Mean average Precision (MAP)', np.mean(ap))\n","print('Normalized Discounted Cumulative Gain (NDCG)', np.mean(cg))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":503},"id":"aSFRDp37l-2B","executionInfo":{"status":"error","timestamp":1658443144545,"user_tz":240,"elapsed":203,"user":{"displayName":"jagannathan Lakshmipathy","userId":"05639691877293412421"}},"outputId":"56bac7e6-85a7-450f-dcbb-dab93b59d8ee"},"execution_count":84,"outputs":[{"output_type":"error","ename":"AttributeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;32m<ipython-input-84-75860144eafa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mrr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0map\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_twotower_scores\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_set\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Mean Reciprocal Rank (MRR):'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Mean average Precision (MAP)'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0map\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Normalized Discounted Cumulative Gain (NDCG)'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-83-9458494b691d>\u001b[0m in \u001b[0;36mrun_twotower_scores\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mqid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mans_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mseq\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseq\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseq\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseq\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mcands_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcand_ans\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscann_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconstant\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mqid_to_text\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mqid\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0mcands\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcand_ans\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m     \u001b[0;31m#cands = [s.decode('utf-8') for s in np.ravel(cands).tolist()]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mcands_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcands_score\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-83-9458494b691d>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mqid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mans_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mseq\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseq\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseq\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseq\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mcands_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcand_ans\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscann_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconstant\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mqid_to_text\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mqid\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0mcands\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcand_ans\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m     \u001b[0;31m#cands = [s.decode('utf-8') for s in np.ravel(cands).tolist()]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mcands_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcands_score\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'decode'"]}]},{"cell_type":"code","source":["ap[:10]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"P_mT7m9spkRl","executionInfo":{"status":"ok","timestamp":1658438848618,"user_tz":240,"elapsed":212,"user":{"displayName":"jagannathan Lakshmipathy","userId":"05639691877293412421"}},"outputId":"a419b5a0-8ba5-4746-c57d-b61a4802beeb"},"execution_count":50,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"]},"metadata":{},"execution_count":50}]}]}